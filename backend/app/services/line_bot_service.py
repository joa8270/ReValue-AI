import asyncio
import io
import json
import random
import uuid
import re
import base64
import requests
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    MessagingApiBlob,
    ReplyMessageRequest,
    TextMessage,
    PushMessageRequest
)
from app.core.config import settings
from app.core.database import create_simulation, update_simulation, get_simulation, get_random_citizens

# Alias for compatibility with main.py
get_simulation_data = get_simulation


class LineBotService:
    # In-memory session storage for user states
    user_session = {}
    
    def __init__(self):
        configuration = Configuration(access_token=settings.LINE_CHANNEL_ACCESS_TOKEN)
        self.api_client = ApiClient(configuration)
        self.line_bot_api = MessagingApi(self.api_client)
        self.line_bot_blob = MessagingApiBlob(self.api_client)

    async def handle_event(self, event):
        """
        é›™è»Œè¼¸å…¥æ©Ÿåˆ¶ (Dual-Track Input)
        - æƒ…å¢ƒ A: åœ–ç‰‡ (ImageMessage) â†’ æš«å­˜ä¸¦ç­‰å¾…è£œå……èªªæ˜
        - æƒ…å¢ƒ B: æ–‡å­— (TextMessage) â†’ æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        - æƒ…å¢ƒ C: æª”æ¡ˆ (FileMessage) â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸
        """
        user_id = event.source.user_id
        reply_token = event.reply_token
        message_type = event.message.type
        
        print(f"[EVENT] user_id={user_id}, type={message_type}")
        
        # ===== æƒ…å¢ƒ A: åœ–ç‰‡è¨Šæ¯ =====
        if message_type == "image":
            await self._handle_image_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ B: æ–‡å­—è¨Šæ¯ =====
        elif message_type == "text":
            await self._handle_text_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ C: æª”æ¡ˆè¨Šæ¯ (PDF) =====
        elif message_type == "file":
            await self._handle_file_message(event, user_id, reply_token)
        
        else:
            # ä¸æ”¯æ´çš„è¨Šæ¯é¡å‹
            pass

    async def _handle_image_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ A: æ”¶åˆ°åœ–ç‰‡ â†’ æš«å­˜ä¸¦ç­‰å¾…ç”¢å“åç¨±å’Œå”®åƒ¹"""
        message_id = event.message.id
        
        # ä¸‹è¼‰åœ–ç‰‡ä¸¦æš«å­˜
        try:
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            
            # æš«å­˜åˆ° sessionï¼ˆæ–°æµç¨‹ï¼šå…ˆå•åç¨±/å”®åƒ¹ï¼‰
            self.user_session[user_id] = {
                "image_bytes": image_bytes,
                "message_id": message_id,
                "stage": "waiting_for_name_price",  # æ–°ç‹€æ…‹ï¼šç­‰å¾…åç¨±å’Œå”®åƒ¹
                "product_name": None,
                "product_price": None,
                "product_description": None,
                "generated_descriptions": None  # AI ç”Ÿæˆçš„å…©æ®µæè¿°
            }
            
            print(f"ğŸ“¸ [SESSION] å·²æš«å­˜åœ–ç‰‡: user_id={user_id}, size={len(image_bytes)} bytes")
            
            # å›è¦†å¼•å°è¨Šæ¯ï¼ˆæ–°æµç¨‹ï¼šå…ˆå•åç¨±å’Œå”®åƒ¹ï¼‰
            guide_msg = (
                "ğŸ”® **MIRRA ç³»çµ±å·²æ¥æ”¶ç”¢å“å½±åƒã€‚**\n\n"
                "è«‹æä¾›ä»¥ä¸‹è³‡è¨Šï¼Œæ ¼å¼ï¼š**åç¨± / å”®åƒ¹**\n"
                "ä¾‹å¦‚ï¼šã€Œçç é«®å¤¾ / 380ã€\n\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "ğŸ’¡ è‹¥ä¸ç¢ºå®šå”®åƒ¹ï¼Œå¯è¼¸å…¥ï¼šã€Œçç é«®å¤¾ / æœªå®šã€"
            )
            self.reply_text(reply_token, guide_msg)
            
        except Exception as e:
            print(f"âŒ [IMAGE] ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {e}")
            self.reply_text(reply_token, "âŒ åœ–ç‰‡ä¸‹è¼‰å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def _handle_text_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ B: æ”¶åˆ°æ–‡å­— â†’ å¤šéšæ®µè™•ç†æµç¨‹"""
        text_content = event.message.text.strip()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        if user_id not in self.user_session:
            # æ²’æœ‰æš«å­˜åœ–ç‰‡ï¼Œå›è¦†å¼•å°è¨Šæ¯
            guide_msg = (
                "ğŸ”® **æ­¡è¿ä¾†åˆ° MIRRA é¡ç•Œ**\n\n"
                "æˆ‘æ˜¯é€£æ¥ç¾å¯¦èˆ‡å¹³è¡Œä¸–ç•Œçš„é æ¼”ç³»çµ±ã€‚\n\n"
                "ğŸ“¸ ä¸Šå‚³ **ç”¢å“åœ–ç‰‡** â†’ å•Ÿå‹•è³¼è²·æ„åœ–é æ¼”\n"
                "ğŸ“„ ä¸Šå‚³ **å•†æ¥­è¨ˆåŠƒæ›¸ PDF** â†’ å•Ÿå‹•å•†æ¥­æ¨¡å¼æ¨æ¼”\n\n"
                "è«‹é¸æ“‡æ‚¨çš„é æ¼”è»Œé“ã€‚"
            )
            self.reply_text(reply_token, guide_msg)
            return
        
        session = self.user_session[user_id]
        stage = session.get("stage")
        
        # ===== éšæ®µ 1: ç­‰å¾…åç¨±å’Œå”®åƒ¹ =====
        if stage == "waiting_for_name_price":
            # è§£æã€Œåç¨± / å”®åƒ¹ã€æ ¼å¼
            if "/" in text_content:
                parts = text_content.split("/", 1)
                name = parts[0].strip()
                price = parts[1].strip() if len(parts) > 1 else "æœªå®š"
            else:
                name = text_content
                price = "æœªå®š"
            
            session["product_name"] = name
            session["product_price"] = price
            session["stage"] = "waiting_for_description_choice"
            
            print(f"ğŸ“ [SESSION] æ”¶åˆ°åç¨±/å”®åƒ¹: {name} / {price}")
            
            # è©¢å•æè¿°ä¾†æº
            choice_msg = (
                f"âœ… å·²æ”¶åˆ°ï¼š**{name}** / **{price}**\n\n"
                "è«‹é¸æ“‡ç”¢å“æè¿°çš„æ–¹å¼ï¼š\n\n"
                "1ï¸âƒ£ è¼¸å…¥ã€Œ**1**ã€â†’ è‡ªè¡Œè¼¸å…¥æè¿°\n"
                "2ï¸âƒ£ è¼¸å…¥ã€Œ**2**ã€â†’ è®“ AI å¹«æˆ‘ç”Ÿæˆæè¿°\n"
                "3ï¸âƒ£ è¼¸å…¥ã€Œ**ç•¥é**ã€â†’ ç›´æ¥é–‹å§‹åˆ†æ"
            )
            self.reply_text(reply_token, choice_msg)
        
        # ===== éšæ®µ 2: ç­‰å¾…æè¿°é¸æ“‡ =====
        elif stage == "waiting_for_description_choice":
            if text_content == "1":
                # é¸æ“‡è‡ªè¡Œè¼¸å…¥
                session["stage"] = "waiting_for_manual_description"
                self.reply_text(reply_token, "ğŸ“ è«‹è¼¸å…¥æ‚¨çš„ç”¢å“æè¿°èˆ‡ç‰¹é»ï¼š")
            
            elif text_content == "2":
                # é¸æ“‡ AI ç”Ÿæˆ
                session["stage"] = "generating_descriptions"
                self.reply_text(reply_token, "ğŸ¤– AI æ­£åœ¨æ ¹æ“šåœ–ç‰‡ç”Ÿæˆæè¿°ï¼Œè«‹ç¨å€™...")
                
                # éåŒæ­¥ç”Ÿæˆæè¿°
                await self._generate_ai_descriptions(user_id, reply_token)
            
            elif text_content.lower() in ["ç•¥é", "skip", "è·³é", "3"]:
                # ç›´æ¥é–‹å§‹åˆ†æ
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€Œ1ã€ã€ã€Œ2ã€æˆ–ã€Œç•¥éã€")
        
        # ===== éšæ®µ 3: ç­‰å¾…æ‰‹å‹•è¼¸å…¥æè¿° =====
        elif stage == "waiting_for_manual_description":
            session["product_description"] = text_content
            print(f"[SESSION] æ”¶åˆ°æ‰‹å‹•æè¿°: {text_content[:50]}...")
            await self._start_simulation(user_id, reply_token)
        
        # ===== éšæ®µ 4: ç­‰å¾… A/B é¸æ“‡ =====
        elif stage == "waiting_for_ab_choice":
            descriptions = session.get("generated_descriptions", [])
            
            if text_content.upper() == "A" and len(descriptions) > 0:
                session["product_description"] = descriptions[0]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° A")
                await self._start_simulation(user_id, reply_token)
            
            elif text_content.upper() == "B" and len(descriptions) > 1:
                session["product_description"] = descriptions[1]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° B")
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€ŒAã€æˆ–ã€ŒBã€é¸æ“‡æè¿°")
        
        # ===== èˆŠæµç¨‹å…¼å®¹ï¼ˆwaiting_for_detailsï¼‰=====
        elif stage == "waiting_for_details":
            # èˆŠæµç¨‹ï¼šç›´æ¥ä½¿ç”¨æ–‡å­—ä½œç‚ºè£œå……èªªæ˜
            text_context = None if text_content.lower() in ["ç•¥é", "skip", "è·³é"] else text_content
            session["product_description"] = text_context
            await self._start_simulation(user_id, reply_token)
        
        else:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")

    async def _generate_ai_descriptions(self, user_id, reply_token):
        """ä½¿ç”¨ AI æ ¹æ“šåœ–ç‰‡+åç¨±+å”®åƒ¹ç”Ÿæˆå…©æ®µç”¢å“æè¿°"""
        session = self.user_session.get(user_id)
        if not session:
            return
        
        image_bytes = session.get("image_bytes")
        product_name = session.get("product_name", "ç”¢å“")
        product_price = session.get("product_price", "æœªå®š")
        
        try:
            # å°‡åœ–ç‰‡è½‰ç‚º Base64
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # æ§‹å»º Promptï¼šè¦æ±‚æ·±åº¦å ´æ™¯èˆ‡æ²‰æµ¸å¼æ–‡æ¡ˆ
            prompt = f"""è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦æ ¹æ“šæä¾›çš„è³‡è¨Šï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚

ç”¢å“åç¨±ï¼š{product_name}
å»ºè­°å”®åƒ¹ï¼š{product_price}

è«‹ä¸è¦åªå¯«ã€Œå„ªé›…ã€æˆ–ã€Œå¯¦ç”¨ã€é€™ç¨®ç©ºæ³›çš„å½¢å®¹è©ã€‚æˆ‘éœ€è¦ä½ èƒ½å¤ ï¼š
1. **æ·±åº¦è­˜åˆ¥**ï¼šå®Œå…¨ç†è§£å•†å“çš„æè³ªã€è¨­è¨ˆèªè¨€èˆ‡æ½›åœ¨å•†æ¥­åƒ¹å€¼ã€‚
2. **ç²¾æº–åŒ¹é…**ï¼šå…·é«”æŒ‡å‡ºé€™æ¬¾ç”¢å“æœ€é©åˆã€Œä»€éº¼æ¨£çš„äººã€ã€ã€Œåœ¨ä»€éº¼å ´åˆã€ã€ã€Œåšä»€éº¼äº‹ã€æ™‚ä½¿ç”¨ã€‚
3. **æ²‰æµ¸é«”é©—**ï¼šç”¨æ–‡å­—ç‡Ÿé€ å‡ºæ°›åœï¼Œè®“è§€çœ‹è€…å½·å½¿ç½®èº«å…¶ä¸­ï¼Œæ„Ÿå—åˆ°æ“æœ‰é€™ä»¶å•†å“å¾Œçš„ç¾å¥½ç”Ÿæ´»åœ–æ™¯ã€‚

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆç¹é«”ä¸­æ–‡ï¼Œæ¯æ®µç´„ 100-150 å­—ï¼‰ï¼š

ã€Aã€‘åˆ‡å…¥é»ä¸€ï¼šæƒ…æ„Ÿå…±é³´èˆ‡æ°›åœç‡Ÿé€  (Emotional & Atmospheric)
- å´é‡æ–¼æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨ç•¶ä¸‹çš„ç¾å¥½ç•«é¢ã€å¿ƒç†æ»¿è¶³æ„Ÿæˆ–è‡ªæˆ‘å±•ç¾ã€‚
- é©åˆæƒ³é€éç”¢å“æå‡ç”Ÿæ´»è³ªæ„Ÿæˆ–è¡¨é”å€‹æ€§çš„å®¢ç¾¤ã€‚

ã€Bã€‘åˆ‡å…¥é»äºŒï¼šç²¾æº–å ´æ™¯èˆ‡ç—›é»è§£æ±º (Scenario & Solution)
- å´é‡æ–¼ç†æ€§èˆ‡å ´æ™¯è¨´æ±‚ï¼Œå…·é«”æè¿°åœ¨å·¥ä½œã€ç¤¾äº¤æˆ–ç‰¹å®šæ´»å‹•ä¸­çš„å®Œç¾è¡¨ç¾ã€‚
- å³ä½¿æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œä¹Ÿè¦æè¿°å…¶å•†æ¥­æ¨¡å¼è½åœ°çš„å…·é«”å ´æ™¯èˆ‡è§£æ±ºçš„å¯¦éš›å•é¡Œã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdown æ¨™è¨˜ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ (å¦‚ï¼šé€±æœ«åˆå¾Œçš„å¾®å¥¢æ™‚å…‰)",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ (å¦‚ï¼šè·å ´ç©¿æ­çš„é»ç›ä¹‹ç­†)",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
"""
            
            # èª¿ç”¨ Gemini API
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{
                    "parts": [
                        {"text": prompt},
                        {"inline_data": {"mime_type": "image/jpeg", "data": image_b64}}
                    ]
                }],
                "generationConfig": {
                    "maxOutputTokens": 1024,
                    "temperature": 0.8,
                    "responseMimeType": "application/json"
                }
            }
            
            api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?key={api_key}"
            
            # æ·»åŠ é‡è©¦æ©Ÿåˆ¶
            max_retries = 2
            response = None
            for attempt in range(max_retries):
                try:
                    response = requests.post(api_url, headers={'Content-Type': 'application/json'}, json=payload, timeout=30)
                    if response.status_code == 200:
                        break
                    elif response.status_code == 429:
                        print(f"âš ï¸ API Rate Limit (429), å˜—è©¦ {attempt + 1}/{max_retries}, ç­‰å¾… 2 ç§’...")
                        await asyncio.sleep(2)
                    else:
                        print(f"âš ï¸ API Error: {response.status_code} - {response.text}")
                        break
                except Exception as e:
                    print(f"âŒ API è«‹æ±‚éŒ¯èª¤: {e}")
            
            if response and response.status_code == 200:
                result = response.json()
                try:
                    ai_text = result['candidates'][0]['content']['parts'][0]['text']
                except (KeyError, IndexError):
                    ai_text = "{}"
                
                # æ¸…ç† Markdown æ¨™è¨˜ä¸¦æå– JSON
                ai_text = ai_text.strip()
                match = re.search(r'\{.*\}', ai_text, re.DOTALL)
                if match:
                    ai_text = match.group(0)
                
                # è§£æ JSON
                try:
                    data = json.loads(ai_text)
                    title_a = data.get("title_a", "âœ¨ æƒ…æ„Ÿå…±é³´ç‰ˆ")
                    desc_a = data.get("description_a", "AI ç”Ÿæˆæè¿° A")
                    title_b = data.get("title_b", "ğŸ’¼ ç²¾æº–å ´æ™¯ç‰ˆ")
                    desc_b = data.get("description_b", "AI ç”Ÿæˆæè¿° B")
                except:
                    # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨é è¨­æè¿°
                    title_a = "âœ¨ æƒ…æ„Ÿå…±é³´ç‰ˆ"
                    desc_a = f"é€™æ¬¾{product_name}ä¸åƒ…æ˜¯å•†å“ï¼Œæ›´æ˜¯ä¸€ç¨®ç”Ÿæ´»æ…‹åº¦çš„å±•ç¾ã€‚å„ªè³ªææ–™èˆ‡ç´°è†©è¨­è¨ˆï¼Œç‚ºæ‚¨çš„æ—¥å¸¸ç”Ÿæ´»å¢æ·»ä¸€æŠ¹ä¸å‡¡çš„è³ªæ„Ÿï¼Œè®“æ¯ä¸€æ¬¡ä½¿ç”¨éƒ½æˆç‚ºäº«å—ã€‚"
                    title_b = "ğŸ’¼ ç²¾æº–å ´æ™¯ç‰ˆ"
                    desc_b = f"{product_name}å®Œç¾è§£æ±ºäº†å¯¦éš›éœ€æ±‚ï¼Œå”®åƒ¹ {product_price} å…ƒã€‚ç„¡è«–æ˜¯å·¥ä½œå ´åˆé‚„æ˜¯æ—¥å¸¸ä½¿ç”¨ï¼Œéƒ½èƒ½å±•ç¾æ¥µä½³çš„å¯¦ç”¨æ€§èˆ‡å°ˆæ¥­æ„Ÿï¼Œæ˜¯é«˜CPå€¼çš„è°æ˜é¸æ“‡ã€‚"
                
                # å„²å­˜ç”Ÿæˆçš„æè¿°
                session["generated_descriptions"] = [desc_a, desc_b]
                session["stage"] = "waiting_for_ab_choice"
                
                # ç™¼é€é¸æ“‡è¨Šæ¯ï¼ˆä½¿ç”¨ push messageï¼‰
                choice_msg = (
                    "ğŸ”® **AI ç‚ºæ‚¨ç”Ÿæˆäº†å…©æ®µæ²‰æµ¸å¼æ–‡æ¡ˆï¼š**\n\n"
                    f"ã€Aã€‘{title_a}\n{desc_a}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    f"ã€Bã€‘{title_b}\n{desc_b}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    "è«‹å›è¦†ã€Œ**A**ã€æˆ–ã€Œ**B**ã€é¸æ“‡æ‚¨åå¥½çš„æ‡‰ç”¨å ´æ™¯"
                )
                self._push_text(user_id, choice_msg)
            else:
                # API å¤±æ•—æ™‚ä½¿ç”¨é è¨­æè¿°
                print(f"âš ï¸ AI ç”Ÿæˆæè¿°å¤±æ•— ({response.status_code if response else 'No response'})ï¼Œä½¿ç”¨é è¨­æè¿°")
                title_a = "âœ¨ æƒ…æ„Ÿå…±é³´ç‰ˆ"
                desc_a = f"é€™æ¬¾{product_name}ä¸åƒ…æ˜¯å•†å“ï¼Œæ›´æ˜¯ä¸€ç¨®ç”Ÿæ´»æ…‹åº¦çš„å±•ç¾ã€‚å„ªè³ªææ–™èˆ‡ç´°è†©è¨­è¨ˆï¼Œç‚ºæ‚¨çš„æ—¥å¸¸ç”Ÿæ´»å¢æ·»ä¸€æŠ¹ä¸å‡¡çš„è³ªæ„Ÿï¼Œè®“æ¯ä¸€æ¬¡ä½¿ç”¨éƒ½æˆç‚ºäº«å—ã€‚"
                title_b = "ğŸ’¼ ç²¾æº–å ´æ™¯ç‰ˆ"
                desc_b = f"{product_name}å®Œç¾è§£æ±ºäº†å¯¦éš›éœ€æ±‚ï¼Œå”®åƒ¹ {product_price} å…ƒã€‚ç„¡è«–æ˜¯å·¥ä½œå ´åˆé‚„æ˜¯æ—¥å¸¸ä½¿ç”¨ï¼Œéƒ½èƒ½å±•ç¾æ¥µä½³çš„å¯¦ç”¨æ€§èˆ‡å°ˆæ¥­æ„Ÿï¼Œæ˜¯é«˜CPå€¼çš„è°æ˜é¸æ“‡ã€‚"
                
                session["generated_descriptions"] = [desc_a, desc_b]
                session["stage"] = "waiting_for_ab_choice"
                
                choice_msg = (
                    "ğŸ”® **AI ç‚ºæ‚¨ç”Ÿæˆäº†å…©æ®µæ²‰æµ¸å¼æ–‡æ¡ˆï¼ˆé è¨­æ¨¡æ¿ï¼‰ï¼š**\n\n"
                    f"ã€Aã€‘{title_a}\n{desc_a}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    f"ã€Bã€‘{title_b}\n{desc_b}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    "è«‹å›è¦†ã€Œ**A**ã€æˆ–ã€Œ**B**ã€é¸æ“‡æ‚¨åå¥½çš„æ‡‰ç”¨å ´æ™¯"
                )
                self._push_text(user_id, choice_msg)
                
        except Exception as e:
            print(f"âŒ _generate_ai_descriptions éŒ¯èª¤: {e}")
            session["stage"] = "waiting_for_description_choice"
            self._push_text(user_id, "âŒ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é¸æ“‡ã€Œ1ã€è‡ªè¡Œè¼¸å…¥æè¿°")

    async def _start_simulation(self, user_id, reply_token):
        """çµ„åˆç”¢å“è³‡è¨Šä¸¦å•Ÿå‹•æ¨¡æ“¬åˆ†æ"""
        session = self.user_session.get(user_id)
        if not session:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")
            return
        
        # å–å¾—æ‰€æœ‰è³‡è¨Š
        image_bytes = session.get("image_bytes")
        message_id = session.get("message_id")
        product_name = session.get("product_name", "")
        product_price = session.get("product_price", "")
        product_description = session.get("product_description", "")
        
        # çµ„åˆæ–‡å­—ä¸Šä¸‹æ–‡
        text_context = ""
        if product_name:
            text_context += f"ç”¢å“åç¨±ï¼š{product_name}\n"
        if product_price:
            text_context += f"å»ºè­°å”®åƒ¹ï¼š{product_price}\n"
        if product_description:
            text_context += f"ç”¢å“æè¿°ï¼š{product_description}\n"
        
        text_context = text_context.strip() if text_context else None
        
        print(f"ğŸ“ [SESSION] å•Ÿå‹•æ¨¡æ“¬: name={product_name}, price={product_price}, desc={product_description[:30] if product_description else 'None'}...")
        
        # æ¸…é™¤ session
        del self.user_session[user_id]
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ”µ **MIRRA å¹³è¡Œæ™‚ç©ºé æ¼”ç³»çµ±å•Ÿå‹•ä¸­...**\n\n"
            f"ğŸ“¦ ç”¢å“ï¼š{product_name or '(åœ–ç‰‡åˆ†æ)'}\n"
            f"ğŸ’° å”®åƒ¹ï¼š{product_price or 'æœªå®š'}\n\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–š 1,000 ä½è™›æ“¬å¸‚æ°‘é€²å…¥è¼¿è«–ç«¶æŠ€å ´...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨åˆ†ææ‚¨çš„ç”¢å“åœ–ç‰‡ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ AI åˆ†æï¼ˆé‡æ§‹å¾Œï¼šä½¿ç”¨ run_simulation_with_image_dataï¼‰
        await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)

    def _push_text(self, user_id, text):
        """ä¸»å‹•æ¨é€æ–‡å­—è¨Šæ¯çµ¦ç”¨æˆ¶ï¼ˆéå›è¦†ï¼‰"""
        try:
            self.line_bot_api.push_message(
                PushMessageRequest(to=user_id, messages=[TextMessage(text=text)])
            )
        except Exception as e:
            print(f"âŒ Push message å¤±æ•—: {e}")

    async def _handle_file_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ C: æ”¶åˆ°æª”æ¡ˆ â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸"""
        file_name = event.message.file_name
        file_size = event.message.file_size
        message_id = event.message.id
        
        print(f"ğŸ“„ [FILE] æ”¶åˆ°æª”æ¡ˆ: {file_name}, size={file_size}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚º PDF
        if not file_name.lower().endswith('.pdf'):
            self.reply_text(reply_token, "âŒ ç›®å‰åƒ…æ”¯æ´ PDF æ ¼å¼çš„å•†æ¥­è¨ˆåŠƒæ›¸")
            return
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ“„ **MIRRA ç³»çµ±å·²è®€å–å•†æ¥­è¨ˆåŠƒæ›¸ (PDF)**\n\n"
            f"æ­£åœ¨å°‡å•†æ¥­æ¨¡å¼è§£æ§‹ä¸¦å‚³é€è‡³è¼¿è«–ç«¶æŠ€å ´...\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–šè™›æ“¬å¸‚æ°‘é‡å° **ã€Œå•†æ¥­å¯è¡Œæ€§ã€** èˆ‡ **ã€Œç²åˆ©æ¨¡å¼ã€** é€²è¡Œæ¨æ¼”...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨é–±è®€æ‚¨çš„å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ PDF åˆ†æï¼ˆå¾…é‡æ§‹ï¼‰
        try:
            # ä¸‹è¼‰ PDF
            print(f"ğŸ“¥ [PDF] ä¸‹è¼‰ PDF: message_id={message_id}")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            self.reply_text(reply_token, "âŒ PDF ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def process_image_with_ai(self, message_id, sim_id, text_context=None):
        """
        [Legacy Wrapper] 
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼ï¼Œä½†å…§éƒ¨æ”¹ç‚ºä¸‹è¼‰å¾Œèª¿ç”¨ run_simulation_with_image_data
        """
        try:
            print(f"ğŸš€ [LineBot] é–‹å§‹ AI åˆ†ææµç¨‹: sim_id={sim_id}")
            print(f"ğŸ“¥ [LineBot] ä¸‹è¼‰åœ–ç‰‡: message_id={message_id}")
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot] åœ–ç‰‡ä¸‹è¼‰å®Œæˆ: {len(image_bytes)} bytes")
            
            await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)
        except Exception as e:
            print(f"âŒ [LineBot] åœ–ç‰‡ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            # Error updating happens inside run_simulation_with_image_data for analysis errors
            # But if download fails, we handle it here roughly? 
            # Actually run_simulation handles db update. 
            pass

    async def process_pdf_with_ai(self, message_id, sim_id, file_name):
        """
        [Legacy Wrapper]
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼
        """
        try:
            print(f"ğŸ“„ [LineBot PDF] é–‹å§‹ PDF åˆ†ææµç¨‹: sim_id={sim_id}, file={file_name}")
            print(f"ğŸ“¥ [LineBot PDF] ä¸‹è¼‰ PDF...")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [LineBot PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")

    async def run_simulation_with_image_data(self, image_bytes, sim_id, text_context=None):
        """æ ¸å¿ƒåœ–ç‰‡åˆ†æé‚è¼¯ (Decoupled)"""
        try:
            # Convert image to base64 for REST API
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            print(f"âœ… [Core] Base64 ç·¨ç¢¼å®Œæˆ")

            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            print(f"ğŸ” [Core] å¾è³‡æ–™åº«æŠ½å–å¸‚æ°‘...")
            sampled_citizens = get_random_citizens(sample_size=30)
            print(f"âœ… [Core] æŠ½å–å®Œæˆ: {len(sampled_citizens)} ä½å¸‚æ°‘")
            
            random.shuffle(sampled_citizens)
            
            # ç°¡åŒ–å¸‚æ°‘è³‡æ–™ä¾› prompt ä½¿ç”¨
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "occupation": c.get("occupation", "è‡ªç”±æ¥­"),
                    "location": c.get("location", "å°ç£"),
                    "traits": c["traits"][:2] if c["traits"] else []
                }
                for c in sampled_citizens[:15]
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False)
            
            # æ§‹å»ºç”¢å“è£œå……è³‡è¨Š
            product_context = ""
            if text_context:
                product_context = f"""
ğŸ“¦ ä½¿ç”¨è€…è£œå……çš„ç”¢å“è³‡è¨Šï¼š
{text_context}

è«‹ç‰¹åˆ¥è€ƒæ…®ä¸Šè¿°ç”¢å“è³‡è¨Šé€²è¡Œåˆ†æã€‚
"""
            
            # 3. Prompt
            prompt_text = f"""
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AIã€‚è«‹åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦ã€Œæ‰®æ¼”ã€ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ {len(sampled_citizens)} ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œæ¨¡æ“¬ä»–å€‘å°ç”¢å“çš„åæ‡‰ã€‚
{product_context}
ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

    "simulation_metadata": {{
        "product_category": "(ç”¢å“é¡åˆ¥)",
        "marketing_angle": "(è¡ŒéŠ·åˆ‡è§’)",
        "bazi_analysis": "(å…«å­—äº”è¡Œèˆ‡ç”¢å“çš„å¥‘åˆåº¦åˆ†æ)"
    }},
    "result": {{
        "score": (0-100 çš„è³¼è²·æ„åœ–åˆ†æ•¸),
        "summary": "(100å­—å…§çš„ç¹é«”ä¸­æ–‡ç¸½çµåˆ†æ)",
        "objections": [
            {{"reason": "(æ‹’çµ•ç†ç”±1)", "percentage": (ä½”æ¯”)}},
            {{"reason": "(æ‹’çµ•ç†ç”±2)", "percentage": (ä½”æ¯”)}}
        ],
        "suggestions": [
            {{
                "target": "(ç›®æ¨™æ—ç¾¤/æ ¼å±€)", 
                "advice": "(æ ¸å¿ƒç­–ç•¥å»ºè­°)",
                "execution_plan": ["æ­¥é©Ÿ1", "æ­¥é©Ÿ2", "æ­¥é©Ÿ3"],
                "score_improvement": "+(é æœŸæå‡åˆ†æ•¸ï¼Œå¦‚ 5~10åˆ†)"
            }},
            {{
                "target": "(ç›®æ¨™æ—ç¾¤/æ ¼å±€)", 
                "advice": "(å»ºè­°)",
                "execution_plan": ["æ­¥é©Ÿ1", "æ­¥é©Ÿ2", "æ­¥é©Ÿ3"],
                "score_improvement": "+(é æœŸæå‡åˆ†æ•¸)"
            }}
        ]
    }},
    "comments": [
        {{
            "citizen_id": (è«‹å¡«å…¥å°æ‡‰å¸‚æ°‘çš„ ID),
            "sentiment": "positive",
            "text": "(ä½¿ç”¨è©²å¸‚æ°‘å£å»ï¼Œæ ¹æ“šå…¶å…«å­—ã€è·æ¥­ã€å¹´é½¡å¯«å‡ºè©•è«–ï¼Œç¹é«”ä¸­æ–‡ï¼Œå£èªåŒ–ã€‚ä¾‹å¦‚é£Ÿç¥æ ¼é‡è¦–äº«å—ã€ä¸ƒæ®ºæ ¼è¬›ç©¶æ•ˆç‡ã€æ­£è²¡æ ¼é‡è¦–CPå€¼)"
        }},
        {{
            "citizen_id": (è«‹å¡«å…¥å°æ‡‰å¸‚æ°‘çš„ ID),
            "sentiment": "negative", 
            "text": "(...)"
        }},
        {{
            "citizen_id": (è«‹å¡«å…¥å°æ‡‰å¸‚æ°‘çš„ ID),
            "sentiment": "neutral",
            "text": "(...)"
        }}
        // è«‹å‹™å¿…ç”Ÿæˆ 8 å‰‡è©•è«–ï¼Œæ¶µè“‹ä¸åŒäº”è¡Œèˆ‡æ ¼å±€ï¼Œæ¯å‰‡è©•è«–éƒ½å¿…é ˆæ ¹æ“šè©²å¸‚æ°‘çš„å…«å­—ç‰¹è³ªæ’°å¯«
    ]
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **çµ•å°ä¸è¦** ç”Ÿæˆä¸¦æ²’æœ‰æä¾›çš„å¸‚æ°‘ IDã€‚
2. è©•è«–å…§å®¹è«‹å‹™å¿…çµåˆå¸‚æ°‘çš„**è·æ¥­**ã€**åœ°é»**èˆ‡**ç”Ÿæ´»æƒ…å¢ƒ**ã€‚
3. `simulation_metadata` ä¸­çš„åˆ†æè«‹åŸºæ–¼æ•´é«”å¸‚æ°‘æ¨£æœ¬ã€‚
4. **è‹¥æä¾›å»ºè­°å”®åƒ¹ï¼Œæ‰€æœ‰åˆ†æèˆ‡è©•è«–å¿…é ˆåš´æ ¼åŸºæ–¼è©²åƒ¹æ ¼ï¼Œä¸å¾—è‡ªè¡Œä¿®æ”¹ã€å››æ¨äº”å…¥æˆ–è‡†æ¸¬å…¶ä»–åƒ¹æ ¼ã€‚**
"""

            # 3. REST API Call
            api_key = settings.GOOGLE_API_KEY
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, image_b64)

            if ai_text is None:
                raise Exception(f"All models failed. {last_error}")

            print(f"RAW AI RESPONSE: {ai_text[:100]}...")

            # 4. Process Response
            data = self._clean_and_parse_json(ai_text)
            
            # 5. Build Result Data
            result_data = self._build_simulation_result(data, sampled_citizens, sim_metadata_override=data.get("simulation_metadata", {}))
            update_simulation(sim_id, "ready", result_data)
            print(f"âœ… [Core] Bazi-enriched AI æ•¸æ“šå·²å¯«å…¥ PostgreSQL: {sim_id}")

        except Exception as e:
            print(f"âŒ [Core] AI åˆ†æ/è§£æå¤±æ•—: {e}")
            error_msg = str(e)
            try:
                with open("last_error.txt", "w", encoding="utf-8") as f:
                    f.write(error_msg)
            except:
                pass
            self._handle_error_db(sim_id, error_msg)

    async def run_simulation_with_pdf_data(self, pdf_bytes, sim_id, file_name):
        """æ ¸å¿ƒ PDF åˆ†æé‚è¼¯ (Decoupled)"""
        try:
            # Convert PDF to base64
            pdf_b64 = base64.b64encode(pdf_bytes).decode('utf-8')
            
            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            sampled_citizens = get_random_citizens(sample_size=30)
            
            # ç°¡åŒ–å¸‚æ°‘è³‡æ–™
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "gender": c["gender"],
                    "location": c["location"],
                    "day_master": c["bazi_profile"].get("day_master", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "traits": c["traits"]
                }
                for c in sampled_citizens
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False, indent=2)
            
            # 3. Prompt
            prompt_text = f"""
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AIã€‚ä½ æ­£åœ¨å¯©é–±ä¸€ä»½å•†æ¥­è¨ˆåŠƒæ›¸ PDFã€‚

è«‹è®“ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ {len(sampled_citizens)} ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œé‡å°é€™ä»½å•†æ¥­è¨ˆåŠƒæ›¸é€²è¡Œã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€çš„æ¿€çƒˆè¾¯è«–ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "sample_size": {len(sampled_citizens)},
        "bazi_distribution": {{
            "Fire": (æ ¹æ“šä¸Šæ–¹å¸‚æ°‘çµ±è¨ˆçš„ç«è±¡ä½”æ¯” %),
            "Water": (æ°´è±¡ä½”æ¯” %),
            "Metal": (é‡‘è±¡ä½”æ¯” %),
            "Wood": (æœ¨è±¡ä½”æ¯” %),
            "Earth": (åœŸè±¡ä½”æ¯” %)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (æŒ‘é¸ 5-8 ä½ä»£è¡¨æ€§å¸‚æ°‘ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½)
            {{"id": "å¸‚æ°‘ID", "name": "å§“å", "age": "å¹´é½¡", "element": "äº”è¡Œå±¬æ€§(Fire/Water/Metal/Wood/Earth)", "day_master": "æ—¥ä¸»", "pattern": "æ ¼å±€", "trait": "æ€§æ ¼ç‰¹è³ª", "decision_logic": "è©²å¸‚æ°‘åŸºæ–¼å…«å­—çš„æŠ•è³‡/åˆä½œæ±ºç­–é‚è¼¯"}}
        ]
    }},
    "arena_comments": [
        (ç”Ÿæˆ 5-8 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è©•è«–)
        {{"sentiment": "positive/negative/neutral", "text": "å¸‚æ°‘ç™¼è¨€å…§å®¹ï¼ˆç¹é«”ä¸­æ–‡ï¼Œéœ€å¼•ç”¨å•†æ¥­è¨ˆåŠƒæ›¸å…·é«”å…§å®¹ï¼‰", "persona": {{"name": "å¸‚æ°‘å§“å", "pattern": "æ ¼å±€", "element": "äº”è¡Œ", "icon": "å°æ‡‰ emoji"}}}}
    ],
    "result": {{
        "score": (0-100 çš„å•†æ¥­å¯è¡Œæ€§åˆ†æ•¸),
        "market_sentiment": "(æ•´é«”å¸‚å ´æƒ…ç·’ï¼Œå¦‚ï¼šå¯©æ…æ¨‚è§€/é«˜åº¦æ‡·ç–‘/å¼·çƒˆçœ‹å¥½)",
        "summary": "(200å­—å…§çš„å•†æ¥­æ¨¡å¼å„ªåŠ£åˆ†æï¼ŒåŒ…å«ç²åˆ©æ¨¡å¼è©•ä¼°)",
        "objections": [
            {{"reason": "(å•†æ¥­æ¨¡å¼çš„ä¸»è¦è³ªç–‘é»)", "percentage": (è³ªç–‘æ¯”ä¾‹ %)}},
            {{"reason": "(è³ªç–‘é»2)", "percentage": %}},
            {{"reason": "(è³ªç–‘é»3)", "percentage": %}}
        ],
        "suggestions": [
            {{
                "target": "(ç›®æ¨™æŠ•è³‡è€…/åˆä½œå¤¥ä¼´é¡å‹)", 
                "advice": "(é‡å°è©²é¡å‹çš„æºé€šå»ºè­°)", 
                "element_focus": "(å°æ‡‰äº”è¡Œ)",
                "execution_plan": ["æ­¥é©Ÿ1", "æ­¥é©Ÿ2", "æ­¥é©Ÿ3"],
                "score_improvement": "+(é æœŸæå‡åˆ†æ•¸)"
            }},
            {{
                "target": "(é¡å‹2)", 
                "advice": "(å»ºè­°)",
                "execution_plan": ["æ­¥é©Ÿ1", "æ­¥é©Ÿ2"],
                "score_improvement": "+(é æœŸæå‡åˆ†æ•¸)"
            }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. é€™æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æï¼Œè«‹èšç„¦æ–¼ã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€
2. arena_comments è«‹ç”ŸæˆæŠ•è³‡è€…/å‰µæ¥­è€…è§’åº¦çš„è©•è«–
3. suggestions è«‹èšç„¦æ–¼å•†æ¥­æ¨¡å¼çš„å„ªåŒ–å»ºè­°
4. æ‰€æœ‰è©•è«–éƒ½éœ€å¼•ç”¨è¨ˆåŠƒæ›¸ä¸­çš„å…·é«”å…§å®¹
"""

            # 4. REST API Call
            api_key = settings.GOOGLE_API_KEY
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, pdf_b64=pdf_b64)

            if ai_text is None:
                raise Exception(f"All models failed for PDF. {last_error}")

            # 5. Process
            data = self._clean_and_parse_json(ai_text)
            
            # 6. Build Result Data
            sim_metadata = data.get("simulation_metadata", {})
            bazi_dist = sim_metadata.get("bazi_distribution", {"Fire": 20, "Water": 20, "Metal": 20, "Wood": 20, "Earth": 20})
            genesis_data = data.get("genesis", {})
            personas = genesis_data.get("personas", [])
            
            result_data = {
                "status": "ready",
                "score": data.get("result", {}).get("score", 50),
                "intent": data.get("result", {}).get("market_sentiment", "å¯©æ…è©•ä¼°ä¸­"),
                "summary": data.get("result", {}).get("summary", "å•†æ¥­æ¨¡å¼åˆ†æå®Œæˆã€‚"),
                "simulation_metadata": {
                    "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
                    "target_market": sim_metadata.get("target_market", "å°ç£"),
                    "sample_size": len(sampled_citizens),
                    "bazi_distribution": bazi_dist
                },
                "bazi_distribution": bazi_dist,
                "genesis": {
                    "total_population": 1000,
                    "sample_size": len(personas),
                    "personas": personas
                },
                "arena_comments": data.get("arena_comments", []),
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            update_simulation(sim_id, "ready", result_data)
            print(f"âœ… [Core PDF] å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æå·²å¯«å…¥ PostgreSQL: {sim_id}")

        except Exception as e:
            print(f"âŒ [Core PDF] åˆ†æå¤±æ•—: {e}")
            self._handle_error_db(sim_id, str(e))

    # ===== Helpers =====

    async def _call_gemini_rest(self, api_key, prompt, image_b64=None, pdf_b64=None):
        """Helper to call Gemini REST API"""
        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 8192,
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "image/jpeg", "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        models = [
        "gemini-2.0-flash-exp",
        "gemini-2.5-flash",
        "gemini-1.5-flash"
    ]
        
        last_error = ""
        for model in models:
            try:
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=60)
                if response.status_code == 200:
                    try:
                        return response.json()['candidates'][0]['content']['parts'][0]['text'], None
                    except:
                        continue
                else:
                    last_error = f"{model}: {response.status_code} {response.text}"
            except Exception as e:
                last_error = str(e)
        
        return None, last_error

    def _clean_and_parse_json(self, ai_text):
        """Helper to clean and parse JSON"""
        clean_text = ai_text
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", ai_text, re.DOTALL)
        if match:
            clean_text = match.group(1)
        
        try:
            return json.loads(clean_text)
        except json.JSONDecodeError:
            # Simple fix attempt
            fixed_text = clean_text.strip()
            if fixed_text.count('{') > fixed_text.count('}'): fixed_text += '}' * (fixed_text.count('{') - fixed_text.count('}'))
            if fixed_text.count('[') > fixed_text.count(']'): fixed_text += ']' * (fixed_text.count('[') - fixed_text.count(']'))
            try:
                return json.loads(fixed_text)
            except:
                # Return empty structure
                return {"result": {}, "arena_comments": [], "genesis": {}}

    def _build_simulation_result(self, data, sampled_citizens, sim_metadata_override=None):
        """Helper to build final result structure"""
        # Logic extracted from original code to build result_data
        # ... simplified for brevity as it copies logic ...
        
        # Reconstruct Bazi distribution
        element_counts = {"Fire": 0, "Water": 0, "Metal": 0, "Wood": 0, "Earth": 0}
        for c in sampled_citizens:
            elem = c["bazi_profile"].get("element", "Fire")
            if elem in element_counts: element_counts[elem] += 1
        total = len(sampled_citizens)
        bazi_dist = {k: round(v / total * 100) for k, v in element_counts.items()} if total else element_counts

        # Build Personas
        personas = [
            {
                "id": str(c["id"]),
                "name": c["name"],
                "age": c["age"],
                "location": c.get("location", "å°ç£"),
                "occupation": c.get("occupation", "æœªçŸ¥è·æ¥­"),
                "element": c["bazi_profile"].get("element", "Fire"),
                "day_master": c["bazi_profile"].get("day_master", ""),
                "pattern": c["bazi_profile"].get("structure", "æœªçŸ¥æ ¼å±€"),
                "trait": ", ".join(c["traits"][:2]) if c["traits"] else "å€‹æ€§é®®æ˜",
                "decision_logic": "æ ¹æ“šå…«å­—æ ¼å±€ç‰¹è³ªåˆ†æ",
                "current_luck": c["bazi_profile"].get("current_luck", {}),
                "luck_timeline": c["bazi_profile"].get("luck_timeline", [])
            }
            for c in sampled_citizens[:8]
        ]
        
        # Build comments
        gemini_comments = data.get("comments", [])
        arena_comments = []
        citizen_map = {c["id"]: c for c in sampled_citizens}
        
        for comment in gemini_comments:
            c_id = comment.get("citizen_id")
            citizen = citizen_map.get(c_id)
            if not citizen and isinstance(c_id, int) and 0 <= c_id < len(sampled_citizens):
                citizen = sampled_citizens[c_id]
            
            if citizen:
                bazi = citizen["bazi_profile"]
                arena_comments.append({
                    "sentiment": comment.get("sentiment", "neutral"),
                    "text": comment.get("text", "ï¼ˆç„¡è©•è«–å…§å®¹ï¼‰"),
                    "persona": {
                        "id": str(citizen["id"]),
                        "name": citizen["name"],
                        "age": str(citizen["age"]),
                        "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                        "element": bazi.get("element", "Fire"),
                        "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                        "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                        "location": citizen.get("location", "å°ç£"),
                        "birth_year": bazi.get("birth_year"),
                        "birth_month": bazi.get("birth_month"),
                        "birth_day": bazi.get("birth_day"),
                        "birth_shichen": bazi.get("birth_shichen"),
                        "four_pillars": bazi.get("four_pillars", ""),
                        "day_master": bazi.get("day_master", ""),
                        "strength": bazi.get("strength", "ä¸­å’Œ"),
                        "favorable": bazi.get("favorable", []),
                        "current_luck": bazi.get("current_luck", {}),
                        "luck_timeline": bazi.get("luck_timeline", [])
                    }
                })

        # Fallback comments if not enough (ensure at least 8)
        bazi_comment_templates = {
            "é£Ÿç¥æ ¼": ["é€™ç”¢å“çœ‹èµ·ä¾†æŒºæœ‰è³ªæ„Ÿçš„ï¼Œç”¨èµ·ä¾†æ‡‰è©²å¾ˆäº«å—~", "å“‡ï¼Œé€™å€‹è¨­è¨ˆè »æœ‰å“å‘³çš„ï¼Œå¾ˆé©åˆæ—¥å¸¸ä½¿ç”¨ï¼"],
            "å‚·å®˜æ ¼": ["è¨­è¨ˆé‚„ä¸éŒ¯ï¼Œä½†æˆ‘è¦ºå¾—å¯ä»¥æ›´æœ‰å‰µæ„ä¸€é»", "å—¯...æˆ‘æœ‰ä¸€äº›æ”¹é€²çš„æƒ³æ³•ï¼Œä¸éæ•´é«”é‚„è¡Œ"],
            "æ­£è²¡æ ¼": ["CPå€¼å¦‚ä½•ï¼Ÿæˆ‘æ¯”è¼ƒåœ¨æ„æ€§åƒ¹æ¯”", "åƒ¹æ ¼å’Œå“è³ªçš„å¹³è¡¡å¾ˆé‡è¦ï¼Œé€™å€‹çœ‹èµ·ä¾†é‚„å¯ä»¥"],
            "åè²¡æ ¼": ["æ„Ÿè¦ºæœ‰æ½›åŠ›ï¼å¯ä»¥è€ƒæ…®æŠ•è³‡çœ‹çœ‹", "é€™å€‹åˆ‡å…¥é»ä¸éŒ¯ï¼Œå•†æ©Ÿè »å¤§çš„"],
            "æ­£å®˜æ ¼": ["å“è³ªå’Œè¦æ ¼éƒ½ç¬¦åˆæ¨™æº–å—ï¼Ÿæˆ‘æ¯”è¼ƒè¬¹æ…", "éœ€è¦å¤šäº†è§£ä¸€ä¸‹ç´°ç¯€ï¼Œå†åšæ±ºå®š"],
            "ä¸ƒæ®ºæ ¼": ["æ•ˆç‡æ€éº¼æ¨£ï¼Ÿæˆ‘æ™‚é–“å¾ˆå¯¶è²´", "ç›´æ¥èªªé‡é»ï¼Œé€™å€‹èƒ½è§£æ±ºä»€éº¼å•é¡Œï¼Ÿ"],
            "æ­£å°æ ¼": ["é€™å°é•·æœŸç™¼å±•æœ‰å¹«åŠ©å—ï¼Ÿæˆ‘æ¯”è¼ƒçœ‹é‡é•·é åƒ¹å€¼", "å“ç‰Œä¿¡è­½å¾ˆé‡è¦ï¼Œé€™å€‹å…¬å¸å¯é å—ï¼Ÿ"],
            "åå°æ ¼": ["é€™å€‹æ¦‚å¿µæŒºç‰¹åˆ¥çš„ï¼Œè·Ÿå¸‚é¢ä¸Šçš„ä¸å¤ªä¸€æ¨£", "æœ‰é»æ„æ€ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šæ™‚é–“æ€è€ƒ"],
        }
        default_templates = ["é€™å€‹ç”¢å“çœ‹èµ·ä¾†ä¸éŒ¯ï¼", "åƒ¹æ ¼åˆç†ï¼Œæœƒè€ƒæ…®è³¼è²·ã€‚", "è¨­è¨ˆè »æœ‰ç‰¹è‰²çš„ã€‚", "æ•´é«”ä¾†èªªé‚„å¯ä»¥æ¥å—ã€‚"]
        
        while len(arena_comments) < 8 and sampled_citizens:
            # æ‰¾ä¸€å€‹é‚„æ²’è©•è«–éçš„å¸‚æ°‘
            commented_names = {c["persona"]["name"] for c in arena_comments}
            remaining = [c for c in sampled_citizens if c["name"] not in commented_names]
            if not remaining:
                break
            citizen = remaining[0]
            bazi = citizen["bazi_profile"]
            structure = bazi.get("structure", "")
            
            # æ ¹æ“šå…«å­—çµæ§‹é¸æ“‡è©•è«–æ¨¡æ¿
            templates = default_templates
            for pattern, texts in bazi_comment_templates.items():
                if pattern in structure:
                    templates = texts
                    break
            
            sentiment = ["positive", "neutral", "negative"][len(arena_comments) % 3]
            arena_comments.append({
                "sentiment": sentiment,
                "text": templates[len(arena_comments) % len(templates)],
                "persona": {
                    "id": str(citizen["id"]),
                    "name": citizen["name"],
                    "age": str(citizen["age"]),
                    "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                    "element": bazi.get("element", "Fire"),
                    "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                    "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                    "location": citizen.get("location", "å°ç£"),
                    "birth_year": bazi.get("birth_year"),
                    "birth_month": bazi.get("birth_month"),
                    "birth_day": bazi.get("birth_day"),
                    "birth_shichen": bazi.get("birth_shichen"),
                    "four_pillars": bazi.get("four_pillars", ""),
                    "day_master": bazi.get("day_master", ""),
                    "strength": bazi.get("strength", "ä¸­å’Œ"),
                    "favorable": bazi.get("favorable", []),
                    "current_luck": bazi.get("current_luck", {}),
                    "luck_timeline": bazi.get("luck_timeline", [])
                }
            })

        result_data = {
            "status": "ready",
            "score": data.get("result", {}).get("score", 75),
            "intent": data.get("result", {}).get("market_sentiment", "è¬¹æ…æ¨‚è§€"),
            "summary": data.get("result", {}).get("summary", "åˆ†æå®Œæˆ"),
            "simulation_metadata": {
                "product_category": sim_metadata_override.get("product_category", "æœªåˆ†é¡") if sim_metadata_override else "æœªåˆ†é¡",
                "sample_size": len(sampled_citizens),
                "bazi_distribution": bazi_dist
            },
            "bazi_distribution": bazi_dist,
            "genesis": {
                "total_population": 1000,
                "sample_size": len(personas),
                "personas": personas
            },
            "arena_comments": arena_comments,
            "objections": data.get("result", {}).get("objections", []),
            "suggestions": data.get("result", {}).get("suggestions", [])
        }
        return result_data

    def _handle_error_db(self, sim_id, error_msg):
        error_data = {
            "status": "error",
            "score": 0,
            "intent": "Error",
            "summary": f"ç³»çµ±éŒ¯èª¤: {error_msg}",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        update_simulation(sim_id, "error", error_data)

    def reply_text(self, reply_token, text):
        try:
            self.line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=text)]
                )
            )
        except Exception:
            pass

    async def generate_marketing_copy(self, image_bytes, product_name, price):
        """Web API å°ˆç”¨ï¼šç”Ÿæˆç”¢å“æ–‡æ¡ˆ"""
        try:
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            prompt = f"""è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦æ ¹æ“šæä¾›çš„è³‡è¨Šï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚

ç”¢å“åç¨±ï¼š{product_name}
å»ºè­°å”®åƒ¹ï¼š{price}

è«‹ä¸è¦åªå¯«ã€Œå„ªé›…ã€æˆ–ã€Œå¯¦ç”¨ã€é€™ç¨®ç©ºæ³›çš„å½¢å®¹è©ã€‚æˆ‘éœ€è¦ä½ èƒ½å¤ ï¼š
1. **æ·±åº¦è­˜åˆ¥**ï¼šå®Œå…¨ç†è§£å•†å“çš„æè³ªã€è¨­è¨ˆèªè¨€èˆ‡æ½›åœ¨å•†æ¥­åƒ¹å€¼ã€‚
2. **ç²¾æº–åŒ¹é…**ï¼šå…·é«”æŒ‡å‡ºé€™æ¬¾ç”¢å“æœ€é©åˆã€Œä»€éº¼æ¨£çš„äººã€ã€ã€Œåœ¨ä»€éº¼å ´åˆã€ã€ã€Œåšä»€éº¼äº‹ã€æ™‚ä½¿ç”¨ã€‚
3. **æ²‰æµ¸é«”é©—**ï¼šç”¨æ–‡å­—ç‡Ÿé€ å‡ºæ°›åœï¼Œè®“è§€çœ‹è€…å½·å½¿ç½®èº«å…¶ä¸­ï¼Œæ„Ÿå—åˆ°æ“æœ‰é€™ä»¶å•†å“å¾Œçš„ç¾å¥½ç”Ÿæ´»åœ–æ™¯ã€‚

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆç¹é«”ä¸­æ–‡ï¼Œæ¯æ®µç´„ 100-150 å­—ï¼‰ï¼š

ã€Aã€‘åˆ‡å…¥é»ä¸€ï¼šæƒ…æ„Ÿå…±é³´èˆ‡æ°›åœç‡Ÿé€  (Emotional & Atmospheric)
- å´é‡æ–¼æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨ç•¶ä¸‹çš„ç¾å¥½ç•«é¢ã€å¿ƒç†æ»¿è¶³æ„Ÿæˆ–è‡ªæˆ‘å±•ç¾ã€‚
- é©åˆæƒ³é€éç”¢å“æå‡ç”Ÿæ´»è³ªæ„Ÿæˆ–è¡¨é”å€‹æ€§çš„å®¢ç¾¤ã€‚

ã€Bã€‘åˆ‡å…¥é»äºŒï¼šç²¾æº–å ´æ™¯èˆ‡ç—›é»è§£æ±º (Scenario & Solution)
- å´é‡æ–¼ç†æ€§èˆ‡å ´æ™¯è¨´æ±‚ï¼Œå…·é«”æè¿°åœ¨å·¥ä½œã€ç¤¾äº¤æˆ–ç‰¹å®šæ´»å‹•ä¸­çš„å®Œç¾è¡¨ç¾ã€‚
- å³ä½¿æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œä¹Ÿè¦æè¿°å…¶å•†æ¥­æ¨¡å¼è½åœ°çš„å…·é«”å ´æ™¯èˆ‡è§£æ±ºçš„å¯¦éš›å•é¡Œã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdown æ¨™è¨˜ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
"""
            if not settings.GOOGLE_API_KEY:
                 return {"error": "å¾Œç«¯æœªè¨­å®š GOOGLE_API_KEY"}

            api_key = settings.GOOGLE_API_KEY
            # Run blocking request in thread pool
            ai_text, last_error = await asyncio.to_thread(self._run_blocking_gemini_request, api_key, prompt, image_b64)
            
            if ai_text:
                result = self._clean_and_parse_json(ai_text)
                # Combine title and description for easier usage
                option_a = result.get('description_a', '')
                option_b = result.get('description_b', '')
                return {"option_a": option_a, "option_b": option_b}
            else:
                return {"error": f"AI ç”Ÿæˆå¤±æ•—: {last_error}"}

        except Exception as e:
            print(f"[ERROR] generate_marketing_copy éŒ¯èª¤: {e}")
            return {"error": str(e)}

    def _run_blocking_gemini_request(self, api_key, prompt, image_b64=None, pdf_b64=None):
        """Helper to run synchronous requests in a thread"""
        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 8192,
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "image/jpeg", "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        models = [
            "gemini-2.0-flash-exp",
            "gemini-2.5-flash",
            "gemini-1.5-flash"
        ]
        
        last_error = ""
        for model in models:
            try:
                print(f"[AI] å˜—è©¦ä½¿ç”¨æ¨¡å‹: {model}...")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                # Reduced timeout to 30s
                response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=30)
                if response.status_code == 200:
                    try:
                        return response.json()['candidates'][0]['content']['parts'][0]['text'], None
                    except:
                        continue
                else:
                    error_msg = f"{model}: {response.status_code} {response.text}"
                    print(f"[AI] æ¨¡å‹ {model} å¤±æ•—: {error_msg}")
                    last_error = error_msg
            except Exception as e:
                last_error = str(e)
        
        return None, last_error