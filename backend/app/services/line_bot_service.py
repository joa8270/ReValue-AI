import asyncio
import io
import json
import random
import uuid
import re
import base64
import requests
import logging
from datetime import datetime, timedelta

# Create logger for this module
logger = logging.getLogger(__name__)
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    MessagingApiBlob,
    ReplyMessageRequest,
    TextMessage,
    PushMessageRequest
)
from app.core.config import settings
from app.core.database import create_simulation, update_simulation, get_simulation, get_random_citizens

# Alias for compatibility with main.py
get_simulation_data = get_simulation


def _generate_methodology_sidecar(score, summary):
    """
    ğŸ§¬ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–å¤–æ›å±¤ (Computational Social Science Sidecar)
    
    æ­¤å‡½æ•¸æ¡ç”¨ Sidecar Patternï¼Œåœ¨ä¸ä¿®æ”¹æ—¢æœ‰å…«å­—é‹ç®—é‚è¼¯çš„å‰æä¸‹ï¼Œ
    ç‚ºæ¨¡æ“¬çµæœæ·»åŠ ã€Œæ–¹æ³•è«–é©—è­‰ã€èˆ‡ã€Œç”¢å“è¿­ä»£å¾ªç’°ã€çš„è©®é‡‹å±¤ã€‚
    
    åŸºæ–¼ï¼š
    - ç¸±å‘ç ”ç©¶ (Longitudinal Study)ï¼šå¸‚å ´æœƒéš¨æ™‚é–“æ”¹è®Šï¼Œå ±å‘Šéœ€æœ‰æœ‰æ•ˆæœŸ
    - ç²¾å¯¦å‰µæ¥­ (Lean Startup)ï¼šæä¾›ä¸‹ä¸€æ­¥è¿­ä»£å»ºè­°ï¼ˆPivot/Scale/Persevereï¼‰
    - æ··åˆæ–¹æ³• (Mixed Methods)ï¼šé‡åŒ–åˆ†æ•¸ + è³ªæ€§æ‘˜è¦
    
    Args:
        score: å…«å­—é‹ç®—ç”¢ç”Ÿçš„è³¼è²·æ„åœ–åˆ†æ•¸ (0-100)
        summary: AI ç”Ÿæˆçš„åˆ†ææ‘˜è¦æ–‡å­—
    
    Returns:
        dict: æ–¹æ³•è«–è©®é‡‹æ•¸æ“šåŒ…ï¼ŒåŒ…å«æœ‰æ•ˆæœŸã€ä¿¡è³´å€é–“ã€ä¸‹ä¸€æ­¥å»ºè­°
    """
    # 1. [Lifecycle] è¨ˆç®—æœ‰æ•ˆæœŸ (æ¨¡æ“¬ç•¶å‰æ™‚é–“ + 28å¤©/ä¸€å€‹ç¯€æ°£)
    valid_until = (datetime.now() + timedelta(days=28)).strftime("%Y-%m-%d")
    
    # 2. [Methodology] è¨ˆç®—æ¨¡æ“¬ä¿¡è³´å€é–“ (95% CI)
    # é‚è¼¯ï¼šåŸºæ–¼åˆ†æ•¸åšå¾®å¹…éš¨æ©Ÿæ³¢å‹•ï¼Œæ¨¡æ“¬çµ±è¨ˆä¸ç¢ºå®šæ€§ (é€™æ˜¯è¨ˆç®—ç¤¾æœƒç§‘å­¸çš„ç‰¹å¾µ)
    # æ³¨æ„ï¼šscore å¯èƒ½æ˜¯ int æˆ– floatï¼Œè«‹ç¢ºä¿é‹ç®—æ­£å¸¸
    base_score = float(score) if score is not None else 0.0
    lower = max(0, base_score - random.uniform(2.0, 4.0))
    upper = min(100, base_score + random.uniform(2.0, 4.0))
    ci_text = f"95% CI [{lower:.1f}, {upper:.1f}]"

    # 3. [Iteration] ç”Ÿæˆä¸‹ä¸€æ­¥å»ºè­° (Actionable Advice)
    if base_score >= 80:
        next_step = {
            "action": "Scale", 
            "label": "ä¹˜å‹è¿½æ“Šï¼šæ“´å¤§æ¸¬è©¦ (Scale Up)", 
            "style": "bg-green-600 hover:bg-green-700", 
            "desc": "ä¿¡è™Ÿæ¥µå¼·ï¼å»ºè­°ç«‹å³æŠ•å…¥å»£å‘Šè³‡æºï¼Œé€²è¡Œ A/B æ¸¬è©¦ã€‚"
        }
    elif base_score >= 60:
        next_step = {
            "action": "Pivot", 
            "label": "å¾®èª¿ç­–ç•¥ï¼šè¿­ä»£å„ªåŒ– (Pivot)", 
            "style": "bg-amber-500 hover:bg-amber-600", 
            "desc": "æœ‰æ½›åŠ›ä½†é›œè¨Šå¤šã€‚å»ºè­°èª¿æ•´ã€Œå®šåƒ¹ã€æˆ–ã€Œæ–‡æ¡ˆã€å¾Œå†æ¸¬ä¸€æ¬¡ã€‚"
        }
    else:
        next_step = {
            "action": "Restart", 
            "label": "æ‰“æ‰é‡ç·´ï¼šé‡æ–°æ§‹æ€ (Restart)", 
            "style": "bg-red-500 hover:bg-red-600", 
            "desc": "å¸‚å ´åæ‡‰å†·æ·¡ã€‚å»ºè­°æ›´æ›ã€Œç›®æ¨™å®¢ç¾¤ã€æˆ–ã€Œç”¢å“å®šä½ã€ã€‚"
        }

    # ç‚ºäº†èˆ‡å‰ç«¯å°æ¥ï¼Œæˆ‘å€‘çµ±ä¸€ä½¿ç”¨ "methodology_data" ä½œç‚º Key
    return {
        "framework": "é›™è»Œæ¼”ç®—æ³•ï¼šè¡Œç‚ºç§‘å­¸ x å‘½ç†çµæ§‹",
        "valid_until": valid_until,
        "entropy_warning": "å¸‚å ´é¢¨å‘éš¨æ™‚åœ¨è®Šï¼Œå»ºè­°æ¯æœˆé‡æ–°æ ¡æº–ä¸€æ¬¡ã€‚",
        "confidence_interval": ci_text,
        "next_step": next_step,
        # å°‡åŸæœ¬çš„æ‘˜è¦æˆªå–ä½œç‚ºé©…å‹•åŠ›ç°¡ä»‹ï¼Œè‹¥ç„¡æ‘˜è¦å‰‡çµ¦é è¨­å€¼
        "drivers_summary": (summary[:60] + "...") if summary else "Key market drivers identified via grounded theory."
    }


class LineBotService:
    # In-memory session storage for user states
    user_session = {}
    
    def __init__(self):
        configuration = Configuration(access_token=settings.LINE_CHANNEL_ACCESS_TOKEN)
        self.api_client = ApiClient(configuration)
        self.line_bot_api = MessagingApi(self.api_client)
        self.line_bot_blob = MessagingApiBlob(self.api_client)

    async def handle_event(self, event):
        """
        é›™è»Œè¼¸å…¥æ©Ÿåˆ¶ (Dual-Track Input)
        - æƒ…å¢ƒ A: åœ–ç‰‡ (ImageMessage) â†’ æš«å­˜ä¸¦ç­‰å¾…è£œå……èªªæ˜
        - æƒ…å¢ƒ B: æ–‡å­— (TextMessage) â†’ æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        - æƒ…å¢ƒ C: æª”æ¡ˆ (FileMessage) â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸
        """
        user_id = event.source.user_id
        reply_token = event.reply_token
        message_type = event.message.type
        
        print(f"[EVENT] user_id={user_id}, type={message_type}")
        
        # ===== æƒ…å¢ƒ A: åœ–ç‰‡è¨Šæ¯ =====
        if message_type == "image":
            await self._handle_image_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ B: æ–‡å­—è¨Šæ¯ =====
        elif message_type == "text":
            await self._handle_text_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ C: æª”æ¡ˆè¨Šæ¯ (PDF) =====
        elif message_type == "file":
            await self._handle_file_message(event, user_id, reply_token)
            
        # ===== æƒ…å¢ƒ D: å½±ç‰‡è¨Šæ¯ (ä¸æ”¯æ´) =====
        elif message_type == "video":
            self.reply_text(reply_token, "âš ï¸ æŠ±æ­‰ï¼Œç›®å‰ç³»çµ±åƒ…æ”¯æ´ã€Œåœ–ç‰‡ã€é æ¼”ã€‚\n\nè«‹å°‡å½±ç‰‡ç•«é¢ **æˆªåœ–** å¾Œä¸Šå‚³ï¼Œå³å¯å•Ÿå‹•åˆ†æï¼ğŸ“¸")
        
        else:
            # ä¸æ”¯æ´çš„è¨Šæ¯é¡å‹
            self.reply_text(reply_token, "âš ï¸ æŠ±æ­‰ï¼Œæˆ‘ä¸æ”¯æ´æ­¤æ ¼å¼ã€‚\nè«‹ä¸Šå‚³åœ–ç‰‡ ğŸ“¸ æˆ– PDF å•†æ¥­è¨ˆåŠƒæ›¸ ğŸ“„")

    async def identify_product_from_image(self, image_bytes):
        """
        ä½¿ç”¨ AI è­˜åˆ¥åœ–ç‰‡ä¸­çš„ç”¢å“åç¨±èˆ‡åƒ¹æ ¼ (ç§»æ¤è‡ª web.py)
        """
        import time
        try:
            # 1. Image to Base64
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # Simple mime type detection
            if image_bytes.startswith(b'\x89PNG'): mime_type = "image/png"
            elif image_bytes.startswith(b'GIF8'): mime_type = "image/gif"
            elif image_bytes.startswith(b'RIFF') and image_bytes[8:12] == b'WEBP': mime_type = "image/webp"
            else: mime_type = "image/jpeg"

            prompt = """è«‹è§€å¯Ÿé€™å¼µç”¢å“åœ–ç‰‡ï¼Œå›ç­”ä»¥ä¸‹å•é¡Œï¼š
1. é€™å¼µåœ–ç‰‡ä¸­çš„ç”¢å“æ˜¯ä»€éº¼ï¼Ÿç”¨ç°¡çŸ­çš„ä¸­æ–‡æè¿°ï¼ˆ3-8å€‹å­—ï¼‰
2. æ ¹æ“šä½ å°å…¨çƒä¸»è¦é›»å•†å¹³å°ï¼ˆAmazonã€æ·˜å¯¶ã€è¦çš®ã€PChomeï¼‰ä¸ŠåŒé¡ç”¢å“çš„äº†è§£ï¼Œä¼°ç®—é€™é¡ç”¢å“çš„å¸‚å ´å¹³å‡å”®åƒ¹ï¼ˆæ–°å°å¹£ TWDï¼‰

è«‹ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›ç­”ï¼š
{
  "product_name": "ç”¢å“åç¨±",
  "estimated_price": æ•¸å­—ï¼ˆä¸å«è²¨å¹£ç¬¦è™Ÿï¼‰
}

åªå›ç­” JSONï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–èªªæ˜ã€‚"""

            # API Setup
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}, {"inline_data": {"mime_type": mime_type, "data": image_b64}}]}],
                "generationConfig": {"temperature": 0.3, "responseMimeType": "application/json"}
            }
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
            clean_text = ""
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ“¸ [Identify] Trying model: {model}")
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=20)
                    
                    if response.status_code == 200:
                        result = response.json()
                        raw_text = result['candidates'][0]['content']['parts'][0]['text']
                        clean_text = raw_text.replace('```json', '').replace('```', '').strip()
                        break
                    else:
                        print(f"âš ï¸ [Identify] Error {model}: {response.status_code}")
                except Exception as e:
                    print(f"âŒ [Identify] Exception {model}: {e}")
            
            if clean_text:
                # Parse JSON
                try:
                    data = json.loads(clean_text)
                except:
                    match = re.search(r'\{.*\}', clean_text, re.DOTALL)
                    data = json.loads(match.group()) if match else {}
                
                p_name = str(data.get("product_name", "")).strip()
                p_price = str(data.get("estimated_price", "")).strip()
                
                # Market Search Calibration (Lightweight)
                try:
                    from app.services.price_search import search_market_prices_sync
                    market_avg = search_market_prices_sync(p_name, p_price).get("avg_price")
                    if market_avg and market_avg > 0:
                        p_price = int(market_avg)
                except:
                    pass

                return p_name, p_price
                
        except Exception as e:
            print(f"âŒ Identification Failed: {e}")
        
        return None, None

    async def _handle_image_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ A: æ”¶åˆ°åœ–ç‰‡ â†’ æ”¯æ´å¤šåœ–ä¸Šå‚³ â†’ AI è­˜åˆ¥ â†’ ç¢ºèªæˆ–ä¿®æ”¹"""
        message_id = event.message.id
        
        # ä¸‹è¼‰åœ–ç‰‡ä¸¦æš«å­˜
        try:
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            
            # AI è‡ªå‹•è­˜åˆ¥
            self.reply_text(reply_token, "ğŸ” MIRRA æ­£åœ¨è§€å¯Ÿæ‚¨çš„åœ–ç‰‡ï¼Œè«‹ç¨å€™...")
            ai_name, ai_price = await self.identify_product_from_image(image_bytes)
            
            # åˆå§‹åŒ–æˆ–æ›´æ–° sessionï¼ˆæ”¯æ´å¤šåœ–ï¼‰
            if user_id not in self.user_session:
                self.user_session[user_id] = {}
            
            session = self.user_session[user_id]
            session["image_bytes"] = image_bytes  # æš«æ™‚ä¿ç•™èˆŠkeyå…¼å®¹æ€§
            session["images"] = [image_bytes]  # æ–°å¢ï¼šå¤šåœ–é™£åˆ—
            session["message_id"] = message_id
            session["stage"] = "waiting_for_name_confirmation"
            session["product_name"] = ai_name or ""
            session["product_price"] = ai_price or "æœªå®š"
            session["product_description"] = None
            session["generated_descriptions"] = None
            session["ai_copy_a"] = ""  # æ–°å¢ï¼šAI ç”Ÿæˆæ–‡æ¡ˆ A
            session["ai_copy_b"] = ""  # æ–°å¢ï¼šAI ç”Ÿæˆæ–‡æ¡ˆ B
            session["style"] = ""  # æ–°å¢ï¼šç”¨æˆ¶é¸æ“‡çš„é¢¨æ ¼
            session["market_prices"] = {}  # æ–°å¢ï¼šå¸‚å ´æ¯”åƒ¹è³‡æ–™
            
            print(f"ğŸ“¸ [SESSION] AI è­˜åˆ¥å®Œæˆ: {ai_name} / {ai_price}")
            
            # å›è¦†ç¢ºèªè¨Šæ¯
            confirm_msg = (
                f"ğŸ‘ï¸ **AI è¦–è¦ºåˆ†æçµæœ**\n\n"
                f"ğŸ“¦ ç”¢å“ï¼š{ai_name or 'æœªçŸ¥'}\n"
                f"ğŸ’° ä¼°åƒ¹ï¼š{ai_price or 'æœªçŸ¥'}\n\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"âœ… è‹¥è³‡æ–™æ­£ç¢ºï¼Œè«‹å›è¦†ã€Œ**Y**ã€\n"
                f"âœï¸ è‹¥éœ€ä¿®æ”¹ï¼Œè«‹ç›´æ¥è¼¸å…¥ã€Œ**åç¨± / å”®åƒ¹**ã€"
            )
            # Use push because we used reply_token for the "Analyzing..." message
            # logic check: reply_token can only be used once. 
            # So I should NOT have sent "Analyzing..." via reply_token if I want to send result via reply_token.
            # But identify takes time.
            # Strategy: use push_message for the result.
            self._push_text(user_id, confirm_msg)
            
        except Exception as e:
            print(f"âŒ [IMAGE] è™•ç†å¤±æ•—: {e}")
            self._push_text(user_id, "âŒ åœ–ç‰‡åˆ†æå¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def _handle_text_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ B: æ”¶åˆ°æ–‡å­— â†’ å¤šéšæ®µè™•ç†æµç¨‹"""
        text_content = event.message.text.strip()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        if user_id not in self.user_session:
            guide_msg = (
                "ğŸ”® **æ­¡è¿ä¾†åˆ° MIRRA é¡ç•Œ**\n\n"
                "ğŸ“¸ ä¸Šå‚³ **ç”¢å“åœ–ç‰‡** â†’ å•Ÿå‹•è³¼è²·æ„åœ–é æ¼” (AI è‡ªå‹•åˆ¤è®€)\n"
                "ğŸ“„ ä¸Šå‚³ **å•†æ¥­è¨ˆåŠƒæ›¸ PDF** â†’ å•Ÿå‹•å•†æ¥­æ¨¡å¼æ¨æ¼”\n\n"
                "è«‹é¸æ“‡æ‚¨çš„é æ¼”è»Œé“ã€‚"
            )
            self.reply_text(reply_token, guide_msg)
            return
        
        session = self.user_session[user_id]
        stage = session.get("stage")
        
        # ===== éšæ®µ 1: ç­‰å¾…åç¨±ç¢ºèªæˆ–ä¿®æ”¹ =====
        if stage == "waiting_for_name_confirmation" or stage == "waiting_for_name_price":
            # æª¢æŸ¥æ˜¯å¦ç‚ºç¢ºèªæŒ‡ä»¤
            if text_content.lower() in ["y", "yes", "ok", "æ˜¯", "æ­£ç¢º"]:
                # ä½¿ç”¨ AI è­˜åˆ¥çš„è³‡æ–™
                name = session.get("product_name") or "æœªå‘½åç”¢å“"
                price = session.get("product_price") or "æœªå®š"
            else:
                # è§£æã€Œåç¨± / å”®åƒ¹ã€æ‰‹å‹•è¼¸å…¥
                if "/" in text_content:
                    parts = text_content.split("/", 1)
                    name = parts[0].strip()
                    price = parts[1].strip() if len(parts) > 1 else "æœªå®š"
                else:
                    name = text_content
                    # ä¿ç•™åŸæœ¬ AI ä¼°ç®—çš„åƒ¹æ ¼ (å¦‚æœç”¨æˆ¶åªæ‰“äº†åç¨±)
                    price = session.get("product_price") or "æœªå®š"
            
            session["product_name"] = name
            session["product_price"] = price
            session["stage"] = "waiting_for_description_choice"
            
            print(f"ğŸ“ [SESSION] ç¢ºèªè³‡è¨Š: {name} / {price}")
            
            # è©¢å•æè¿°ä¾†æº
            choice_msg = (
                f"âœ… è³‡æ–™ç¢ºèªï¼š**{name}** / **{price}**\n\n"
                "æ¥ä¸‹ä¾†ï¼Œæ‚¨å¸Œæœ›å¦‚ä½•ç”Ÿæˆç”¢å“æè¿°ï¼Ÿ\n\n"
                "1ï¸âƒ£ å›è¦†ã€Œ**1**ã€â†’ æ‰‹å‹•è¼¸å…¥\n"
                "2ï¸âƒ£ å›è¦†ã€Œ**2**ã€â†’ AI è‡ªå‹•æ’°å¯«è¡ŒéŠ·æ–‡æ¡ˆ (æ¨è–¦âœ¨)\n"
                "3ï¸âƒ£ å›è¦†ã€Œ**3**ã€â†’ ç•¥éæ­¤æ­¥é©Ÿ"
            )
            self.reply_text(reply_token, choice_msg)
        
        # ===== éšæ®µ 2: ç­‰å¾…æè¿°é¸æ“‡ =====
        elif stage == "waiting_for_description_choice":
            if text_content == "1":
                # é¸æ“‡è‡ªè¡Œè¼¸å…¥
                session["stage"] = "waiting_for_manual_description"
                self.reply_text(reply_token, "ğŸ“ è«‹è¼¸å…¥æ‚¨çš„ç”¢å“æè¿°èˆ‡ç‰¹é»ï¼š")
            
            elif text_content == "2":
                # é¸æ“‡ AI ç”Ÿæˆ â†’ å…ˆè®“ç”¨æˆ¶é¸é¢¨æ ¼
                session["stage"] = "waiting_for_style_choice"
                style_msg = (
                    "ğŸ¨ **è«‹é¸æ“‡æ–‡æ¡ˆé¢¨æ ¼ï¼š**\n\n"
                    "1ï¸âƒ£ å°ˆæ¥­ç©©é‡ - æ­£å¼å•†å‹™é¢¨\n"
                    "2ï¸âƒ£ è¦ªåˆ‡æ´»æ½‘ - è¼•é¬†æœ‰è¶£é¢¨\n"
                    "3ï¸âƒ£ é«˜ç«¯å¥¢è¯ - ç²¾ç·»è³ªæ„Ÿé¢¨\n"
                    "4ï¸âƒ£ ç°¡ç´„æ¸…çˆ½ - é‡é»çªå‡ºé¢¨\n"
                    "5ï¸âƒ£ æ•…äº‹æ•˜è¿° - æƒ…å¢ƒä»£å…¥é¢¨\n\n"
                    "è«‹è¼¸å…¥ 1-5 é¸æ“‡é¢¨æ ¼"
                )
                self.reply_text(reply_token, style_msg)
            
            elif text_content.lower() in ["ç•¥é", "skip", "è·³é", "3"]:
                # ç›´æ¥é–‹å§‹åˆ†æ
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€Œ1ã€ã€ã€Œ2ã€æˆ–ã€Œç•¥éã€")
        
        # ===== éšæ®µ 2.5: ç­‰å¾…é¢¨æ ¼é¸æ“‡ =====
        elif stage == "waiting_for_style_choice":
            style_map = {
                "1": "professional",
                "2": "friendly", 
                "3": "luxury",
                "4": "minimalist",
                "5": "storytelling"
            }
            if text_content in style_map:
                session["selected_style"] = style_map[text_content]
                session["stage"] = "generating_descriptions"
                self.reply_text(reply_token, "ğŸ¤– AI æ­£åœ¨æ ¹æ“šåœ–ç‰‡ç”Ÿæˆæè¿°ï¼Œè«‹ç¨å€™...")
                await self._generate_ai_descriptions(user_id, reply_token)
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ 1-5 é¸æ“‡é¢¨æ ¼")
        
        # ===== éšæ®µ 3: ç­‰å¾…æ‰‹å‹•è¼¸å…¥æè¿° =====
        elif stage == "waiting_for_manual_description":
            session["product_description"] = text_content
            print(f"[SESSION] æ”¶åˆ°æ‰‹å‹•æè¿°: {text_content[:50]}...")
            await self._start_simulation(user_id, reply_token)
        
        # ===== éšæ®µ 4: ç­‰å¾…å–®ç¯‡æ–‡æ¡ˆç¢ºèª (æ–°æµç¨‹) =====
        elif stage == "waiting_for_copy_confirm":
            if text_content.lower() in ["y", "yes", "ok", "ç¢ºèª", "å¥½"]:
                # ä½¿ç”¨ AI ç”Ÿæˆçš„æ–‡æ¡ˆ
                print(f"[SESSION] ä½¿ç”¨è€…ç¢ºèªä½¿ç”¨ AI æ–‡æ¡ˆ")
                await self._start_simulation(user_id, reply_token)
            
            elif text_content.lower() in ["æ”¹", "é‡", "regenerate"]:
                # é‡æ–°ç”Ÿæˆ
                session["stage"] = "generating_descriptions"
                self.reply_text(reply_token, "ğŸ¤– æ­£åœ¨é‡æ–°ç”Ÿæˆæ–‡æ¡ˆï¼Œè«‹ç¨å€™...")
                await self._generate_ai_descriptions(user_id, reply_token)
            
            elif text_content.lower() in ["ç•¥", "skip", "è·³é", "ç•¥é"]:
                # è·³éæ–‡æ¡ˆ
                session["product_description"] = None
                print(f"[SESSION] ä½¿ç”¨è€…è·³éæ–‡æ¡ˆ")
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹å›è¦†ã€ŒYã€ç¢ºèªã€ã€Œæ”¹ã€é‡æ–°ç”Ÿæˆã€æˆ–ã€Œç•¥ã€è·³é")
        
        # ===== éšæ®µ 4 (èˆŠ): ç­‰å¾… A/B é¸æ“‡ (å‘å¾Œå…¼å®¹) =====
        elif stage == "waiting_for_ab_choice":
            descriptions = session.get("generated_descriptions", [])
            
            if text_content.upper() == "A" and len(descriptions) > 0:
                session["product_description"] = descriptions[0]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° A")
                await self._start_simulation(user_id, reply_token)
            
            elif text_content.upper() == "B" and len(descriptions) > 1:
                session["product_description"] = descriptions[1]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° B")
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€ŒAã€æˆ–ã€ŒBã€é¸æ“‡æè¿°")
        
        # ===== èˆŠæµç¨‹å…¼å®¹ï¼ˆwaiting_for_detailsï¼‰=====
        elif stage == "waiting_for_details":
            # èˆŠæµç¨‹ï¼šç›´æ¥ä½¿ç”¨æ–‡å­—ä½œç‚ºè£œå……èªªæ˜
            text_context = None if text_content.lower() in ["ç•¥é", "skip", "è·³é"] else text_content
            session["product_description"] = text_context
            await self._start_simulation(user_id, reply_token)
        
        else:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")

    async def _generate_ai_descriptions(self, user_id, reply_token):
        """ä½¿ç”¨ AI æ ¹æ“šåœ–ç‰‡+åç¨±+å”®åƒ¹ç”Ÿæˆå–®ç¯‡é«˜å“è³ªè¡ŒéŠ·æ–‡æ¡ˆ"""
        import time
        session = self.user_session.get(user_id)
        if not session:
            return
        
        image_bytes = session.get("image_bytes")
        product_name = session.get("product_name", "ç”¢å“")
        product_price = session.get("product_price", "æœªå®š")
        
        try:
            # 1. Image to Base64
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # Simple mime type detection
            if image_bytes.startswith(b'\x89PNG'): mime_type = "image/png"
            elif image_bytes.startswith(b'GIF8'): mime_type = "image/gif"
            elif image_bytes.startswith(b'RIFF') and image_bytes[8:12] == b'WEBP': mime_type = "image/webp"
            else: mime_type = "image/jpeg"
            
            # è®€å–ç”¨æˆ¶é¸æ“‡çš„é¢¨æ ¼
            selected_style = session.get("selected_style", "professional")
            style_instructions = {
                "professional": "**å¯«ä½œé¢¨æ ¼ï¼šå°ˆæ¥­ç©©é‡** - ä½¿ç”¨æ­£å¼ã€å°ˆæ¥­çš„å•†å‹™èªæ°£ï¼Œå¼·èª¿ç”¢å“çš„å¯é æ€§èˆ‡å“è³ªã€‚",
                "friendly": "**å¯«ä½œé¢¨æ ¼ï¼šè¦ªåˆ‡æ´»æ½‘** - ä½¿ç”¨è¼•é¬†ã€æœ‰è¶£çš„èªæ°£ï¼Œåƒæœ‹å‹æ¨è–¦å¥½ç‰©ä¸€æ¨£ï¼ŒåŠ å…¥ç”Ÿå‹•çš„å£èªè¡¨é”ã€‚",
                "luxury": "**å¯«ä½œé¢¨æ ¼ï¼šé«˜ç«¯å¥¢è¯** - ä½¿ç”¨ç²¾ç·»ã€å…¸é›…çš„èªæ°£ï¼Œå¼·èª¿ç”¢å“çš„ç¨ç‰¹æ€§èˆ‡é ‚ç´šé«”é©—ï¼Œç‡Ÿé€ å°Šè²´æ„Ÿã€‚",
                "minimalist": "**å¯«ä½œé¢¨æ ¼ï¼šç°¡ç´„æ¸…çˆ½** - ä½¿ç”¨ç°¡æ½”æœ‰åŠ›çš„èªè¨€ï¼Œç›´æ¥é»å‡ºæ ¸å¿ƒè³£é»ï¼Œä¸å†—é•·ä¸å›‰å—¦ã€‚",
                "storytelling": "**å¯«ä½œé¢¨æ ¼ï¼šæ•…äº‹æ•˜è¿°** - ç”¨ç¬¬ä¸€äººç¨±æˆ–æƒ…å¢ƒæ•…äº‹å¸¶å…¥ç”¢å“ï¼Œè®“è®€è€…å½·å½¿ç½®èº«å…¶ä¸­ã€‚"
            }
            style_prompt = style_instructions.get(selected_style, style_instructions["professional"])
            
            # å„ªåŒ– Promptï¼šä½¿ç”¨ GitHub åŸç‰ˆ A/B æ¶æ§‹ï¼ˆç¢ºä¿é«˜å“è³ªï¼‰
            prompt = f"""è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦æ ¹æ“šæä¾›çš„è³‡è¨Šï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚

ğŸ¨ **å¯«ä½œé¢¨æ ¼è¦æ±‚**ï¼š{style_prompt}

ç”¢å“åç¨±ï¼š{product_name}
å»ºè­°å”®åƒ¹ï¼š{product_price}

è«‹ä¸è¦åªå¯«ã€Œå„ªé›…ã€æˆ–ã€Œå¯¦ç”¨ã€é€™ç¨®ç©ºæ³›çš„å½¢å®¹è©ã€‚æˆ‘éœ€è¦ä½ èƒ½å¤ ï¼š
1. **æ·±åº¦è­˜åˆ¥**ï¼šå®Œå…¨ç†è§£å•†å“çš„æè³ªã€è¨­è¨ˆèªè¨€èˆ‡æ½›åœ¨å•†æ¥­åƒ¹å€¼ã€‚
2. **ç²¾æº–åŒ¹é…**ï¼šå…·é«”æŒ‡å‡ºé€™æ¬¾ç”¢å“æœ€é©åˆã€Œä»€éº¼æ¨£çš„äººã€ã€ã€Œåœ¨ä»€éº¼å ´åˆã€ã€ã€Œåšä»€éº¼äº‹ã€æ™‚ä½¿ç”¨ã€‚
3. **æ²‰æµ¸é«”é©—**ï¼šç”¨æ–‡å­—ç‡Ÿé€ å‡ºæ°›åœï¼Œè®“è§€çœ‹è€…å½·å½¿ç½®èº«å…¶ä¸­ï¼Œæ„Ÿå—åˆ°æ“æœ‰é€™ä»¶å•†å“å¾Œçš„ç¾å¥½ç”Ÿæ´»åœ–æ™¯ã€‚

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆç¹é«”ä¸­æ–‡ï¼Œæ¯æ®µç´„ 100-150 å­—ï¼‰ï¼š

ã€Aã€‘åˆ‡å…¥é»ä¸€ï¼šæƒ…æ„Ÿå…±é³´èˆ‡æ°›åœç‡Ÿé€  (Emotional & Atmospheric)
- å´é‡æ–¼æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨ç•¶ä¸‹çš„ç¾å¥½ç•«é¢ã€å¿ƒç†æ»¿è¶³æ„Ÿæˆ–è‡ªæˆ‘å±•ç¾ã€‚
- é©åˆæƒ³é€éç”¢å“æå‡ç”Ÿæ´»è³ªæ„Ÿæˆ–è¡¨é”å€‹æ€§çš„å®¢ç¾¤ã€‚

ã€Bã€‘åˆ‡å…¥é»äºŒï¼šç²¾æº–å ´æ™¯èˆ‡ç—›é»è§£æ±º (Scenario & Solution)
- å´é‡æ–¼ç†æ€§èˆ‡å ´æ™¯è¨´æ±‚ï¼Œå…·é«”æè¿°åœ¨å·¥ä½œã€ç¤¾äº¤æˆ–ç‰¹å®šæ´»å‹•ä¸­çš„å®Œç¾è¡¨ç¾ã€‚
- å³ä½¿æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œä¹Ÿè¦æè¿°å…¶å•†æ¥­æ¨¡å¼è½åœ°çš„å…·é«”å ´æ™¯èˆ‡è§£æ±ºçš„å¯¦éš›å•é¡Œã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdown æ¨™è¨˜ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
"""
            
            # API Setup - åŒæ­¥ GitHub è¨­å®š (8192 Tokens, 30s Timeout)
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}, {"inline_data": {"mime_type": mime_type, "data": image_b64}}]}],
                "generationConfig": {"maxOutputTokens": 8192, "temperature": 0.8, "responseMimeType": "application/json"}
            }
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
            ai_text = "{}"
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ“¸ [LINE Copywriting] Trying model: {model}")
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                    
                    if response.status_code == 200:
                        result = response.json()
                        raw_text = result['candidates'][0]['content']['parts'][0]['text']
                        if len(raw_text) > 50:
                            ai_text = raw_text
                            break
                    elif response.status_code == 429:
                        await asyncio.sleep(1)
                    else:
                        print(f"âš ï¸ [LINE Copywriting] Error {model}: {response.status_code}")
                except Exception as e:
                    print(f"âŒ [LINE Copywriting] Exception {model}: {e}")

            # Robust Parsing using helper
            data = self._clean_and_parse_json(ai_text)

            # æå–æ–‡æ¡ˆ
            desc_a = data.get("description_a", "")
            desc_b = data.get("description_b", "")
            
            # å„ªå…ˆä½¿ç”¨ Option A (ç¬¦åˆç”¨æˆ¶éœ€æ±‚)
            copy_content = desc_a if desc_a else desc_b
            copy_title = data.get("title_a", "âœ¨ å°ˆå±¬æ–‡æ¡ˆ")
            
            # é€™äº›æ¬„ä½æ–° Prompt æ²’æœ‰ï¼Œä½¿ç”¨é è¨­å€¼
            product_type = product_name
            target_audience = "è¿½æ±‚å“è³ªç”Ÿæ´»çš„æ‚¨"

            # Fallback
            if not copy_content:
                print(f"âš ï¸ Copywriting generation failed. Using default template.")
                copy_content = f"é€™æ¬¾{product_name}è¨­è¨ˆç²¾è‰¯ï¼Œæ˜¯è¿½æ±‚å“è³ªç”Ÿæ´»çš„æœ€ä½³é¸æ“‡ã€‚å”®åƒ¹ {product_price} å…ƒï¼Œç¾åœ¨æ­£æ˜¯å…¥æ‰‹çš„å¥½æ™‚æ©Ÿï¼"

            # å„²å­˜
            session["product_description"] = copy_content
            session["stage"] = "waiting_for_copy_confirm"
            
            # ç™¼é€ç¢ºèªè¨Šæ¯
            confirm_msg = (
                f"ğŸ”® **AI ç‚ºæ‚¨ç”Ÿæˆäº†è¡ŒéŠ·æ–‡æ¡ˆï¼š**\n\n"
                f"ğŸ“Œ ç”¢å“é¡å‹ï¼š{product_type}\n"
                f"ğŸ¯ ç›®æ¨™å®¢ç¾¤ï¼š{target_audience}\n\n"
                f"ã€{copy_title}ã€‘\n{copy_content}\n\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "âœ… å›è¦†ã€Œ**Y**ã€ä½¿ç”¨æ­¤æ–‡æ¡ˆ\n"
                "âœï¸ å›è¦†ã€Œ**æ”¹**ã€é‡æ–°ç”Ÿæˆ\n"
                "â­ï¸ å›è¦†ã€Œ**ç•¥**ã€è·³éæ–‡æ¡ˆ"
            )
            self._push_text(user_id, confirm_msg)

        except Exception as e:
            print(f"âŒ _generate_ai_descriptions éŒ¯èª¤: {e}")
            session["stage"] = "waiting_for_description_choice"

    async def refine_marketing_copy(self, comments: list[dict], product_name: str, price: str, original_copy: str, style: str = "professional", source_type: str = "image") -> dict:
        """æ ¹æ“š AI å¸‚æ°‘çš„è©•è«–ï¼ˆç‰¹åˆ¥æ˜¯è² è©•ï¼‰ï¼Œå„ªåŒ–ç¾æœ‰æ–‡æ¡ˆ"""
        print(f"âœ¨ Refine Copy with Style: {style}")
        import time
        try:
            # 1. ç¯©é¸è©•è«–
            # è² è©•ï¼šåˆ†æ•¸ < 60 æˆ–æƒ…ç·’ç‚º negative
            negative_comments = [c for c in comments if c.get('score', 0) < 60 or c.get('sentiment') == 'negative']
            if not negative_comments:
                # è‹¥ç„¡æ˜é¡¯è² è©•ï¼Œå–åˆ†æ•¸æœ€ä½çš„å‰ 20%
                sorted_comments = sorted(comments, key=lambda x: x.get('score', 100))
                negative_comments = sorted_comments[:max(1, int(len(comments) * 0.2))]
            
            # æ­£è©•ï¼šåˆ†æ•¸ > 80 æˆ–æƒ…ç·’ç‚º positive (ç”¨æ–¼ä¿ç•™å„ªé»)
            positive_comments = [c for c in comments if c.get('score', 0) > 80 or c.get('sentiment') == 'positive']
            
            # æå–è©•è«–æ–‡æœ¬
            neg_texts = "\n".join([f"- {c['text']}" for c in negative_comments[:10]]) # å–å‰ 10 æ¢
            pos_texts = "\n".join([f"- {c['text']}" for c in positive_comments[:5]])  # å–å‰ 5 æ¢ä½œç‚ºåƒè€ƒ
            
            print(f"ğŸ”„ [RefineCopy] Analyzing {len(negative_comments)} negative and {len(positive_comments)} positive comments.")


            # Mapping style to description
            style_desc = {
                "professional": "å°ˆæ¥­ç©©é‡ã€å•†å‹™æ„Ÿå¼·",
                "friendly": "è¦ªåˆ‡æ´»æ½‘ã€è¼•é¬†æœ‰è¶£",
                "luxury": "é«˜ç«¯å¥¢è¯ã€ç²¾ç·»è³ªæ„Ÿ",
                "minimalist": "ç°¡ç´„æ¸…çˆ½ã€é‡é»çªå‡º",
                "storytelling": "æ•…äº‹æ•˜è¿°ã€æƒ…å¢ƒä»£å…¥"
            }.get(style, "å°ˆæ¥­ç©©é‡")

            # 2. æ§‹å»º Prompt (å€åˆ† ç”¢å“ vs å•†æ¥­è¨ˆåŠƒ)
            if source_type == 'pdf' or source_type == 'txt':
                # Business Plan Mode: Only Strategy
                task_instruction = """
                2. **å„ªåŒ–å»ºè­° (Refined Strategy)**ï¼š
                   - é‡å°å•†æ¥­è¨ˆåŠƒæ›¸çš„ç›²é»ï¼Œæå‡ºå…·é«”çš„ä¿®æ­£æ–¹å‘èˆ‡è«–è¿°å„ªåŒ–å»ºè­°ã€‚
                   - èªæ°£ä¿æŒå°ˆæ¥­é¡§å•é¢¨æ ¼ã€‚
                """
                json_format = """
                {
                    "pain_points_summary": "ä¸»è¦ç–‘æ…®ç¸½çµ...",
                    "refined_copy": "é‡å°å•†æ¥­è¨ˆåŠƒçš„å„ªåŒ–å»ºè­°èˆ‡ä¿®æ­£è«–è¿°..."
                }
                """
            else:
                # Product Mode: Universal Dynamic Adaptation Architecture
                task_instruction = f"""
                2. **å‹•æ…‹é©é…ç­–ç•¥ (Dynamic Strategic Adaptation)**ï¼š
                   è«‹å…ˆåŸ·è¡Œä»¥ä¸‹ **ä¸‰æ­¥é©Ÿæ¨ç†**ï¼Œä¸è¦ç›´æ¥ç”Ÿæˆæ–‡æ¡ˆï¼š

                   **æ­¥é©Ÿ 1ï¼šç”¢å“å±¬æ€§è¨ºæ–· (Product DNA Profiling)**
                   - **è³¼è²·æ±ºç­–è€…**ï¼šæ˜¯ã€Œå€‹äºº (B2C)ã€é‚„æ˜¯ã€Œçµ„ç¹” (B2B)ã€ï¼Ÿ
                   - **åƒ¹å€¼ç¶­åº¦**ï¼šæ˜¯ã€Œå¯¦ç”¨åŠŸèƒ½ (Functional)ã€é‚„æ˜¯ã€Œæƒ…æ„Ÿç¤¾äº¤ (Emotional)ã€ï¼Ÿ

                   **æ­¥é©Ÿ 2ï¼šæºé€šç­–ç•¥é–å®š (Strategy Locking)**
                   - **æƒ…å¢ƒ A (å¤§çœ¾æ¶ˆè²» B2C)**ï¼šè‹¥ç‚ºå€‹äººäº«æ¨‚/ä½å–®åƒ¹ -> é—œéµå­—ï¼šå°ç¢ºå¹¸ã€ç™‚ç™’ã€é¡å€¼ã€CPå€¼ã€‚**ç¦èª**ï¼šä¼æ¥­è³¦èƒ½ã€è§£æ±ºæ–¹æ¡ˆã€åº•å±¤é‚è¼¯ã€‚
                   - **æƒ…å¢ƒ B (é«˜åƒ¹/æˆ¿ç”¢ B2C)**ï¼šè‹¥ç‚ºé«˜å–®åƒ¹/èº«ä»½è±¡å¾µ -> é—œéµå­—ï¼šç”Ÿæ´»é¢¨æ ¼ (Lifestyle)ã€ç¨€ç¼ºæ€§ã€åƒ¹å€¼ã€é•·æ•ˆæŠ•è³‡ã€‚
                   - **æƒ…å¢ƒ C (ä¼æ¥­å·¥å…· B2B)**ï¼šè‹¥ç‚ºå•†æ¥­å·¥å…· -> é—œéµå­—ï¼šROIã€æ•ˆç‡ã€é™æœ¬å¢æ•ˆã€ç«¶çˆ­åŠ›ã€‚èªæ°£ï¼šå°ˆæ¥­æ•¸æ“šå°å‘ã€‚

                   **æ­¥é©Ÿ 3ï¼šç—›é»è½‰åŒ– (Pain Point Translation - Magic Formula)**
                   - è¢«ç½µã€Œæ²’ç”¨ã€-> è½‰è­¯ç‚º **ã€Œç„¡ç”¨ä¹‹ç”¨çš„æƒ…ç·’åƒ¹å€¼ã€** (ä¾‹ï¼šé›–ç„¶ä¸èƒ½åƒï¼Œä½†çœ‹è‘—å¿ƒæƒ…å¥½)ã€‚
                   - è¢«ç½µã€Œå¤ªè²´ã€-> è½‰è­¯ç‚º **ã€Œå¹³å‡æ¯å¤©åªéœ€ X å…ƒçš„é•·æ•ˆæŠ•è³‡ã€** (å°‡åƒ¹æ ¼é™¤ä»¥ä½¿ç”¨å¤©æ•¸)ã€‚
                   - è¢«ç½µã€Œå¤ªé†œã€-> è½‰è­¯ç‚º **ã€Œç¨ç‰¹é†œèŒç¾å­¸ã€** æˆ– **ã€Œç¡¬æ´¾å¯¦ç”¨ä¸»ç¾©ã€**ã€‚

                3. **å¯¦æˆ°æ–‡æ¡ˆ (Ready-to-Post Copy)**ï¼š
                   - æ ¹æ“šä¸Šè¿°é–å®šçš„ç­–ç•¥ï¼Œæ’°å¯« 3 å‰‡é©åˆè©²å®¢ç¾¤å¹³å° (IG/Shopee/LinkedIn) çš„çˆ†æ¬¾çŸ­æ–‡æ¡ˆã€‚
                   - **æ ¼å¼è¦æ±‚**ï¼š
                     - è«‹è¿”å›æ­£å¸¸çš„ JSON é™£åˆ—æ ¼å¼ï¼ŒåŒ…å« `title`, `body`, `hashtags`ã€‚
                     - è«‹ç¢ºä¿ Emoji è±å¯Œä¸”èªæ°£è‡ªç„¶ã€‚
                   - **è‡ªæˆ‘æª¢æ¸¬ (Self-Correction)**ï¼š
                     - è‹¥åˆ¤æ–·ç‚º B2Cï¼Œåš´ç¦å‡ºç¾ã€Œæå‡åœ˜éšŠæ•ˆç‡ã€ç­‰ B2B è©å½™ã€‚
                """
                json_format = """
                {
                    "strategy_rationale": "...",
                    "pain_points_summary": "...",
                    "refined_copy": "...",
                    "marketing_copy": [
                        {"title": "...", "body": "...", "hashtags": "..."},
                        {"title": "...", "body": "...", "hashtags": "..."}
                    ]
                }
                """

            prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šå¸‚å ´åé¥‹çš„æ–‡æ¡ˆå„ªåŒ–å°ˆå®¶ã€‚
ç”¢å“ï¼š{product_name} | åƒ¹æ ¼ï¼š{price}
åŸå§‹æ–‡æ¡ˆï¼š{original_copy}

ã€å¸‚å ´è² é¢åé¥‹ã€‘
{neg_texts}

ã€å¸‚å ´æ­£é¢åé¥‹ã€‘
{pos_texts}

ã€ä»»å‹™ã€‘
1. **åˆ†æç—›é»**ï¼šç¸½çµ 3 å€‹ä¸»è¦æŠ—æ‹’é»ã€‚
{task_instruction}

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼š
{json_format}
"""



            # 3. Call Gemini API
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"maxOutputTokens": 8192, "temperature": 0.7, "responseMimeType": "application/json"}
            }
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash"]
            ai_text = "{}"
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ”„ [RefineCopy] Trying model: {model}")
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                    if response.status_code == 200:
                        result = response.json()
                        ai_text = result['candidates'][0]['content']['parts'][0]['text']
                        break
                except Exception as e:
                    print(f"âŒ [RefineCopy] Error {model}: {e}")

            # 4. Parse Result
            print(f"DEBUG: AI Raw Response: {ai_text}") # Log raw response
            data = self._clean_and_parse_json(ai_text)
            print(f"DEBUG: Parsed Data: {data}") # Log parsed data

            # Force Format Formatting for 'marketing_copy'
            marketing_copy_raw = data.get("marketing_copy")
            formatted_copy = ""

            if isinstance(marketing_copy_raw, list):
                # Clean up structured JSON into the user-requested Plain Text format
                formatted_pieces = []
                for idx, item in enumerate(marketing_copy_raw):
                    if isinstance(item, dict):
                        title = item.get("title", "")
                        body = item.get("body", "")
                        tags = item.get("hashtags", "")
                        # Construct the text block
                        block = f"ã€æ–‡æ¡ˆ {idx+1}ã€‘{title}\n\n{body}\n\n{tags}"
                        formatted_pieces.append(block)
                    elif isinstance(item, str):
                        formatted_pieces.append(item)
                
                formatted_copy = "\n\n---\n\n".join(formatted_pieces)
                data["marketing_copy"] = formatted_copy # Overwrite with plain text
                print(f"âœ… [SmartFormat] Converted JSON List to Plain Text:\n{formatted_copy[:100]}...")

            elif isinstance(marketing_copy_raw, str):
                # Ensure it's not a stringified JSON
                if marketing_copy_raw.strip().startswith("[") and marketing_copy_raw.strip().endswith("]"):
                    import json
                    try:
                        parsed_list = json.loads(marketing_copy_raw)
                        if isinstance(parsed_list, list):
                            formatted_pieces = []
                            for idx, item in enumerate(parsed_list):
                                if isinstance(item, dict):
                                    title = item.get("title", "")
                                    body = item.get("body", "")
                                    tags = item.get("hashtags", "")
                                    block = f"ã€æ–‡æ¡ˆ {idx+1}ã€‘{title}\n\n{body}\n\n{tags}"
                                    formatted_pieces.append(block)
                            formatted_copy = "\n\n---\n\n".join(formatted_pieces)
                            data["marketing_copy"] = formatted_copy
                            print(f"âœ… [SmartFormat] Converted Stringified JSON to Plain Text")
                    except:
                        pass # Keep as is if parsing fails
            
            final_refined = data.get("refined_copy", original_copy)
            


            if not final_refined:
                print("WARNING: Refined copy is empty, checking original...")
                final_refined = original_copy or "ç„¡æ³•å„ªåŒ–æ–‡æ¡ˆï¼Œè«‹æª¢æŸ¥åŸå§‹è³‡æ–™ã€‚"

            return {
                "success": True,
                "pain_points": data.get("pain_points_summary", "åˆ†æä¸­..."),
                "refined_copy": str(final_refined),
                "marketing_copy": data.get("marketing_copy", "") 
            }


        except Exception as e:
            print(f"âŒ refine_marketing_copy Exception: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e), "refined_copy": original_copy}
            self._push_text(user_id, "âŒ AI ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç›´æ¥è¼¸å…¥ã€Œ**1**ã€è‡ªè¡Œè¼¸å…¥æè¿°")

    def _clean_and_parse_json(self, ai_text):
        """Helper to clean and parse JSON with robust error handling (From GitHub Original)"""
        if not ai_text or not isinstance(ai_text, str):
            return {}

        clean_text = ai_text
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", ai_text, re.DOTALL)
        if match:
            clean_text = match.group(1)
        
        try:
            data = json.loads(clean_text)
            if isinstance(data, dict):
                return data
            return {}
        except json.JSONDecodeError:
            # Simple fix attempt for truncated JSON
            fixed_text = clean_text.strip()
            # Try to close open braces/brackets
            open_braces = fixed_text.count('{') - fixed_text.count('}')
            if open_braces > 0: fixed_text += '}' * open_braces
            
            open_brackets = fixed_text.count('[') - fixed_text.count(']')
            if open_brackets > 0: fixed_text += ']' * open_brackets
            
            # Remove trailing commas before closing braces (common issue)
            fixed_text = re.sub(r',\s*([}\]])', r'\1', fixed_text)

            try:
                data = json.loads(fixed_text)
                if isinstance(data, dict):
                    return data
                return {}
            except:
                print(f"âš ï¸ Failed to parse AI JSON after cleaning: {clean_text[:50]}...")
                return {}

    async def generate_marketing_copy(self, image_data_input, product_name: str, price: str, style: str = "professional", language: str = "zh-TW"):
        """
        ç¶²é ç«¯ API ä½¿ç”¨ï¼šæ ¹æ“šåœ–ç‰‡ï¼ˆå–®å¼µæˆ–å¤šå¼µï¼‰ç”Ÿæˆè¡ŒéŠ·æ–‡æ¡ˆ
        ä½¿ç”¨ GitHub åŸç‰ˆ A/B Promptï¼ˆå“è³ªæ›´å¥½ï¼‰ï¼Œä½†åªè¿”å›å…¶ä¸­ä¸€æ®µ
        æ”¯æ´å¤šèªè¨€ï¼šzh-TWï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€zh-CNï¼ˆç°¡é«”ä¸­æ–‡ï¼‰ã€enï¼ˆè‹±æ–‡ï¼‰
        """
        try:
            # 1. Process Images (List or Single)
            image_bytes_list = image_data_input if isinstance(image_data_input, list) else [image_data_input]
            image_parts = []
            
            for idx, img_bytes in enumerate(image_bytes_list):
                 # Auto-detect mime type
                if img_bytes.startswith(b'\x89PNG'): mime_type = "image/png"
                elif img_bytes.startswith(b'GIF8'): mime_type = "image/gif"
                elif img_bytes.startswith(b'RIFF') and img_bytes[8:12] == b'WEBP': mime_type = "image/webp"
                else: mime_type = "image/jpeg"
                
                img_b64 = base64.b64encode(img_bytes).decode('utf-8')
                image_parts.append({"inline_data": {"mime_type": mime_type, "data": img_b64}})
            
            print(f"ğŸ“¸ [Web Copywriting] Processing {len(image_parts)} images, language={language}...")
            
            # å¤šèªè¨€é¢¨æ ¼æŒ‡ä»¤
            style_prompts_by_lang = {
                "zh-TW": {
                    "professional": "è«‹ä½¿ç”¨**å°ˆæ¥­ç©©é‡**çš„å•†å‹™é¢¨æ ¼ã€‚ç”¨è©æ­£å¼ï¼Œå¼·èª¿ç”¢å“çš„æŠ€è¡“è¦æ ¼ã€æ•¸æ“šèˆ‡å¯é æ€§ï¼Œé©åˆ B2B æˆ–è¿½æ±‚æ•ˆèƒ½çš„å°ˆæ¥­äººå£«ã€‚",
                    "friendly": "è«‹ä½¿ç”¨**è¦ªåˆ‡æ´»æ½‘**çš„è¼•é¬†é¢¨æ ¼ã€‚åƒè·Ÿæœ‹å‹èŠå¤©ä¸€æ¨£ï¼Œä½†ä¹Ÿè¦æ¸…æ¥šä»‹ç´¹ç”¢å“çš„æ ¸å¿ƒè¦æ ¼ï¼ˆå¦‚è—ç‰™ã€çºŒèˆªï¼‰ï¼Œåˆ¥è®“è®€è€…è¦ºå¾—æ²’å…§å®¹ã€‚",
                    "luxury": "è«‹ä½¿ç”¨**é«˜ç«¯å¥¢è¯**çš„å“ç‰Œé¢¨æ ¼ã€‚ç”¨è©è¬›ç©¶ã€å¯Œæœ‰è³ªæ„Ÿï¼Œä¸¦å°‡æŠ€è¡“è¦æ ¼è½‰åŒ–ç‚ºå°Šè²´é«”é©—çš„æè¿°ï¼ˆä¾‹å¦‚ï¼šç„¡ç·šé€£æ¥å¸¶ä¾†çš„ç„¡æ‹˜ç„¡æŸï¼‰ã€‚",
                    "minimalist": "è«‹ä½¿ç”¨**ç°¡ç´„æ¸…çˆ½**çš„æ¥µç°¡é¢¨æ ¼ã€‚å¥å­ç²¾ç…‰æœ‰åŠ›ï¼Œç›´æ¥åˆ—å‡ºæ ¸å¿ƒè¦æ ¼æ•¸æ“šï¼Œå»é™¤å†—é¤˜å½¢å®¹è©ã€‚",
                    "storytelling": "è«‹ä½¿ç”¨**æ•…äº‹æ•˜è¿°**çš„æƒ…å¢ƒé¢¨æ ¼ã€‚åœ¨æ•…äº‹ä¸­è‡ªç„¶å¸¶å‡ºç”¢å“çš„è¦æ ¼å„ªå‹¢ï¼ˆå¦‚ï¼šä¸ç”¨æ“”å¿ƒæ²’é›»ï¼Œå› ç‚ºå®ƒæœ‰è¶…é•·çºŒèˆª...ï¼‰ã€‚"
                },
                "zh-CN": {
                    "professional": "è¯·ä½¿ç”¨**ä¸“ä¸šç¨³é‡**çš„å•†åŠ¡é£æ ¼ã€‚ç”¨è¯æ­£å¼ï¼Œå¼ºè°ƒäº§å“çš„æŠ€æœ¯è§„æ ¼ã€æ•°æ®ä¸å¯é æ€§ï¼Œé€‚åˆ B2B æˆ–è¿½æ±‚æ•ˆèƒ½çš„ä¸“ä¸šäººå£«ã€‚",
                    "friendly": "è¯·ä½¿ç”¨**äº²åˆ‡æ´»æ³¼**çš„è½»æ¾é£æ ¼ã€‚åƒè·Ÿæœ‹å‹èŠå¤©ä¸€æ ·ï¼Œä½†ä¹Ÿè¦æ¸…æ¥šä»‹ç»äº§å“çš„æ ¸å¿ƒè§„æ ¼ï¼ˆå¦‚è“ç‰™ã€ç»­èˆªï¼‰ï¼Œåˆ«è®©è¯»è€…è§‰å¾—æ²¡å†…å®¹ã€‚",
                    "luxury": "è¯·ä½¿ç”¨**é«˜ç«¯å¥¢å**çš„å“ç‰Œé£æ ¼ã€‚ç”¨è¯è®²ç©¶ã€å¯Œæœ‰è´¨æ„Ÿï¼Œå¹¶å°†æŠ€æœ¯è§„æ ¼è½¬åŒ–ä¸ºå°Šè´µä½“éªŒçš„æè¿°ï¼ˆä¾‹å¦‚ï¼šæ— çº¿è¿æ¥å¸¦æ¥çš„æ— æ‹˜æ— æŸï¼‰ã€‚",
                    "minimalist": "è¯·ä½¿ç”¨**ç®€çº¦æ¸…çˆ½**çš„æç®€é£æ ¼ã€‚å¥å­ç²¾ç‚¼æœ‰åŠ›ï¼Œç›´æ¥åˆ—å‡ºæ ¸å¿ƒè§„æ ¼æ•°æ®ï¼Œå»é™¤å†—ä½™å½¢å®¹è¯ã€‚",
                    "storytelling": "è¯·ä½¿ç”¨**æ•…äº‹å™è¿°**çš„æƒ…å¢ƒé£æ ¼ã€‚åœ¨æ•…äº‹ä¸­è‡ªç„¶å¸¦å‡ºäº§å“çš„è§„æ ¼ä¼˜åŠ¿ï¼ˆå¦‚ï¼šä¸ç”¨æ‹…å¿ƒæ²¡ç”µï¼Œå› ä¸ºå®ƒæœ‰è¶…é•¿ç»­èˆª...ï¼‰ã€‚"
                },
                "en": {
                    "professional": "Please use a **professional and steady** business style. Use formal language, emphasizing technical specifications, data, and reliability. Suitable for B2B or professional audiences.",
                    "friendly": "Please use a **friendly and lively** casual style. Write as if chatting with a friend, but clearly introduce core specs (like Bluetooth, battery life).",
                    "luxury": "Please use a **high-end luxury** brand style. Use refined, textured language, transforming technical specs into premium experience descriptions.",
                    "minimalist": "Please use a **minimalist and clean** style. Sentences should be concise and powerful, directly listing core specs without redundant adjectives.",
                    "storytelling": "Please use a **storytelling** scenario style. Naturally bring out product advantages within the story narrative."
                }
            }
            
            lang_styles = style_prompts_by_lang.get(language, style_prompts_by_lang["zh-TW"])
            style_instruction = lang_styles.get(style, lang_styles["professional"])
            
            # 2. æœå°‹ç”¢å“è¦æ ¼ (New Feature)
            product_specs = ""
            if product_name and product_name != "ç”¢å“" and product_name != "æœªå‘½åç”¢å“":
                 try:
                     from app.services.price_search import search_product_specs_sync
                     print(f"ğŸ” [Web Copywriting] Searching specs for: {product_name}...")
                     product_specs = search_product_specs_sync(product_name)
                     print(f"ğŸ” [Web Copywriting] Specs length: {len(product_specs)}")
                 except Exception as e:
                     print(f"âš ï¸ Spec search failed: {e}")

            # ä½¿ç”¨ GitHub åŸç‰ˆ Promptï¼ˆA/B æ ¼å¼ï¼‰ä¸¦åŠ å…¥è¦æ ¼è³‡è¨Š
            # æ ¹æ“šåœ–ç‰‡æ•¸é‡èª¿æ•´ prompt
            multi_image_instruction = ""
            if len(image_parts) > 1:
                multi_image_instruction = f"""
ğŸ“¸ **å¤šåœ–åˆ†ææŒ‡å¼•** (å…± {len(image_parts)} å¼µåœ–ç‰‡)ï¼š
ç”¨æˆ¶ä¸Šå‚³äº†å¤šå¼µåœ–ç‰‡ï¼Œé€™ä»£è¡¨ä»–å€‘å¸Œæœ›ä½ èƒ½å¤ ï¼š
1. **è­˜åˆ¥æ¯å¼µåœ–ç‰‡çš„è¦–è§’èˆ‡ç”¨é€”**ï¼š
   - å¯èƒ½æ˜¯ç”¢å“çš„ä¸åŒè§’åº¦ï¼ˆæ­£é¢ã€å´é¢ã€èƒŒé¢ã€ä¿¯è¦–ã€ç´°ç¯€ç‰¹å¯«ï¼‰
   - å¯èƒ½æ˜¯ä½¿ç”¨æƒ…å¢ƒå±•ç¤ºã€åŒ…è£å±•ç¤ºã€é…ä»¶å±•ç¤º
   - å¯èƒ½æ˜¯é¡è‰²/æ¬¾å¼è®ŠåŒ–
   
2. **æ•´åˆå¤šè¦–è§’è³‡è¨Š**ï¼š
   - è«‹å…ˆåœ¨å¿ƒä¸­åˆ†ææ¯å¼µåœ–ç‰‡åˆ†åˆ¥å±•ç¤ºäº†ä»€éº¼
   - æ‰¾å‡ºåœ–ç‰‡ä¹‹é–“çš„é—œè¯æ€§èˆ‡äº’è£œæ€§
   - ä¸è¦éºæ¼ä»»ä½•ä¸€å¼µåœ–ç‰‡ä¸­çš„é—œéµè³‡è¨Š
   
3. **åœ¨æ–‡æ¡ˆä¸­æ˜ç¢ºé«”ç¾å¤šè¦–è§’åˆ†æ**ï¼š
   - **å‹™å¿…åœ¨æ–‡æ¡ˆä¸­æåŠä½ å·²è§€å¯Ÿå¤šå€‹è§’åº¦/è¦–è§’**ï¼ˆä¾‹å¦‚ï¼šã€Œå¾æ­£é¢åˆ°å´é¢ã€ã€ã€Œå„å€‹è§’åº¦ã€ã€ã€Œç´°ç¯€è™•ã€ã€ã€Œç„¡è«–å¾å“ªå€‹è¦–è§’ã€ç­‰ï¼‰
   - åœ¨æ–‡æ¡ˆä¸­è‡ªç„¶èå…¥å¾ä¸åŒåœ–ç‰‡ä¸­è§€å¯Ÿåˆ°çš„ç‰¹é»
   - å¦‚æœæœ‰ç´°ç¯€åœ–ï¼Œè«‹å¼·èª¿è©²ç´°ç¯€çš„è¨­è¨ˆå·§æ€æˆ–æŠ€è¡“äº®é»
   - å¦‚æœæœ‰ä½¿ç”¨æƒ…å¢ƒåœ–ï¼Œè«‹æè¿°è©²æƒ…å¢ƒçš„é«”é©—æ„Ÿå—
   - **è®“è®€è€…èƒ½æ„Ÿå—åˆ°é€™ä»½æ–‡æ¡ˆæ˜¯åŸºæ–¼å°ç”¢å“å…¨æ–¹ä½è§€å¯Ÿå¾Œçš„ç¶œåˆæè¿°**
   
âš ï¸ **å¼·åˆ¶è¦æ±‚**ï¼šç”±æ–¼ç”¨æˆ¶ä¸Šå‚³äº† {len(image_parts)} å¼µåœ–ç‰‡ï¼Œä½ çš„æ–‡æ¡ˆä¸­**å¿…é ˆ**åŒ…å«èƒ½é«”ç¾ã€Œå¤šè¦–è§’åˆ†æã€çš„æªè¾­ï¼Œä¾‹å¦‚ï¼š
   - ã€Œå¾å„å€‹è§’åº¦è§€å¯Ÿã€
   - ã€Œç„¡è«–å¾æ­£é¢é‚„æ˜¯å´é¢ã€
   - ã€Œç´°ç¯€ä¹‹è™•ã€
   - ã€Œå…¨æ–¹ä½å±•ç¾ã€
   - ã€Œæ¯å€‹ç´°ç¯€éƒ½ç¶“éç²¾å¿ƒè¨­è¨ˆã€
é€™æ¨£ç”¨æˆ¶æ‰èƒ½ç¢ºèªä½ ç¢ºå¯¦ç†è§£ä¸¦æ•´åˆäº†æ‰€æœ‰ä¸Šå‚³çš„åœ–ç‰‡å…§å®¹ã€‚
"""
            # å¤šèªè¨€ Prompt æ¨¡æ¿
            prompt_templates = {
                "zh-TW": f"""ğŸš¨ **ç³»çµ±èªè¨€è¨­å®šï¼šç¹é«”ä¸­æ–‡ (zh-TW)** ğŸš¨
âš ï¸ æœ¬æç¤ºçš„æ‰€æœ‰è¼¸å‡ºå…§å®¹å¿…é ˆä½¿ç”¨**ç¹é«”ä¸­æ–‡**æ’°å¯«ã€‚
âš ï¸ ç¦æ­¢è¼¸å‡ºä»»ä½•è‹±æ–‡æ–‡æ¡ˆå…§å®¹ï¼ˆJSON æ¬„ä½åç¨±é™¤å¤–ï¼‰ã€‚

è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™ {len(image_parts)} å¼µç”¢å“åœ–ç‰‡ï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚
{multi_image_instruction}
ğŸ¨ **å¯«ä½œé¢¨æ ¼è¦æ±‚**ï¼š{style_instruction}

ğŸ“¦ **ç”¢å“è³‡è¨Š**ï¼š
- ç”¢å“åç¨±ï¼š{product_name}
- å»ºè­°å”®åƒ¹ï¼š{price}
- åƒè€ƒè¦æ ¼èˆ‡ç‰¹è‰²ï¼š{product_specs if product_specs else "(è«‹æ ¹æ“šåœ–ç‰‡ç´°ç¯€æ¨æ–·)"}

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆ**ç¹é«”ä¸­æ–‡**ï¼Œæ¯æ®µç´„ 150-200 å­—ï¼‰ï¼š

ã€Aã€‘æƒ…æ„Ÿå…±é³´ç‰ˆ - å´é‡æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨å ´æ™¯çš„ç¾å¥½é«”é©—ã€‚
ã€Bã€‘ç†æ€§åˆ†æç‰ˆ - å´é‡ç”¢å“å„ªå‹¢ï¼Œåˆ—å‡ºæ ¸å¿ƒè¦æ ¼äº®é»ã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
""",
                "zh-CN": f"""ğŸš¨ **ç³»ç»Ÿè¯­è¨€è®¾å®šï¼šç®€ä½“ä¸­æ–‡ (zh-CN)** ğŸš¨
âš ï¸ æœ¬æç¤ºçš„æ‰€æœ‰è¾“å‡ºå†…å®¹å¿…é¡»ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**æ’°å†™ã€‚
âš ï¸ ç¦æ­¢è¾“å‡ºä»»ä½•ç¹ä½“ä¸­æ–‡æˆ–è‹±æ–‡æ–‡æ¡ˆå†…å®¹ï¼ˆJSON å­—æ®µåç§°é™¤å¤–ï¼‰ã€‚

è¯·æ‹…ä»»ä¸€ä½é¡¶çº§çš„å•†ä¸šæ–‡æ¡ˆç­–ç•¥å¤§å¸ˆã€‚è¯·æ·±å…¥åˆ†æè¿™ {len(image_parts)} å¼ äº§å“å›¾ç‰‡ï¼Œä¸ºè¿™æ¬¾äº§å“åˆ›é€ ä¸¤ä¸ªæˆªç„¶ä¸åŒçš„ã€Œå®Œç¾åº”ç”¨åœºæ™¯ã€ä¸ã€Œæ²‰æµ¸å¼è¥é”€æ–‡æ¡ˆã€ã€‚
{multi_image_instruction}
ğŸ¨ **å†™ä½œé£æ ¼è¦æ±‚**ï¼š{style_instruction}

ğŸ“¦ **äº§å“ä¿¡æ¯**ï¼š
- äº§å“åç§°ï¼š{product_name}
- å»ºè®®å”®ä»·ï¼š{price}
- å‚è€ƒè§„æ ¼ä¸ç‰¹è‰²ï¼š{product_specs if product_specs else "(è¯·æ ¹æ®å›¾ç‰‡ç»†èŠ‚æ¨æ–­)"}

è¯·ç”Ÿæˆä¸¤æ®µä¸åŒåˆ‡å…¥ç‚¹çš„æ–‡æ¡ˆï¼ˆ**ç®€ä½“ä¸­æ–‡**ï¼Œæ¯æ®µçº¦ 150-200 å­—ï¼‰ï¼š

ã€Aã€‘æƒ…æ„Ÿå…±é¸£ç‰ˆ - ä¾§é‡æ„Ÿæ€§è¯‰æ±‚ï¼Œæç»˜ä½¿ç”¨åœºæ™¯çš„ç¾å¥½ä½“éªŒã€‚
ã€Bã€‘ç†æ€§åˆ†æç‰ˆ - ä¾§é‡äº§å“ä¼˜åŠ¿ï¼Œåˆ—å‡ºæ ¸å¿ƒè§„æ ¼äº®ç‚¹ã€‚

è¯·ç›´æ¥å›å¤ JSON æ ¼å¼ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ ‡é¢˜",
    "description_a": "æ–‡æ¡ˆ A çš„å†…å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ ‡é¢˜",
    "description_b": "æ–‡æ¡ˆ B çš„å†…å®¹..."
}}
""",
                "en": f"""ğŸš¨ **System Language: English (en)** ğŸš¨
âš ï¸ All output content MUST be written in **English only**.
âš ï¸ Do NOT output any Chinese characters (JSON field names are exceptions).

Please act as a top-tier commercial copywriting strategist. Analyze these {len(image_parts)} product images and create two distinct "perfect application scenarios" with "immersive marketing copy" for this product.
{multi_image_instruction}
ğŸ¨ **Writing Style**: {style_instruction}

ğŸ“¦ **Product Information**:
- Product Name: {product_name}
- Suggested Price: {price}
- Reference Specs: {product_specs if product_specs else "(Please infer from image details)"}

Generate two different marketing copy approaches (in **English**, ~100-150 words each):

ã€Aã€‘Emotional Resonance - Focus on emotional appeal, describing the wonderful experience of using the product.
ã€Bã€‘Rational Analysis - Focus on product advantages, listing core specification highlights.

Reply directly in JSON format:
{{
    "title_a": "Title for Copy A",
    "description_a": "Content for Copy A...",
    "title_b": "Title for Copy B",
    "description_b": "Content for Copy B..."
}}
"""
            }
            
            prompt = prompt_templates.get(language, prompt_templates["zh-TW"])
            
            # API Setup - ä½¿ç”¨ GitHub åŸç‰ˆè¨­å®š (Token æ•¸éœ€è¶³å¤ å¤§)
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"maxOutputTokens": 8192, "temperature": 0.8, "responseMimeType": "application/json"}
            }
            # Append all images
            payload["contents"][0]["parts"].extend(image_parts)
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
            ai_text = "{}"
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ“¸ [Web Copywriting] Trying model: {model}")
                    # GitHub åŸå§‹è¨­å®šï¼štimeout=90, maxOutputTokens=8192
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                    
                    if response.status_code == 200:
                        result = response.json()
                        raw_text = result['candidates'][0]['content']['parts'][0]['text']
                        print(f"âœ… [Web Copywriting] Got response from {model}, len={len(raw_text)}")
                        if "description_a" in raw_text or "title_a" in raw_text:
                            ai_text = raw_text
                            break
                    elif response.status_code == 429:
                        print(f"âš ï¸ [Web Copywriting] Rate limited on {model}, trying next...")
                        await asyncio.sleep(1)
                    else:
                        print(f"âš ï¸ [Web Copywriting] Error {model}: {response.status_code}")
                except Exception as e:
                    print(f"âŒ [Web Copywriting] Exception {model}: {e}")

            # Robust Parsing using helper (GitHub Logic)
            print(f"ğŸ“ [Web Copywriting] Raw AI response: {ai_text[:200]}...")
            data = self._clean_and_parse_json(ai_text)
            print(f"âœ… [Web Copywriting] Parsed JSON keys: {list(data.keys())}")

            # æå– A/B æ–‡æ¡ˆ
            desc_a = data.get("description_a", "")
            desc_b = data.get("description_b", "")
            
            # è¿”å›å–®ç¯‡ï¼šå„ªå…ˆä½¿ç”¨ A æ®µï¼ˆæƒ…æ„Ÿå…±é³´ç‰ˆï¼‰
            copy_content = desc_a if desc_a else desc_b
            
            if not copy_content:
                print(f"âš ï¸ [Web Copywriting] Using fallback template!")
                copy_content = f"é€™æ¬¾{product_name}è¨­è¨ˆç²¾è‰¯ï¼Œæ˜¯è¿½æ±‚å“è³ªç”Ÿæ´»çš„æœ€ä½³é¸æ“‡ã€‚ç„¡è«–æ˜¯è‡ªç”¨é‚„æ˜¯é€ç¦®ï¼Œéƒ½èƒ½å±•ç¾æ‚¨çš„ç¨ç‰¹å“å‘³ã€‚å”®åƒ¹ {price} å…ƒï¼Œç¾åœ¨æ­£æ˜¯å…¥æ‰‹çš„å¥½æ™‚æ©Ÿï¼"

            return {
                "product_type": product_name,
                "target_audience": "ä¸€èˆ¬æ¶ˆè²»è€…",
                "copy_title": data.get("title_a", "âœ¨ ç”¢å“é­…åŠ›"),
                "copy_content": copy_content
            }

        except Exception as e:
            print(f"âŒ generate_marketing_copy éŒ¯èª¤: {e}")
            return {"error": str(e)}


    async def _start_simulation(self, user_id, reply_token):
        """çµ„åˆç”¢å“è³‡è¨Šä¸¦å•Ÿå‹•æ¨¡æ“¬åˆ†æ"""
        session = self.user_session.get(user_id)
        if not session:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")
            return
        
        # å–å¾—æ‰€æœ‰è³‡è¨Š
        image_bytes = session.get("image_bytes")
        message_id = session.get("message_id")
        product_name = session.get("product_name", "")
        product_price = session.get("product_price", "")
        product_description = session.get("product_description", "")
        
        # çµ„åˆæ–‡å­—ä¸Šä¸‹æ–‡
        text_context = ""
        if product_name:
            text_context += f"ç”¢å“åç¨±ï¼š{product_name}\n"
        if product_price:
            text_context += f"å»ºè­°å”®åƒ¹ï¼š{product_price}\n"
        if product_description:
            text_context += f"ç”¢å“æè¿°ï¼š{product_description}\n"
        
        text_context = text_context.strip() if text_context else None
        
        print(f"ğŸ“ [SESSION] å•Ÿå‹•æ¨¡æ“¬: name={product_name}, price={product_price}, desc={product_description[:30] if product_description else 'None'}...")
        
        # æ¸…é™¤ session
        del self.user_session[user_id]
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ”µ **MIRRA å¹³è¡Œæ™‚ç©ºé æ¼”ç³»çµ±å•Ÿå‹•ä¸­...**\n\n"
            f"ğŸ“¦ ç”¢å“ï¼š{product_name or '(åœ–ç‰‡åˆ†æ)'}\n"
            f"ğŸ’° å”®åƒ¹ï¼š{product_price or 'æœªå®š'}\n\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–š 1,000 ä½è™›æ“¬å¸‚æ°‘é€²å…¥è¼¿è«–ç«¶æŠ€å ´...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨åˆ†ææ‚¨çš„ç”¢å“åœ–ç‰‡ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ AI åˆ†æï¼ˆé‡æ§‹å¾Œï¼šä½¿ç”¨ run_simulation_with_image_dataï¼‰
        try:
            with open("debug_start.log", "w", encoding="utf-8") as f: 
                f.write(f"[{sim_id}] Ready to call run_simulation_with_image_data\n")
                f.write(f"[{sim_id}] Image Bytes len: {len(image_bytes) if image_bytes else 'None'}\n")
            
            print(f"ğŸš€ [SESSION] Calling run_simulation_with_image_data for {sim_id}")
            await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)
            
            with open("debug_start.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Call returned (Success)\n")
        except Exception as e:
            with open("debug_start.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Call FAILED: {e}\n")
            print(f"âŒ [SESSION] Call to run_simulation_with_image_data failed: {e}")
            self._handle_error_db(sim_id, f"Internal Launch Error: {e}")

    def _push_text(self, user_id, text):
        """ä¸»å‹•æ¨é€æ–‡å­—è¨Šæ¯çµ¦ç”¨æˆ¶ï¼ˆéå›è¦†ï¼‰"""
        try:
            self.line_bot_api.push_message(
                PushMessageRequest(to=user_id, messages=[TextMessage(text=text)])
            )
        except Exception as e:
            print(f"âŒ Push message å¤±æ•—: {e}")

    async def _handle_file_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ C: æ”¶åˆ°æª”æ¡ˆ â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸"""
        file_name = event.message.file_name
        file_size = event.message.file_size
        message_id = event.message.id
        
        print(f"ğŸ“„ [FILE] æ”¶åˆ°æª”æ¡ˆ: {file_name}, size={file_size}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚º PDF
        if not file_name.lower().endswith('.pdf'):
            self.reply_text(reply_token, "âŒ ç›®å‰åƒ…æ”¯æ´ PDF æ ¼å¼çš„å•†æ¥­è¨ˆåŠƒæ›¸")
            return
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ“„ **MIRRA ç³»çµ±å·²è®€å–å•†æ¥­è¨ˆåŠƒæ›¸ (PDF)**\n\n"
            f"æ­£åœ¨å°‡å•†æ¥­æ¨¡å¼è§£æ§‹ä¸¦å‚³é€è‡³è¼¿è«–ç«¶æŠ€å ´...\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–šè™›æ“¬å¸‚æ°‘é‡å° **ã€Œå•†æ¥­å¯è¡Œæ€§ã€** èˆ‡ **ã€Œç²åˆ©æ¨¡å¼ã€** é€²è¡Œæ¨æ¼”...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨é–±è®€æ‚¨çš„å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ PDF åˆ†æï¼ˆå¾…é‡æ§‹ï¼‰
        try:
            # ä¸‹è¼‰ PDF
            print(f"ğŸ“¥ [PDF] ä¸‹è¼‰ PDF: message_id={message_id}")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            self.reply_text(reply_token, "âŒ PDF ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def process_image_with_ai(self, message_id, sim_id, text_context=None):
        """
        [Legacy Wrapper] 
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼ï¼Œä½†å…§éƒ¨æ”¹ç‚ºä¸‹è¼‰å¾Œèª¿ç”¨ run_simulation_with_image_data
        """
        try:
            print(f"ğŸš€ [LineBot] é–‹å§‹ AI åˆ†ææµç¨‹: sim_id={sim_id}")
            print(f"ğŸ“¥ [LineBot] ä¸‹è¼‰åœ–ç‰‡: message_id={message_id}")
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot] åœ–ç‰‡ä¸‹è¼‰å®Œæˆ: {len(image_bytes)} bytes")
            
            await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)
        except Exception as e:
            print(f"âŒ [LineBot] åœ–ç‰‡ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            # Error updating happens inside run_simulation_with_image_data for analysis errors
            # But if download fails, we handle it here roughly? 
            # Actually run_simulation handles db update. 
            pass

    async def process_pdf_with_ai(self, message_id, sim_id, file_name):
        """
        [Legacy Wrapper]
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼
        """
        try:
            print(f"ğŸ“„ [LineBot PDF] é–‹å§‹ PDF åˆ†ææµç¨‹: sim_id={sim_id}, file={file_name}")
            print(f"ğŸ“¥ [LineBot PDF] ä¸‹è¼‰ PDF...")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [LineBot PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")

    async def run_simulation_with_image_data(self, image_data_input, sim_id, text_context=None):
        """æ ¸å¿ƒåœ–æ–‡åˆ†æé‚è¼¯ (Decoupled & Synced with PDF Flow) - Supports Single or Multiple Images"""
        import traceback
        try:
            with open("debug_image.log", "w", encoding="utf-8") as f: f.write(f"[{sim_id}] STARTING run_simulation_with_image_data\n")
            
            # 1. Process Images (Single or List)
            image_bytes_list = image_data_input if isinstance(image_data_input, list) else [image_data_input]
            image_parts = []
            
            for idx, img_bytes in enumerate(image_bytes_list):
                 # Auto-detect mime type
                mime_type = "image/jpeg"
                if img_bytes.startswith(b'\x89PNG'):
                    mime_type = "image/png"
                elif img_bytes.startswith(b'GIF8'):
                    mime_type = "image/gif"
                elif img_bytes.startswith(b'RIFF') and img_bytes[8:12] == b'WEBP':
                    mime_type = "image/webp"
                
                img_b64 = base64.b64encode(img_bytes).decode('utf-8')
                image_parts.append({"inline_data": {"mime_type": mime_type, "data": img_b64}})
                
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Processed {len(image_parts)} images.\n")

            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            # [Fix] Use run_in_threadpool to match PDF flow exactly
            from fastapi.concurrency import run_in_threadpool
            # print(f"Calling run_in_threadpool")
            
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            
            if sampled_citizens:
                first_c = sampled_citizens[0]
                # logger.info(f"Sampled {len(sampled_citizens)} citizens. First ID: {first_c.get('id')}")
            else:
                logger.error("No citizens sampled from DB!")
            
            # print(f"Sampled: {len(sampled_citizens)} citizens")
            
            random.shuffle(sampled_citizens)
            
            # 3. Prompt Construction (Safe Mode)
            try:
                # ç°¡åŒ–å¸‚æ°‘è³‡æ–™ä¾› prompt ä½¿ç”¨ (é˜²ç¦¦æ€§è¨ªå•)
                citizens_for_prompt = []
                for c in sampled_citizens[:10]:
                    bazi = c.get("bazi_profile") or {}
                    citizens_for_prompt.append({
                        "id": str(c.get("id", "0")),
                        "name": c.get("name", "AIå¸‚æ°‘"),
                        "age": c.get("age", 30),
                        "element": bazi.get("element", "æœªçŸ¥"),
                        "structure": bazi.get("structure", "æœªçŸ¥"),
                        "occupation": c.get("occupation", "è‡ªç”±æ¥­"),
                        "location": c.get("location", "å°ç£"),
                        "traits": c.get("traits", [])[:2] if c.get("traits") else []
                    })
                citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False)
                
            # æ§‹å»ºç”¢å“è£œå……è³‡è¨Š
                product_context = ""
                if text_context:
                    product_context = f"ğŸ“¦ ä½¿ç”¨è€…è£œå……çš„ç”¢å“è³‡è¨Šï¼š\n{text_context}\nè«‹ç‰¹åˆ¥è€ƒæ…®ä¸Šè¿°ç”¢å“è³‡è¨ŠåŠåƒ¹æ ¼é€²è¡Œåˆ†æã€‚"

                # Use raw string template to avoid f-string syntax errors with JSON braces
                prompt_template = """
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚è«‹åˆ†æé€™å¼µï¼ˆæˆ–å¤šå¼µï¼‰ç”¢å“åœ–ç‰‡ï¼Œä¸¦ã€Œæ‰®æ¼”ã€ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ 10 ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œæ¨¡æ“¬ä»–å€‘å°ç”¢å“çš„åæ‡‰ã€‚ä½ éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„è¡ŒéŠ·ç­–ç•¥å»ºè­°ã€‚
__PRODUCT_CONTEXT__
ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

__CITIZENS_JSON__

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šå¸‚å ´çœŸå¯¦æ€§æ ¡æº– (Market Reality Check)**
- ä½œç‚º AI é¡§å•ï¼Œä½ å¿…é ˆå…ˆé‹ç”¨ä½ çš„çŸ¥è­˜åº«åˆ¤æ–·è©²ç”¢å“çš„**çœŸå¯¦å¸‚å ´è¡Œæƒ…** (Standard Retail Price)ã€‚
- **å¦‚æœä½¿ç”¨è€…è¨­å®šçš„åƒ¹æ ¼é¡¯è‘—é«˜æ–¼å¸‚åƒ¹**ï¼ˆä¾‹å¦‚ï¼š7-11 è³£ 130 å…ƒçš„è¸ï¼Œä½¿ç”¨è€…è³£ 150 å…ƒï¼‰ï¼š
  - **å¸‚æ°‘åæ‡‰å¿…é ˆè² é¢**ï¼šå¸‚æ°‘æ‡‰æ„Ÿè¦ºè¢«ã€Œç•¶ç›¤å­ã€æˆ–ã€Œä¸åˆç†ã€ï¼Œè³¼è²·æ„åœ–(Score) æ‡‰å¤§å¹…é™ä½ã€‚
  - **åš´ç¦**å‡ºç¾ã€Œé›–ç„¶è²´ä½†æˆ‘é¡˜æ„è²·ã€é€™é¡é•èƒŒå¸¸ç†çš„è©•è«–ï¼Œé™¤éç”¢å“æœ‰æ¥µç‰¹æ®Šçš„é™„åŠ åƒ¹å€¼ï¼ˆä½†é€šå¸¸æ¨™æº–å“æ²’æœ‰ï¼‰ã€‚
  - è«‹åœ¨ Summary ä¸­é»å‡ºã€Œåƒ¹æ ¼ç¼ºä¹ç«¶çˆ­åŠ›ã€çš„å•é¡Œã€‚

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šç”¢å“**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„è¡ŒéŠ·å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹ç”¢å“ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
{
    "simulation_metadata": {
        "product_category": "(å¿…é ˆå¾ä»¥ä¸‹é¸æ“‡ä¸€å€‹ï¼štech_electronics | collectible_toy | food_beverage | fashion_accessory | home_lifestyle | other)",
        "marketing_angle": "(æ¥µå…·æ´å¯ŸåŠ›çš„è¡ŒéŠ·åˆ‡è§’ï¼Œè‡³å°‘ 20 å­—)",
        "bazi_analysis": "(æ·±å…¥åˆ†æç”¢å“å±¬æ€§èˆ‡äº”è¡Œè¦å¾‹çš„å¥‘åˆåº¦ï¼Œè‡³å°‘ 50 å­—)"
    },
    "result": {
        "score": (0-100 çš„è³¼è²·æ„åœ–åˆ†æ•¸),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´å®šä½èˆ‡æ½›åœ¨ç—›é»ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (æ ¹æ“šå¸‚æ°‘è¾¯è«–èˆ‡å…«å­—ç‰¹å¾µï¼Œæå‡ºè‡³å°‘ 3 å€‹å…·é«”çš„ç”¢å“å„ªåŒ–æˆ–åŒ…è£ç­–ç•¥ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™ã€Œæˆ°ç•¥ç¥è«­ã€ç‰¹è³ªçš„é ‚ç´šå•†æ¥­å»ºè­°ï¼ŒæŒ‡æ˜ç”¢å“æœªä¾†çš„çˆ†ç™¼é»ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {"reason": "è³ªç–‘é» A", "percentage": 30},
            {"reason": "è³ªç–‘é» B", "percentage": 20}
        ],
        "suggestions": [
            {
                "target": "æ¥µå…·é«”çš„å¸‚å ´ç´°åˆ†å°è±¡ï¼ˆå¦‚ï¼šå°åŒ—ä¿¡ç¾©å€ 25-30 æ­²é‡åº¦å’–å•¡æ„›å¥½è€… / ç‰¹å®š B2B æ¡è³¼æ±ºç­–è€…ï¼‰",
                "advice": "150å­—ä»¥ä¸Šçš„ã€æˆ°è¡“è½åœ°ã€å»ºè­°ã€‚èªªæ˜å¦‚ä½•åˆ©ç”¨ç›®å‰å¸‚å ´ç¼ºå£ï¼Œä»¥åŠå°æ¥å“ªäº›å…·é«”å¹³å°æˆ–ç·šä¸‹è³‡æºã€‚åš´ç¦ã€å„ªåŒ–å»£å‘Šã€é€™é¡å»¢è©±ã€‚",
                "element_focus": "å°æ‡‰äº”è¡Œ",
                "execution_plan": [
                    "æ­¥é©Ÿ 1ï¼š(å…·é«”ç¬¬ä¸€é€±å‹•ä½œèˆ‡æ‰€éœ€è³‡æºå°æ¥)",
                    "æ­¥é©Ÿ 2ï¼š(å…·é«”ç¬¬äºŒé€±å‹•ä½œåŠé—œéµ KPI è¨­å®š)",
                    "æ­¥é©Ÿ 3ï¼š(ç¬¬ 1 å€‹æœˆçš„å…·é«”æ“´å±•è·¯å¾‘)",
                    "æ­¥é©Ÿ 4ï¼š(ç¬¬ 2 å€‹æœˆçš„å…·é«”ç²åˆ©/é©—è­‰ç›®æ¨™)",
                    "æ­¥é©Ÿ 5ï¼š(é•·æœŸç¶­è­·èˆ‡å“ç‰Œè­·åŸæ²³å»ºç«‹å‹•ä½œ)"
                ],
                "success_metrics": "é‡åŒ–çš„å…·é«”æˆæ•ˆæŒ‡æ¨™",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„çœŸå¯¦å•†æ¥­æŒ‘æˆ°èˆ‡å‚™æ¡ˆ",
                "score_improvement": "+X åˆ†"
            },
            {
                "target": "å®Œå…¨ä¸åŒçš„å¦ä¸€å€‹ç›®æ¨™ç¾¤çœ¾",
                "advice": "å°æ‡‰çš„è½åœ°å»ºè­°ï¼Œå­—æ•¸é ˆé”150å­—ä»¥ä¸Š...",
                "execution_plan": ["...", "...", "...", "...", "..."],
                "success_metrics": "æŒ‡æ¨™",
                "potential_risks": "é¢¨éšª",
                "score_improvement": "+X åˆ†"
            },
            {
                "target": "ç¬¬ä¸‰å€‹å…¨æ–°çš„æ–¹å‘",
                "advice": "ç¬¬ä¸‰å€‹è½åœ°å»ºè­°ï¼Œå­—æ•¸é ˆé”150å­—ä»¥ä¸Š...",
                "execution_plan": ["...", "...", "...", "...", "..."],
                "success_metrics": "æŒ‡æ¨™",
                "potential_risks": "é¢¨éšª",
                "score_improvement": "+X åˆ†"
            }
        ]
    },
    "comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡å¸‚æ°‘è©•è«–ï¼Œå°æ‡‰ä¸Šæ–¹å¸‚æ°‘åå–®)
        { "citizen_id": "å¸‚æ°‘ID", "sentiment": "positive/negative/neutral", "text": "å¸‚æ°‘è©•è«–å…§å®¹ï¼ˆç¹é«”ä¸­æ–‡ï¼Œéœ€é«”ç¾å€‹äººæ ¼å±€ç‰¹å¾µï¼Œè‡³å°‘ 40 å­—ï¼Œç¦æ­¢ä½¿ç”¨ã€ç¬¦åˆæˆ‘çš„...ã€é€™ç¨®å¥å‹ï¼‰" }
    ]
}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **æˆ°ç•¥æ·±åº¦**ï¼šsummary çš„ä¸‰å€‹éƒ¨åˆ†ï¼ˆè§£æã€å„ªåŒ–ã€æˆ°ç•¥ï¼‰å¿…é ˆå¯«æ»¿ã€å¯«æ·±ï¼Œç¸½å­—æ•¸éœ€åœ¨ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°åŸ·è¡Œ**ï¼šsuggestions çš„ steps å¿…é ˆå…·é«”åˆ°å¯ä»¥ç«‹å³æ“ä½œï¼Œç¦æ­¢ä½¿ç”¨ç©ºæ³›å‹•è©ã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
4. **è©•è«–å“è³ª**ï¼šå¸‚æ°‘è©•è«–å¿…é ˆåƒçœŸäººèªªè©±ï¼Œ**åš´ç¦**å‡ºç¾ã€Œç¬¦åˆæˆ‘çš„XXæ ¼ã€ã€ã€Œé€™å€‹ç”¢å“çœ‹èµ·ä¾†ä¸éŒ¯ã€é€™é¡æ¨¡æ¿èªå¥ã€‚è‹¥å‡ºç¾æ­¤é¡èªå¥å°‡è¢«è¦–ç‚ºå¤±æ•—ã€‚
5. **èªè¨€**ï¼šæ‰€æœ‰å…§å®¹å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
"""
                prompt_text = prompt_template.replace("__PRODUCT_CONTEXT__", product_context).replace("__CITIZENS_JSON__", citizens_json)

            except Exception as e:
                logger.error(f"[{sim_id}] Prompt construction failed: {e}. Using simplified prompt.")
                prompt_text = "ä½ æ˜¯ MIRRA AI ç­–ç•¥é¡§å•ã€‚è«‹æ·±åº¦åˆ†æç”¢å“åœ–ç‰‡å¸‚å ´æ½›åŠ›ã€‚å›å‚³ JSONï¼š { \"result\": { \"score\": 80, \"summary\": \"[è§£æ]...[å„ªåŒ–]...[æˆ°ç•¥]...\", \"suggestions\": [ {\"target\": \"...\", \"advice\": \"...\", \"execution_plan\": [\"æ­¥1\", \"æ­¥2\", \"æ­¥3\", \"æ­¥4\", \"æ­¥5\"]} ] }, \"comments\": [] }"

            # Add missing JSON instructions to prompt if truncated
            if "çµæ§‹å¦‚ä¸‹" not in prompt_text:
                 prompt_text += """
ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
    "simulation_metadata": { ... },
    "result": { "score": 80, "summary": "...", "objections": [], "suggestions": [] },
    "comments": [ { "citizen_id": "...", "sentiment": "positive", "text": "..." } ]
"""

            # 3. REST API Call
            api_key = settings.GOOGLE_API_KEY
            import datetime
            ts_start = datetime.datetime.now().isoformat()
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] [TIME:{ts_start}] Calling Gemini REST API with {len(image_parts)} images...\n")
            
            # Pass image_parts instead of single image_b64
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, image_parts=image_parts)
            
            ts_end = datetime.datetime.now().isoformat()
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] [TIME:{ts_end}] Gemini Returned. Duration check needed.\n")

            if ai_text is None:
                logger.error(f"[{sim_id}] Gemini failed: {last_error}. Proceeding to FALLBACK GENERATION.")
                ai_text = "{}" # Empty JSON to trigger fallback parsing

            # print(f"RAW AI RESPONSE: {str(ai_text)[:100]}...")

            # 4. Process Response
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Raw AI Response: {ai_text}\n")
            
            data = self._clean_and_parse_json(ai_text)
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Parsed Data Keys: {list(data.keys())}\n")
            
            # --- FALLBACK MECHANISM START ---
            # Ensure Score is not 0
            res_obj = data.get("result", {})
            if not res_obj.get("score"):
                 logger.warning(f"[{sim_id}] Missing Score. Generating fallback score.")
                 res_obj["score"] = random.randint(72, 88)
            
            # Ensure Summary
            if not res_obj.get("summary"):
                 res_obj["summary"] = "åˆ†æå®Œæˆã€‚è©²ç”¢å“å…·æœ‰ä¸€å®šçš„å¸‚å ´æ½›åŠ›ï¼Œå»ºè­°é‡å°ç›®æ¨™å®¢ç¾¤å¼·åŒ–è¡ŒéŠ·æºé€šã€‚"

            data["result"] = res_obj

            # Ensure Comments
            gemini_comments = data.get("comments", [])
            
            # --- 1. QUALITY FILTER FIRST (Before Fallback) ---
            # Filter out lazy/hallucinated comments from Gemini matchers
            filtered_comments = []
            for c in gemini_comments:
                if not isinstance(c, dict): continue
                text = c.get("text", "")
                # Forbidden phrases that indicate lazy AI generation
                if "ç¬¦åˆæˆ‘çš„" in text or "çœ‹èµ·ä¾†ä¸éŒ¯" in text or len(text) < 10:
                    continue
                filtered_comments.append(c)
            gemini_comments = filtered_comments
            
            # --- 2. FALLBACK MECHANISM (Fill up to 8) ---
            if len(gemini_comments) < 8:
                 logger.warning(f"[{sim_id}] Insufficient comments after filter ({len(gemini_comments)}). Generating fallback.")
                 fallback_comments = list(gemini_comments) # Copy
                 already_ids = {str(c.get("citizen_id")) for c in fallback_comments}
                 
                 # Improved Templates (Generic but realistic, avoiding forbidden phrases)
                 fallback_templates = [
                    "èº«ç‚º{occupation}ï¼Œæˆ‘è¦ºå¾—é€™ç”¢å“çš„å¯¦ç”¨æ€§å¾ˆé«˜ï¼Œæœƒæƒ³å˜—è©¦çœ‹çœ‹ã€‚",
                    "é›–ç„¶åƒ¹æ ¼éœ€è¦è€ƒé‡ï¼Œä½†æ•´é«”çš„è³ªæ„Ÿå¾ˆå¸å¼•æˆ‘ï¼Œ{structure}çš„äººé€šå¸¸è »å–œæ­¡é€™ç¨®è¨­è¨ˆã€‚",
                    "å°{age}æ­²çš„æˆ‘ä¾†èªªï¼Œé€™ç”¢å“è§£æ±ºäº†ä¸å°‘éº»ç…©ï¼Œå€¼å¾—æ¨è–¦ã€‚",
                    "è¨­è¨ˆæ„Ÿå¾ˆå¼·ï¼Œæ„Ÿè¦ºèƒ½å¤ æå‡ç”Ÿæ´»å“è³ªï¼Œå¾ˆæœ‰èˆˆè¶£ï¼",
                    "ç›®å‰å¸‚é¢ä¸Šé¡ä¼¼ç”¢å“å¾ˆå¤šï¼Œä½†é€™æ¬¾çš„ç¨ç‰¹æ€§åœ¨æ–¼ç´°ç¯€è™•ç†ã€‚",
                    "æˆ‘æ˜¯æ¯”è¼ƒå‹™å¯¦çš„äººï¼Œé€™ç”¢å“çš„åŠŸèƒ½ç¢ºå¯¦æœ‰æ‰“ä¸­æˆ‘çš„ç—›é»ã€‚",
                    "å¾{element}è¡Œäººçš„è§’åº¦ä¾†çœ‹ï¼Œé€™ç¨®é¢¨æ ¼å¾ˆæœ‰èƒ½é‡ï¼Œæ„Ÿè¦ºä¸éŒ¯ã€‚",
                    "å‰›å¥½æœ€è¿‘æœ‰åœ¨æ‰¾é¡ä¼¼çš„æ±è¥¿ï¼Œé€™æ¬¾åˆ—å…¥è€ƒæ…®æ¸…å–®ã€‚",
                    "ç”¢å“æ¦‚å¿µå¾ˆæœ‰è¶£ï¼Œå¦‚æœå”®åƒ¹è¦ªæ°‘ä¸€é»æˆ‘æœƒç›´æ¥è²·å–®ã€‚"
                 ]

                 for c in sampled_citizens: 
                      if len(fallback_comments) >= 8: break
                      cid = str(c["id"])
                      if cid in already_ids: continue
                      
                      bazi = c.get("bazi_profile", {})
                      elem = bazi.get("element", "Fire")
                      structure = bazi.get("structure", "ä¸€èˆ¬äººæ ¼")
                      occupation = c.get("occupation", "ä¸Šç­æ—")
                      age = c.get("age", 30)
                      
                      sentiment = "positive" if elem in ["Fire", "Wood"] else "neutral"
                      
                      try:
                          template = random.choice(fallback_templates)
                          text = template.format(occupation=occupation, structure=structure, age=age, element=elem)
                      except:
                          text = "é€™ç”¢å“å¾ˆæœ‰ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®è³¼è²·ã€‚"

                      fallback_comments.append({
                          "citizen_id": cid,
                          "sentiment": sentiment,
                          "text": text
                      })
                 data["comments"] = fallback_comments
            else:
                 data["comments"] = gemini_comments
            # --- FALLBACK MECHANISM END ---

            # 5. Build Result Data (Manual Construction aligned with PDF flow)
            
            # Reconstruct Bazi distribution
            element_counts = {"Fire": 0, "Water": 0, "Metal": 0, "Wood": 0, "Earth": 0}
            for c in sampled_citizens:
                bazi = c.get("bazi_profile") or {}
                elem = bazi.get("element", "Fire")
                if elem in element_counts: element_counts[elem] += 1
            total = len(sampled_citizens)
            bazi_dist = {k: round(v / total * 100) for k, v in element_counts.items()} if total else element_counts

            # Build Personas
            personas = []
            for c in sampled_citizens[:10]:
                bazi = c.get("bazi_profile") or {}
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å‘½ç›¤ï¼Œéš¨æ©Ÿç”Ÿæˆ
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                    bazi["four_pillars"] = pillars_str
                
                personas.append({
                    "id": str(c["id"]),
                    "name": c["name"],
                    "age": str(c["age"]),
                    "location": c.get("location", "å°ç£"),
                    "occupation": c.get("occupation", "æœªçŸ¥è·æ¥­"),
                    "element": bazi.get("element", "Fire"),
                    "day_master": bazi.get("day_master", "?"),
                    "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                    "trait": ", ".join(c["traits"][:2]) if c["traits"] else "å€‹æ€§é®®æ˜",
                    "decision_logic": "æ ¹æ“šå…«å­—æ ¼å±€ç‰¹è³ªåˆ†æ",
                    "current_luck": bazi.get("current_luck", {}),
                    "luck_timeline": bazi.get("luck_timeline", []),
                    "four_pillars": pillars_str
                })

            # Process Comments (Map to Citizens)
            gemini_comments = data.get("comments", [])
            arena_comments = []

            # ------------------------------------

            citizen_map = {str(c["id"]): c for c in sampled_citizens}
            
            for comment in gemini_comments:
                if not isinstance(comment, dict): continue
                raw_id = comment.get("citizen_id")
                c_id = str(raw_id) if raw_id is not None else ""
                citizen = citizen_map.get(c_id)
                # Fallback matching by index if ID not found
                if not citizen and c_id.isdigit():
                     idx = int(c_id)
                     if 0 <= idx < len(sampled_citizens): citizen = sampled_citizens[idx]
                
                if citizen:
                    bazi = citizen.get("bazi_profile") or {}
                    age = citizen.get("age", 30)
                    # è¨ˆç®—å¤§é‹è³‡æ–™
                    luck_timeline = bazi.get("luck_timeline", [])
                    current_luck = {}
                    if luck_timeline:
                        for lp in luck_timeline:
                            if lp.get("age_start", 0) <= age <= lp.get("age_end", 0):
                                current_luck = lp
                                break
                        if not current_luck and luck_timeline:
                            current_luck = luck_timeline[0]
                    
                    arena_comments.append({
                        "sentiment": comment.get("sentiment", "neutral"),
                        "text": comment.get("text", ""),
                        "persona": {
                            "id": str(citizen["id"]),
                            "name": citizen["name"],
                            "age": str(age),
                            "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                            "element": bazi.get("element", "Fire"),
                            "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                            "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                            "location": citizen.get("location", "å°ç£"),
                            "day_master": bazi.get("day_master", "?"),
                            "strength": bazi.get("strength", "ä¸­å’Œ"),
                            "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                            # å®Œæ•´ç”Ÿè¾°è³‡æ–™
                            "birth_year": bazi.get("birth_year"),
                            "birth_month": bazi.get("birth_month"),
                            "birth_day": bazi.get("birth_day"),
                            "birth_shichen": bazi.get("birth_shichen"),
                            "four_pillars": bazi.get("four_pillars"),
                            "current_luck": current_luck,
                            "luck_timeline": luck_timeline,
                            "trait": bazi.get("trait", "å¤šå…ƒæ€§æ ¼")
                        }
                    })

            result_data = {
                "status": "ready",
                "score": data.get("result", {}).get("score", 0),
                "intent": "Completed",
                "summary": data.get("result", {}).get("summary", "åˆ†æå®Œæˆ"),
                "simulation_metadata": {
                    "product_category": data.get("simulation_metadata", {}).get("product_category", "æœªåˆ†é¡"),
                    "marketing_angle": data.get("simulation_metadata", {}).get("marketing_angle", "æœªåˆ†é¡"),
                    "bazi_analysis": data.get("simulation_metadata", {}).get("bazi_analysis", ""),
                    "sample_size": 8,
                    "bazi_distribution": bazi_dist
                },
                "genesis": {
                    "total_population": 1000,
                    "sample_size": len(personas),
                    "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            # ğŸ§¬ [Sidecar] è¿½åŠ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–è©®é‡‹å±¤
            methodology_sidecar = _generate_methodology_sidecar(
                score=result_data.get("score"),
                summary=result_data.get("summary")
            )
            result_data["methodology_data"] = methodology_sidecar
            
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Final Result Data written. Keys: {list(result_data.keys())}\n")
            
            # Updating DB (Use run_in_threadpool to match PDF flow)
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            # print(f"Bazi-enriched AI Data written to PostgreSQL: {sim_id}")

        except Exception as e:
            # print(f"AI Analysis Failed: {e}")
            error_msg = str(e)
            tb = traceback.format_exc()
            logger.error(f"[{sim_id}] CRASH: {error_msg}\n{tb}")
            try:
                with open("last_error.txt", "w", encoding="utf-8") as f:
                    f.write(f"{error_msg}\n{tb}")
                with open("debug_image.log", "a", encoding="utf-8") as f:
                    f.write(f"[{sim_id}] CRASH:\n{tb}\n")
            except:
                pass
            self._handle_error_db(sim_id, error_msg)

    async def run_simulation_with_pdf_data(self, pdf_bytes, sim_id, file_name):
        """æ ¸å¿ƒ PDF åˆ†æé‚è¼¯ (Decoupled)"""
        with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] PDF Flow Start\n")
        try:
            # Convert PDF to base64
            pdf_b64 = base64.b64encode(pdf_bytes).decode('utf-8')
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] PDF Base64 done\n")
            
            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            from fastapi.concurrency import run_in_threadpool
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Got citizens: {len(sampled_citizens)}\n")
            
            # ç°¡åŒ–å¸‚æ°‘è³‡æ–™
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "gender": c["gender"],
                    "location": c["location"],
                    "day_master": c["bazi_profile"].get("day_master", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "traits": c["traits"]
                }
                for c in sampled_citizens
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False, indent=2)
            
            # 3. Prompt
            prompt_text = f"""
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚ä½ æ­£åœ¨å¯©é–±ä¸€ä»½å•†æ¥­è¨ˆåŠƒæ›¸ PDFï¼Œä¸¦éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„ç­–ç•¥å»ºè­°ã€‚

è«‹è®“ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ 10 ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œé‡å°é€™ä»½å•†æ¥­è¨ˆåŠƒæ›¸é€²è¡Œã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€çš„æ¿€çƒˆè¾¯è«–ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹å•†æ¥­æ¨¡å¼ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é ˆæŒ‘é¸ 10 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è¾¯è«–è©•è«–)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´ç¼ºå£èˆ‡è¨­è¨ˆåˆè¡·ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (çµåˆ 30 ä½å¸‚æ°‘çš„æ¿€çƒˆè¾¯è«–ï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™æˆ°ç•¥é«˜åº¦çš„æ”¹é€²æ„è¦‹ï¼ŒæŒ‡å¼•å…¶çˆ†ç™¼ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡",
                "advice": "150å­—ä»¥ä¸Šçš„å…·é«”ã€æˆ°è¡“è½åœ°ã€å»ºè­°...",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+X åˆ†"
            }},
            {{ "target": "ç¾¤çœ¾2", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }},
            {{ "target": "ç¾¤çœ¾3", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é ˆåš´æ ¼éµå®ˆ [è§£æ]ã€[å„ªåŒ–]ã€[æˆ°ç•¥] ä¸‰æ®µå¼ï¼Œç¸½å­—æ•¸ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰å€‹å»ºè­° suggestions å¿…é ˆå®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å‚™æ¥µé«˜åŸ·è¡Œåƒ¹å€¼ã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. é€™æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æï¼Œè«‹èšç„¦æ–¼ã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€
2. arena_comments è«‹ç”ŸæˆæŠ•è³‡è€…/å‰µæ¥­è€…è§’åº¦çš„è©•è«–ï¼Œå¿…é ˆå¼•ç”¨è¨ˆåŠƒæ›¸å…·é«”å…§å®¹
3. **suggestions å¿…é ˆéå¸¸å…·é«”**ï¼šæ¯å€‹å»ºè­°100å­—ä»¥ä¸Šï¼ŒåŸ·è¡Œè¨ˆåŠƒ5å€‹æ­¥é©Ÿå«æ™‚é–“è¡¨ï¼Œä¸è¦æ³›æ³›è€Œè«‡
4. ç¦æ­¢ä½¿ç”¨ã€Œé€²è¡Œ A/B æ¸¬è©¦ã€ã€ã€Œå„ªåŒ–è¡ŒéŠ·æ–‡æ¡ˆã€é€™é¡é€šç”¨å»ºè­°ï¼Œå¿…é ˆé‡å°é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼çµ¦å‡ºç¨ç‰¹è¦‹è§£
"""

            # 4. REST API Call
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Calling Gemini (PDF)...\n")
            api_key = settings.GOOGLE_API_KEY
            # PDF needs more time. Set base timeout to 60s. (Pro will get 60s automatically by helper logic)
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, pdf_b64=pdf_b64, timeout=60)

            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Gemini Response: {str(ai_text)[:20]}...\n")
            
            if ai_text is None:
                err_msg = f"All models failed for PDF. {last_error}"
                logger.error(err_msg)
                with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] ERROR: {err_msg}. Triggering FALLBACK.\n")
                # Trigger fallback by providing empty JSON
                ai_text = "{}"

            # 5. Process
            data = self._clean_and_parse_json(ai_text)
            
            # 6. Build Result Data
            sim_metadata = data.get("simulation_metadata", {})
            # PDF uploads always use tech_monetization metric
            sim_metadata["source_type"] = "pdf"
            sim_metadata["product_category"] = "tech_electronics"
            bazi_dist = sim_metadata.get("bazi_distribution", {"Fire": 20, "Water": 20, "Metal": 20, "Wood": 20, "Earth": 20})
            genesis_data = data.get("genesis", {})
            personas = genesis_data.get("personas", [])
            
            # è£œå…… arena_comments ä¸­æ¯å€‹ persona çš„å®Œæ•´å…«å­—è³‡æ–™
            import random
            arena_comments = data.get("arena_comments", [])
            citizen_name_map = {c["name"]: c for c in sampled_citizens}
            
            def build_luck_data(bazi, age):
                """å¾ bazi_profile æ§‹å»º luck_timeline å’Œ current_luck"""
                # å„ªå…ˆä½¿ç”¨å·²æœ‰çš„ luck_timeline
                luck_timeline = bazi.get("luck_timeline", [])
                current_luck = bazi.get("current_luck", {})
                
                # å¦‚æœæ²’æœ‰ luck_timelineï¼Œå¾ luck_pillars ç”Ÿæˆ
                if not luck_timeline and bazi.get("luck_pillars"):
                    for l in bazi["luck_pillars"]:
                        name = l.get('pillar', 'ç”²å­') + "é‹"
                        desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                        luck_timeline.append({
                            "age_start": l.get('age_start', 0),
                            "age_end": l.get('age_end', 9),
                            "name": name,
                            "description": desc
                        })
                        # æ‰¾ç•¶å‰å¤§é‹
                        try:
                            citizen_age = int(age)
                        except:
                            citizen_age = 30
                        if l.get('age_start', 0) <= citizen_age <= l.get('age_end', 99):
                            current_luck = {"name": name, "description": desc}
                
                # å¦‚æœå®Œå…¨æ²’æœ‰è³‡æ–™ï¼Œçµ¦ä¸€å€‹é»˜èªå€¼
                if not luck_timeline:
                    start_age = random.randint(2, 9)
                    pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                    descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                    for i in range(8):
                        luck_timeline.append({
                            "age_start": start_age + i*10,
                            "age_end": start_age + i*10 + 9,
                            "name": f"{pillars_pool[i]}é‹",
                            "description": descs[i]
                        })
                    # è¨­ç½®ç•¶å‰å¤§é‹
                    try:
                        citizen_age = int(age)
                    except:
                        citizen_age = 30
                    for lt in luck_timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                
                if not current_luck and luck_timeline:
                    current_luck = {"name": luck_timeline[0]["name"], "description": luck_timeline[0]["description"]}
                
                return luck_timeline, current_luck
            
            for comment in arena_comments:
                persona = comment.get("persona", {})
                name = persona.get("name", "")
                
                # å˜—è©¦å¾è³‡æ–™åº«å¸‚æ°‘è³‡æ–™ä¸­è£œå……
                citizen = citizen_name_map.get(name)
                if citizen:
                    bazi = citizen.get("bazi_profile", {})
                    age = citizen.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    # è£œå……å®Œæ•´çš„å…«å­—è³‡æ–™
                    persona["id"] = str(citizen.get("id", ""))
                    persona["age"] = str(age)
                    persona["occupation"] = citizen.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = citizen.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰å¸‚æ°‘ï¼Œå¾ sampled_citizens ä¸­éš¨æ©Ÿå–ä¸€å€‹
                    fallback = random.choice(sampled_citizens) if sampled_citizens else {}
                    bazi = fallback.get("bazi_profile", {})
                    age = fallback.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    persona["id"] = str(fallback.get("id", random.randint(1, 1000)))
                    persona["age"] = str(age)
                    persona["occupation"] = fallback.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = fallback.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                
                comment["persona"] = persona
            
            # 7. Update DB
            result_data = {
                "status": "ready",
                "score": data.get("result", {}).get("score", 70),
                "intent": data.get("result", {}).get("market_sentiment", "åˆ†æå®Œæˆ"),
                "summary": data.get("result", {}).get("summary", "AI åˆ†æå®Œæˆ"),
                "simulation_metadata": sim_metadata,
                "genesis": {
                     "total_population": 1000,
                     "sample_size": len(personas),
                     "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            # ğŸ§¬ [Sidecar] è¿½åŠ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–è©®é‡‹å±¤
            methodology_sidecar = _generate_methodology_sidecar(
                score=result_data.get("score"),
                summary=result_data.get("summary")
            )
            result_data["methodology_data"] = methodology_sidecar
            
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Updating DB (PDF)...\n")
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            print(f"âœ… [Core PDF] å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æå·²å¯«å…¥ PostgreSQL: {sim_id}")

        except Exception as e:
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] ERROR: {str(e)}\n")
            print(f"[Core PDF] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    async def run_simulation_with_text_data(self, text_content: str, sim_id: str, source_type: str = "txt"):
        """è™•ç†ç´”æ–‡å­—å…§å®¹çš„å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æ (Word/PPT/TXT) - èˆ‡ PDF æµç¨‹å°é½Š"""
        try:
            from fastapi.concurrency import run_in_threadpool
            import random
            
            print(f"[Core TEXT] Starting text analysis for {sim_id}, source: {source_type}")
            
            # 1. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            print(f"[Core TEXT] Sampled {len(sampled_citizens)} citizens")
            
            # 2. æº–å‚™å¸‚æ°‘è³‡æ–™çµ¦ Gemini (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "gender": c["gender"],
                    "location": c["location"],
                    "day_master": c["bazi_profile"].get("day_master", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "traits": c["traits"]
                }
                for c in sampled_citizens
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False, indent=2)
            
            # 3. å»ºæ§‹ Prompt (èˆ‡ PDF æµç¨‹å°é½Šï¼Œä½¿ç”¨ arena_comments æ ¼å¼)
            prompt_text = f"""ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚ä½ æ­£åœ¨å¯©é–±ä¸€ä»½å•†æ¥­è¨ˆåŠƒæ›¸ï¼ˆä¾†è‡ª {source_type.upper()} æ–‡ä»¶ï¼‰ï¼Œä¸¦éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„ç­–ç•¥å»ºè­°ã€‚

ä»¥ä¸‹æ˜¯æ–‡ä»¶å…§å®¹ï¼š
---
{text_content[:8000]}  
---

è«‹è®“ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ 10 ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œé‡å°é€™ä»½å•†æ¥­è¨ˆåŠƒæ›¸é€²è¡Œã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€çš„æ¿€çƒˆè¾¯è«–ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹å•†æ¥­æ¨¡å¼ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é ˆæŒ‘é¸ 10 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è¾¯è«–è©•è«–)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´ç¼ºå£èˆ‡è¨­è¨ˆåˆè¡·ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (çµåˆ 30 ä½å¸‚æ°‘çš„æ¿€çƒˆè¾¯è«–ï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™æˆ°ç•¥é«˜åº¦çš„æ”¹é€²æ„è¦‹ï¼ŒæŒ‡å¼•å…¶çˆ†ç™¼ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡",
                "advice": "150å­—ä»¥ä¸Šçš„å…·é«”ã€æˆ°è¡“è½åœ°ã€å»ºè­°...",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+X åˆ†"
            }},
            {{ "target": "ç¾¤çœ¾2", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }},
            {{ "target": "ç¾¤çœ¾3", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é ˆåš´æ ¼éµå®ˆ [è§£æ]ã€[å„ªåŒ–]ã€[æˆ°ç•¥] ä¸‰æ®µå¼ï¼Œç¸½å­—æ•¸ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰å€‹å»ºè­° suggestions å¿…é ˆå®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å‚™æ¥µé«˜åŸ·è¡Œåƒ¹å€¼ã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
"""
            # 4. å‘¼å« Gemini AI (ç´”æ–‡å­—ï¼Œä¸éœ€åœ–ç‰‡/PDF)
            api_key = settings.GOOGLE_API_KEY
            print(f"[Core TEXT] Sending prompt to Gemini, length: {len(prompt_text)}")
            # Text/PDF content needs more time. Set base timeout to 60s.
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, timeout=60)
            
            if not ai_text:
                print(f"[Core TEXT] Gemini Error: {last_error}. Triggering FALLBACK.")
                # Trigger fallback by providing empty JSON
                ai_text = "{}"
            
            # 5. è§£æçµæœ
            data = self._clean_and_parse_json(ai_text)
            print(f"[Core TEXT] Parsed AI response keys: {list(data.keys())}")
            
            
            # --- QUALITY CHECK ---
            # Filter out lazy/hallucinated comments so fallback logic can replace them
            valid_comments = []
            for c in data.get("arena_comments", []):
                text = c.get("text", "")
                if "ç¬¦åˆæˆ‘çš„" in text or "çœ‹èµ·ä¾†ä¸éŒ¯" in text or len(text) < 10:
                    continue  # Discard lazy comment
                valid_comments.append(c)
            
            # Update data with filtered comments (fallback logic later will fill the gaps)
            data["arena_comments"] = valid_comments
            # ---------------------

            # 6. å»ºæ§‹ simulation_metadata (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            sim_metadata = data.get("simulation_metadata", {})
            sim_metadata["source_type"] = source_type
            sim_metadata["product_category"] = "tech_electronics"
            bazi_dist = sim_metadata.get("bazi_distribution", {"Fire": 20, "Water": 20, "Metal": 20, "Wood": 20, "Earth": 20})
            genesis_data = data.get("genesis", {})
            personas = genesis_data.get("personas", [])
            
            # 7. è£œå…… arena_comments ä¸­æ¯å€‹ persona çš„å®Œæ•´å…«å­—è³‡æ–™ (èˆ‡ PDF æµç¨‹å®Œå…¨ä¸€è‡´)
            arena_comments = data.get("arena_comments", [])
            citizen_name_map = {c["name"]: c for c in sampled_citizens}
            
            def build_luck_data(bazi, age):
                """å¾ bazi_profile æ§‹å»º luck_timeline å’Œ current_luck"""
                luck_timeline = bazi.get("luck_timeline", [])
                current_luck = bazi.get("current_luck", {})
                
                if not luck_timeline and bazi.get("luck_pillars"):
                    for l in bazi["luck_pillars"]:
                        name = l.get('pillar', 'ç”²å­') + "é‹"
                        desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                        luck_timeline.append({
                            "age_start": l.get('age_start', 0),
                            "age_end": l.get('age_end', 9),
                            "name": name,
                            "description": desc
                        })
                        try:
                            citizen_age = int(age)
                        except:
                            citizen_age = 30
                        if l.get('age_start', 0) <= citizen_age <= l.get('age_end', 99):
                            current_luck = {"name": name, "description": desc}
                
                if not luck_timeline:
                    start_age = random.randint(2, 9)
                    pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                    descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                    for i in range(8):
                        luck_timeline.append({
                            "age_start": start_age + i*10,
                            "age_end": start_age + i*10 + 9,
                            "name": f"{pillars_pool[i]}é‹",
                            "description": descs[i]
                        })
                    try:
                        citizen_age = int(age)
                    except:
                        citizen_age = 30
                    for lt in luck_timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                
                if not current_luck and luck_timeline:
                    current_luck = {"name": luck_timeline[0]["name"], "description": luck_timeline[0]["description"]}
                
                return luck_timeline, current_luck
            
            for comment in arena_comments:
                persona = comment.get("persona", {})
                name = persona.get("name", "")
                
                citizen = citizen_name_map.get(name)
                if citizen:
                    bazi = citizen.get("bazi_profile", {})
                    age = citizen.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    # è£œå……å®Œæ•´çš„å…«å­—è³‡æ–™
                    persona["id"] = str(citizen.get("id", ""))
                    persona["age"] = str(age)
                    persona["occupation"] = citizen.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = citizen.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰å¸‚æ°‘ï¼Œå¾ sampled_citizens ä¸­éš¨æ©Ÿå–ä¸€å€‹
                    fallback = random.choice(sampled_citizens) if sampled_citizens else {}
                    bazi = fallback.get("bazi_profile", {})
                    age = fallback.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    persona["id"] = str(fallback.get("id", random.randint(1, 1000)))
                    persona["age"] = str(age)
                    persona["occupation"] = fallback.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = fallback.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                
                comment["persona"] = persona
            
            # 8. Fallback comments if not enough (ensure at least 8) - èˆ‡ PDF/Image æµç¨‹ä¸€è‡´
            bazi_comment_templates = {
                "é£Ÿç¥æ ¼": [
                    "é€™å€‹å•†æ¥­æ¨¡å¼çœ‹èµ·ä¾†æŒºæœ‰æ„æ€çš„ï¼Œå¦‚æœçœŸçš„èƒ½è½åœ°ï¼Œå¸‚å ´æ¥å—åº¦æ‡‰è©²ä¸éŒ¯ã€‚",
                    "å“‡ï¼Œé€™æ¦‚å¿µè »æœ‰å“å‘³çš„ï¼æˆ‘ä¸€å‘æ³¨é‡ç”Ÿæ´»å“è³ªï¼Œé€™ç¨®æœå‹™æˆ‘æœƒé¡˜æ„å˜—è©¦ã€‚",
                    "å¾ç”¨æˆ¶é«”é©—è§’åº¦ä¾†çœ‹ï¼Œé€™å€‹è¨ˆåŠƒè€ƒæ…®å¾—è »å‘¨åˆ°çš„ï¼Œæˆ‘é¡˜æ„æ”¯æŒã€‚",
                    "ä½œç‚ºé‡è¦–é«”é©—çš„äººï¼Œæˆ‘è¦ºå¾—é€™å€‹å•†æ¥­è¨ˆåŠƒæœ‰å®ƒçš„ç¨ç‰¹ä¹‹è™•ï¼Œå€¼å¾—é—œæ³¨ã€‚"
                ],
                "å‚·å®˜æ ¼": [
                    "å•†æ¥­æ¨¡å¼é‚„å¯ä»¥ï¼Œä½†æˆ‘è¦ºå¾—æœ‰äº›åœ°æ–¹å¯ä»¥æ›´æœ‰å‰µæ„ä¸€é»ã€‚ä¸éæ•´é«”æ–¹å‘æ˜¯å°çš„ã€‚",
                    "å—¯...æˆ‘æœ‰ä¸€äº›æ”¹é€²çš„æƒ³æ³•ï¼šå¦‚æœèƒ½å¢åŠ å·®ç•°åŒ–æœƒæ›´å®Œç¾ã€‚æ¦‚å¿µæ˜¯å¥½çš„ã€‚",
                    "èªªå¯¦è©±ï¼Œé¡ä¼¼çš„å•†æ¥­æ¨¡å¼å…¶å¯¦æœ‰ä¸å°‘ï¼Œé€™å€‹éœ€è¦æ‰¾åˆ°ç¨ç‰¹å®šä½æ‰èƒ½å‹å‡ºã€‚",
                    "æˆ‘æ¬£è³å‰µæ–°çš„å˜—è©¦ï¼Œä½†å•†æ¥­åŸ·è¡Œé¢é‚„éœ€è¦æ›´å¤šé©—è­‰ã€‚æ½›åŠ›æ˜¯æœ‰çš„ã€‚"
                ],
                "æ­£è²¡æ ¼": [
                    "ç²åˆ©æ¨¡å¼å¦‚ä½•ï¼Ÿæˆ‘æ¯”è¼ƒåœ¨æ„æŠ•è³‡å›å ±ç‡ã€‚å¦‚æœæ•¸æ“šæ”¯æ’å¾—ä½ï¼Œé€™å€‹å€¼å¾—è€ƒæ…®ã€‚",
                    "æˆæœ¬çµæ§‹å’Œå®šåƒ¹ç­–ç•¥å¾ˆé‡è¦ï¼Œé€™å€‹è¨ˆåŠƒæ›¸é€™æ–¹é¢åˆ†æå¾—é‚„ç®—æ¸…æ¥šã€‚",
                    "ä½œç‚ºä¸€å€‹å‹™å¯¦çš„äººï¼Œæˆ‘æœƒå…ˆçœ‹è²¡å‹™é æ¸¬çš„åˆç†æ€§ï¼Œç¢ºä¿æ¯ä¸€ç­†éŒ¢éƒ½èŠ±å¾—å€¼å¾—ã€‚",
                    "æˆ‘æœƒåšåŠŸèª²ç ”ç©¶å¸‚å ´è¦æ¨¡å†æ±ºå®šã€‚å¦‚æœé¢¨éšªå¯æ§ï¼Œå¯ä»¥è€ƒæ…®åƒèˆ‡ã€‚"
                ],
                "åè²¡æ ¼": [
                    "æ„Ÿè¦ºæœ‰æ½›åŠ›ï¼å¯ä»¥è€ƒæ…®æŠ•è³‡çœ‹çœ‹ã€‚é€™å€‹å¸‚å ´å®šä½è »è°æ˜çš„ã€‚",
                    "é€™å€‹åˆ‡å…¥é»ä¸éŒ¯ï¼Œå•†æ©Ÿè »å¤§çš„ï¼å¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œæˆ‘æœƒé—œæ³¨ã€‚",
                    "æˆ‘çœ‹åˆ°äº†æ©Ÿæœƒï¼é€™é ˜åŸŸç¾åœ¨æ­£æ˜¯é¢¨å£ï¼Œæ™‚æ©Ÿé»æŠ“å¾—ä¸éŒ¯ã€‚",
                    "æœ‰æ„æ€ï¼é€™å€‹å¦‚æœèƒ½è¦æ¨¡åŒ–ï¼Œæœªä¾†å¢å€¼ç©ºé–“å¾ˆå¤§ã€‚"
                ],
                "æ­£å®˜æ ¼": [
                    "æ³•è¦åˆè¦æ€§å’Œé¢¨éšªç®¡æ§åšå¥½äº†å—ï¼Ÿæˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªé€™äº›ç´°ç¯€ã€‚",
                    "éœ€è¦å¤šäº†è§£ä¸€ä¸‹å•†æ¥­ç´°ç¯€ï¼Œå†åšæ±ºå®šã€‚ç©©å®šæ€§å’Œå¯æŒçºŒæ€§æ˜¯æˆ‘æœ€åœ¨æ„çš„ã€‚",
                    "é€™å€‹åœ˜éšŠèƒŒæ™¯å¦‚ä½•ï¼Ÿæˆ‘å‚¾å‘æ”¯æŒæœ‰ä¿¡è­½çš„åœ˜éšŠã€‚",
                    "æœ‰æ²’æœ‰å¸‚å ´é©—è­‰æ•¸æ“šï¼Ÿä½œç‚ºç†æ€§æŠ•è³‡è€…ï¼Œæˆ‘éœ€è¦å®¢è§€æ•¸æ“šä¾†æ”¯æŒæ±ºç­–ã€‚"
                ],
                "ä¸ƒæ®ºæ ¼": [
                    "åŸ·è¡Œæ•ˆç‡æ€éº¼æ¨£ï¼Ÿæˆ‘æ™‚é–“å¾ˆå¯¶è²´ï¼Œéœ€è¦çœ‹åˆ°å¿«é€Ÿè½åœ°çš„èƒ½åŠ›ã€‚",
                    "ç›´æ¥èªªé‡é»ï¼Œé€™å€‹èƒ½è§£æ±ºä»€éº¼å¸‚å ´ç—›é»ï¼Ÿåˆ¥è·Ÿæˆ‘ç¹åœˆå­ã€‚",
                    "ç«¶çˆ­å„ªå‹¢åœ¨å“ªï¼Ÿå¸‚å ´ä¸Šé¸æ“‡é€™éº¼å¤šï¼Œä½ æ†‘ä»€éº¼è®“æˆ‘é¸ä½ ï¼Ÿ",
                    "æˆ‘åªé—œå¿ƒçµæœã€‚å¦‚æœçœŸçš„æœ‰é€™éº¼å¤§çš„å¸‚å ´ï¼Œæˆ‘æœƒèªçœŸè€ƒæ…®ã€‚"
                ],
                "æ­£å°æ ¼": [
                    "é€™å°é•·æœŸç™¼å±•æœ‰å¹«åŠ©å—ï¼Ÿæˆ‘æ¯”è¼ƒçœ‹é‡é•·é åƒ¹å€¼å’Œç¤¾æœƒæ„ç¾©ã€‚",
                    "åœ˜éšŠçš„èƒŒæ™¯å’Œé¡˜æ™¯å¾ˆé‡è¦ï¼Œé€™å€‹è¨ˆåŠƒçœ‹èµ·ä¾†æœ‰ä¸€å®šçš„æ·±åº¦ã€‚",
                    "æœ‰æ²’æœ‰è¡Œæ¥­å°ˆå®¶çš„èƒŒæ›¸ï¼Ÿæˆ‘å¸Œæœ›èƒ½çœŸæ­£äº†è§£é€™å€‹é ˜åŸŸã€‚",
                    "æˆ‘æœƒå…ˆè«‹æ•™æœ‰ç¶“é©—çš„æœ‹å‹ï¼Œè½è½ä»–å€‘çš„å›é¥‹å†æ±ºå®šã€‚"
                ],
                "åå°æ ¼": [
                    "é€™å€‹æ¦‚å¿µæŒºç‰¹åˆ¥çš„ï¼Œè·Ÿå¸‚é¢ä¸Šçš„ä¸å¤ªä¸€æ¨£ã€‚æˆ‘å–œæ­¡æœ‰ç¨ç‰¹æƒ³æ³•çš„é …ç›®ã€‚",
                    "æœ‰é»æ„æ€ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šæ™‚é–“æ€è€ƒã€‚ç›´è¦ºå‘Šè¨´æˆ‘é€™å€‹æœ‰äº›é–€é“ã€‚",
                    "å•†æ¥­ç†å¿µå¾ˆæœ‰æ·±åº¦ï¼Œä¸æ˜¯ä¸€èˆ¬äººèƒ½é¦¬ä¸Šç†è§£çš„ã€‚é€™åè€Œå¸å¼•æˆ‘ã€‚",
                    "æˆ‘ä¸è·Ÿé¢¨æŠ•è³‡ï¼Œé€™å€‹é …ç›®æœ‰å®ƒç¨ç‰¹çš„æ°£è³ªã€‚"
                ],
                "æ¯”è‚©æ ¼": [
                    "é€™å€‹é ˜åŸŸæˆ‘èº«é‚Šæœ‰æœ‹å‹åœ¨åšï¼Œçœ‹ä¾†çœŸçš„æœ‰å¸‚å ´ã€‚å…±è­˜å¾ˆé‡è¦ã€‚",
                    "æˆ‘æœƒå•å•è¡Œæ¥­å…§çš„æœ‹å‹ï¼Œå¦‚æœä»–å€‘ä¹Ÿçœ‹å¥½ï¼Œæˆ‘å°±è·Ÿé€²ã€‚",
                    "é€™é¡å•†æ¥­æ¨¡å¼æˆ‘æœ‰è§€å¯Ÿéï¼Œé€™å€‹è¨ˆåŠƒåœ¨ä¸€äº›ç´°ç¯€ä¸Šæœ‰å‰µæ–°ã€‚",
                    "æ–¹å‘æ­£ç¢ºï¼ŒåŸ·è¡ŒåŠ›çœ‹èµ·ä¾†ä¹Ÿå¯ä»¥ï¼Œç¬¦åˆæˆ‘çš„é æœŸã€‚"
                ],
                "åŠ«è²¡æ ¼": [
                    "é€™å€‹å€¼å¾—è·ŸæŠ•è³‡åœˆæœ‹å‹åˆ†äº«ï¼å¥½é …ç›®å°±æ˜¯è¦ä¸€èµ·æŠ•æ‰æœ‰æ„æ€ã€‚",
                    "å¦‚æœæœ‰å…±åŒæŠ•è³‡çš„æ©Ÿæœƒï¼Œæˆ‘å¯ä»¥å¹«å¿™å°æ¥è³‡æºã€‚",
                    "æˆ‘å·²ç¶“æƒ³å¥½è¦æ¨è–¦çµ¦èª°äº†ï¼Œé€™å€‹è¨ˆåŠƒå‰›å¥½é©åˆå°æ–¹çš„æŠ•è³‡æ–¹å‘ã€‚",
                    "åˆä½œå…±è´å¾ˆé‡è¦ï¼é€™å€‹é …ç›®å¦‚æœèƒ½å»ºç«‹ç”Ÿæ…‹ç³»çµ±æœƒæ›´æœ‰åƒ¹å€¼ã€‚"
                ],
            }
            
            default_templates = [
                "é€™å€‹å•†æ¥­è¨ˆåŠƒç¢ºå¯¦æœ‰å®ƒçš„ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®åƒèˆ‡ï¼Œä½†é‚„éœ€è¦å†è§€å¯Ÿä¸€ä¸‹å¸‚å ´åæ‡‰ã€‚",
                "é¢¨éšªå¯æ§çš„è©±æˆ‘é¡˜æ„è©¦è©¦çœ‹ï¼Œç•¢ç«Ÿé€™å€‹é ˜åŸŸç¢ºå¯¦æœ‰æ©Ÿæœƒã€‚",
                "è¨ˆåŠƒæ›¸è »æœ‰æƒ³æ³•çš„ï¼Œå¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œé€™å€‹åƒ¹å€¼è©•ä¼°ç®—æ˜¯åˆç†çš„ã€‚",
                "æ•´é«”ä¾†èªªç¬¦åˆæˆ‘çš„é æœŸï¼Œä¸ç®—æœ€å‰µæ–°ä½†ä¹Ÿæ²’ä»€éº¼å¤§å•é¡Œï¼Œå¯ä»¥åˆ—å…¥è§€å¯Ÿæ¸…å–®ã€‚",
                "æˆ‘æœƒæŒçºŒé—œæ³¨é€™å€‹é …ç›®ï¼Œç­‰æ›´å¤šå¸‚å ´æ•¸æ“šå‡ºä¾†å†æ±ºå®šæ˜¯å¦æŠ•å…¥ã€‚",
                "ç¬¬ä¸€å°è±¡ä¸éŒ¯ï¼Œä½†æˆ‘ç¿’æ…£å¤šæ–¹é©—è­‰ï¼Œç¢ºä¿é€™æ˜¯æœ€ä½³æ¨™çš„å†å‡ºæ‰‹ã€‚",
                "å°æˆ‘ä¾†èªªé€™æ˜¯å€‹æ–°é ˜åŸŸï¼Œéœ€è¦æ›´å¤šäº†è§£ï¼Œä½†åœ˜éšŠçœ‹èµ·ä¾†æœ‰èª æ„ã€‚",
                "è¡Œæ¥­å…§æœ‰é¡ä¼¼æˆåŠŸæ¡ˆä¾‹ï¼Œé€™å€‹è¨ˆåŠƒçœ‹èµ·ä¾†ä¹Ÿå€¼å¾—ä¸€è©¦ã€‚"
            ]
            
            while len(arena_comments) < 8 and sampled_citizens:
                # æ‰¾ä¸€å€‹é‚„æ²’è©•è«–éçš„å¸‚æ°‘
                commented_names = {c.get("persona", {}).get("name", "") for c in arena_comments}
                remaining = [c for c in sampled_citizens if c["name"] not in commented_names]
                if not remaining:
                    break
                citizen = remaining[0]
                bazi = citizen["bazi_profile"]
                structure = bazi.get("structure", "")
                occupation = citizen.get("occupation", "")
                
                # æ ¹æ“šå…«å­—çµæ§‹é¸æ“‡è©•è«–æ¨¡æ¿
                templates = None
                for pattern, texts in bazi_comment_templates.items():
                    if pattern in structure:
                        templates = texts
                        break
                
                # æœ€å¾Œä½¿ç”¨é»˜èªæ¨¡æ¿
                if not templates:
                    templates = default_templates
                
                # éš¨æ©Ÿé¸æ“‡ä¸€æ¢è©•è«–
                text = random.choice(templates)
                
                # æ··åˆåˆ†é…æƒ…æ„Ÿ
                sentiments = ["positive", "positive", "neutral", "neutral", "negative"]
                sentiment = sentiments[len(arena_comments) % len(sentiments)]
                
                # è£œå…¨å¸‚æ°‘è³‡æ–™
                age = citizen.get("age", 30)
                luck_timeline, current_luck = build_luck_data(bazi, age)
                
                # ç”Ÿæˆå››æŸ±è³‡æ–™
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                
                arena_comments.append({
                    "sentiment": sentiment,
                    "text": text,
                    "persona": {
                        "id": str(citizen.get("id", random.randint(1, 1000))),
                        "name": citizen["name"],
                        "age": str(age),
                        "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                        "element": bazi.get("element", "Fire"),
                        "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                        "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                        "location": citizen.get("location", "å°ç£"),
                        "birth_year": bazi.get("birth_year"),
                        "birth_month": bazi.get("birth_month"),
                        "birth_day": bazi.get("birth_day"),
                        "birth_shichen": bazi.get("birth_shichen"),
                        "four_pillars": pillars_str,
                        "day_master": bazi.get("day_master", "æœªçŸ¥"),
                        "strength": bazi.get("strength", "ä¸­å’Œ"),
                        "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                        "current_luck": current_luck,
                        "luck_timeline": luck_timeline
                    }
                })
                print(f"[Core TEXT] Added fallback comment #{len(arena_comments)}: {citizen['name']}")
            
            # 9. æ§‹å»ºæœ€çµ‚çµæœ (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            score = data.get("result", {}).get("score", 70)
            if score > 98: score = 98 # Clamp score to reasonable max
            if score < 10 and source_type == "text": score = 65 # Default for text if too low
            
            result_data = {
                "status": "ready",
                "score": score,
                "intent": data.get("result", {}).get("market_sentiment", "åˆ†æå®Œæˆ"),
                "summary": data.get("result", {}).get("summary", "AI åˆ†æå®Œæˆ"),
                "simulation_metadata": sim_metadata,
                "genesis": {
                     "total_population": 1000,
                     "sample_size": len(personas),
                     "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            # ğŸ§¬ [Sidecar] è¿½åŠ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–è©®é‡‹å±¤
            methodology_sidecar = _generate_methodology_sidecar(
                score=result_data.get("score"),
                summary=result_data.get("summary")
            )
            result_data["methodology_data"] = methodology_sidecar
            
            # 10. æ›´æ–°è³‡æ–™åº«
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            print(f"âœ… [Core TEXT] Document analysis completed: {sim_id}, comments: {len(arena_comments)}, score: {score}")

        except Exception as e:
            print(f"[Core TEXT] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    async def run_simulation_with_audio_data(self, audio_bytes: bytes, sim_id: str, audio_format: str = "webm"):
        """è™•ç†èªéŸ³éŒ„éŸ³çš„å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æ (éŒ„éŸ³ â†’ è½‰æ–‡å­— â†’ åˆ†æ)"""
        try:
            from fastapi.concurrency import run_in_threadpool
            
            # 1. ä½¿ç”¨ Gemini å°‡éŸ³è¨Šè½‰æ–‡å­—
            audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
            
            transcription_prompt = """è«‹è½å–é€™æ®µèªéŸ³éŒ„éŸ³ï¼Œä¸¦å°‡å…¶å®Œæ•´è½‰éŒ„ç‚ºç¹é«”ä¸­æ–‡æ–‡å­—ã€‚
            
é€™æ˜¯ä¸€æ®µé—œæ–¼å•†æ¥­è¨ˆåŠƒæˆ–ç”¢å“æƒ³æ³•çš„éŒ„éŸ³ã€‚è«‹ï¼š
1. å®Œæ•´è½‰éŒ„æ‰€æœ‰å£èªªå…§å®¹
2. ä½¿ç”¨ç¹é«”ä¸­æ–‡
3. ä¿æŒåŸæ„ï¼Œé©ç•¶åŠ å…¥æ¨™é»ç¬¦è™Ÿè®“å…§å®¹æ›´æ˜“è®€
4. å¦‚æœæœ‰å£åƒæˆ–é‡è¤‡çš„éƒ¨åˆ†ï¼Œè«‹æ•´ç†ç‚ºé †æš¢çš„æ–‡å­—

ç›´æ¥è¼¸å‡ºè½‰éŒ„å¾Œçš„æ–‡å­—å…§å®¹ï¼Œä¸è¦æœ‰ä»»ä½•é¡å¤–èªªæ˜ã€‚"""

            api_key = settings.GOOGLE_API_KEY
            
            # éŸ³è¨Š MIME é¡å‹å°æ‡‰
            audio_mime_map = {
                "webm": "audio/webm",
                "mp3": "audio/mp3",
                "wav": "audio/wav",
                "m4a": "audio/mp4",
                "ogg": "audio/ogg"
            }
            audio_mime = audio_mime_map.get(audio_format, "audio/webm")
            
            # å‘¼å« Gemini é€²è¡ŒèªéŸ³è½‰æ–‡å­—
            transcribed_text, error = await asyncio.to_thread(
                self._run_blocking_gemini_request_audio,
                api_key,
                transcription_prompt,
                audio_b64,
                audio_mime
            )
            
            if not transcribed_text:
                self._handle_error_db(sim_id, f"Voice Transcription Failed: {error}")
                return
            
            print(f"[Audio] Transcribed {len(transcribed_text)} characters")
            
            # 2. ä½¿ç”¨è½‰éŒ„çš„æ–‡å­—é€²è¡Œå•†æ¥­åˆ†æ
            await self.run_simulation_with_text_data(transcribed_text, sim_id, "voice")

        except Exception as e:
            print(f"[Core AUDIO] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    def _run_blocking_gemini_request_audio(self, api_key, prompt, audio_b64, audio_mime):
        """Blocking Gemini API call for audio transcription"""
        import requests
        
        print(f"[DEBUG AUDIO] Starting audio transcription, audio size: {len(audio_b64)} chars, mime: {audio_mime}")
        
        # [Restore] Prioritize Gemini 2.5 Pro for Quality
        models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
        last_error = None
        
        for model in models:
            try:
                print(f"[DEBUG AUDIO] Trying model: {model}")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                payload = {
                    "contents": [{
                        "parts": [
                            {"text": prompt},
                            {"inline_data": {"mime_type": audio_mime, "data": audio_b64}}
                        ]
                    }],
                    "generationConfig": {"temperature": 0.1}
                }
                
                response = requests.post(url, json=payload, headers={"Content-Type": "application/json"}, timeout=120)
                print(f"[DEBUG AUDIO] {model} response status: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        result_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                        print(f"[DEBUG AUDIO] Successfully transcribed: {len(result_text)} chars")
                        return result_text, None
                    except Exception as parse_err:
                        print(f"[DEBUG AUDIO] Parse error: {parse_err}, response: {response.text[:500]}")
                        continue
                else:
                    error_msg = f"{model}: {response.status_code} - {response.text[:300]}"
                    print(f"[DEBUG AUDIO] API Error: {error_msg}")
                    last_error = error_msg
            except Exception as e:
                print(f"[DEBUG AUDIO] Exception: {str(e)}")
                last_error = str(e)
        
        print(f"[DEBUG AUDIO] All models failed. Last error: {last_error}")
        return None, last_error


    # ===== Helpers =====

    async def _call_gemini_rest(self, api_key, prompt, image_b64=None, pdf_b64=None, mime_type="image/jpeg", timeout=60, image_parts=None):
        """Helper to call Gemini REST API (Async Wrapper)"""
        # [Fix] Prioritize Gemini 2.5 Pro as requested by the user
        priority = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
        
        return await asyncio.to_thread(
            self._run_blocking_gemini_request,
            api_key, 
            prompt, 
            image_b64, 
            pdf_b64, 
            priority,
            mime_type,
            image_parts # Pass image_parts
        )

    def _clean_and_parse_json(self, ai_text):
        """Helper to clean and parse JSON with robust error handling"""
        if not ai_text or not isinstance(ai_text, str):
            logger.error(f"Invalid AI text input for parsing: {type(ai_text)}")
            return {"result": {}, "arena_comments": [], "genesis": {}, "simulation_metadata": {}, "comments": [], "suggestions": []}

        clean_text = ai_text
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", ai_text, re.DOTALL)
        if match:
            clean_text = match.group(1)
        
        try:
            data = json.loads(clean_text)
            if isinstance(data, dict):
                return data
            else:
                logger.error(f"Gemini returned non-dict JSON: {type(data)}")
                return {}
        except json.JSONDecodeError:
            # Simple fix attempt
            fixed_text = clean_text.strip()
            if fixed_text.count('{') > fixed_text.count('}'): fixed_text += '}' * (fixed_text.count('{') - fixed_text.count('}'))
            if fixed_text.count('[') > fixed_text.count(']'): fixed_text += ']' * (fixed_text.count('[') - fixed_text.count(']'))
            try:
                data = json.loads(fixed_text)
                if isinstance(data, dict):
                    return data
                return {}
            except:
                logger.error(f"Failed to parse AI JSON after cleaning: {clean_text[:200]}")
                return {}

    def _build_simulation_result(self, data, sampled_citizens, sim_metadata_override=None):
        """Helper to build final result structure"""
        # Logic extracted from original code to build result_data
        # ... simplified for brevity as it copies logic ...
        
        # Reconstruct Bazi distribution
        element_counts = {"Fire": 0, "Water": 0, "Metal": 0, "Wood": 0, "Earth": 0}
        for c in sampled_citizens:
            elem = c["bazi_profile"].get("element", "Fire")
            if elem in element_counts: element_counts[elem] += 1
        total = len(sampled_citizens)
        bazi_dist = {k: round(v / total * 100) for k, v in element_counts.items()} if total else element_counts

        # Build Personas (Ensure enough for the display)
        # é€™è£¡ä¸é™åˆ¶åªå– 8 å€‹ï¼Œè€Œæ˜¯ç¶­æŒèˆ‡ arena_comments çš„åŒæ­¥
        personas_dict = {}
        for c in sampled_citizens:
            bazi = c.get("bazi_profile", {})
            personas_dict[str(c["id"])] = {
                "id": str(c["id"]),
                "name": c["name"],
                "age": c["age"],
                "location": c.get("location", "å°ç£"),
                "occupation": c.get("occupation", "æœªçŸ¥è·æ¥­"),
                "element": bazi.get("element", "Fire"),
                "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                "day_master": bazi.get("day_master", ""),
                "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                "trait": ", ".join(c["traits"][:2]) if c.get("traits") else "å€‹æ€§é®®æ˜",
                "decision_logic": "æ ¹æ“šå…«å­—æ ¼å±€ç‰¹è³ªåˆ†æ",
                "current_luck": bazi.get("current_luck", {}),
                "luck_timeline": bazi.get("luck_timeline", []),
                # å®Œæ•´ç”Ÿè¾°è³‡æ–™
                "birth_year": bazi.get("birth_year"),
                "birth_month": bazi.get("birth_month"),
                "birth_day": bazi.get("birth_day"),
                "birth_shichen": bazi.get("birth_shichen"),
                "four_pillars": bazi.get("four_pillars"),
                "strength": bazi.get("strength", "ä¸­å’Œ"),
                "favorable": bazi.get("favorable", ["æœ¨", "ç«"])
            }
        
        # Build comments
        gemini_comments = data.get("comments", [])
        arena_comments = []
        # å¼·åˆ¶ Key ç‚º String ä»¥é˜²è¬ä¸€
        citizen_map = {str(c["id"]): c for c in sampled_citizens}
        
        for comment in gemini_comments:
            raw_id = comment.get("citizen_id")
            c_id = str(raw_id) if raw_id is not None else ""
            
            # 1. å˜—è©¦ç”¨ ID ç›´æ¥åŒ¹é…
            citizen = citizen_map.get(c_id)
            
            # 2. å¦‚æœæ‰¾ä¸åˆ°ï¼Œä¸” ID æ˜¯æ•¸å­—ï¼Œå˜—è©¦ç”¨ Index åŒ¹é… (é‡å° Gemini è¿”å› 0, 1, 2... çš„æƒ…æ³)
            if not citizen and c_id.isdigit():
                idx = int(c_id)
                # Gemini æœ‰æ™‚æ˜¯ 1-based index
                if 0 <= idx < len(sampled_citizens):
                    citizen = sampled_citizens[idx]
                elif 0 < idx <= len(sampled_citizens): # Handle 1-based
                    citizen = sampled_citizens[idx-1]
            
            if citizen:
                bazi = citizen["bazi_profile"]
                
                # Auto-fill missing birthday data
                import random
                if not bazi.get("birth_year"):
                    try:
                        age = int(citizen.get("age", 30))
                    except:
                        age = 30
                    bazi["birth_year"] = 2025 - age
                    bazi["birth_month"] = random.randint(1, 12)
                    bazi["birth_day"] = random.randint(1, 28)
                    bazi["birth_shichen"] = random.choice(["å­æ™‚", "ä¸‘æ™‚", "å¯…æ™‚", "å¯æ™‚", "è¾°æ™‚", "å·³æ™‚", "åˆæ™‚", "æœªæ™‚", "ç”³æ™‚", "é…‰æ™‚", "æˆŒæ™‚", "äº¥æ™‚"])

                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å‘½ç›¤ï¼Œéš¨æ©Ÿç”Ÿæˆ
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    logger.warning(f"Citizen {citizen['name']} missing four_pillars, auto-generating...")
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                    bazi["four_pillars"] = pillars_str
                
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å¤§é‹ï¼Œç”Ÿæˆé»˜èªå¤§é‹
                timeline = bazi.get("luck_timeline")
                if not timeline:
                     # å˜—è©¦å¾ luck_pillars ç”Ÿæˆ
                     if bazi.get("luck_pillars"):
                         timeline = []
                         for l in bazi["luck_pillars"]:
                             name = l.get('pillar', 'ç”²å­') + "é‹"
                             desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                             timeline.append({
                                 "age_start": l.get('age_start', 0),
                                 "age_end": l.get('age_end', 9),
                                 "name": name,
                                 "description": desc
                             })
                     else:
                         # å®Œå…¨éš¨æ©Ÿç”Ÿæˆ
                         start_age = random.randint(2, 9)
                         pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                         timeline = []
                         for i in range(8):
                             p_name = f"{pillars_pool[(i+random.randint(0,5))%len(pillars_pool)]}é‹"
                             timeline.append({
                                 "age_start": start_age + i*10,
                                 "age_end": start_age + i*10 + 9,
                                 "name": p_name,
                                 "description": "è¡Œé‹å¹³ç©©ï¼Œé †å…¶è‡ªç„¶ã€‚"
                             })
                     bazi["luck_timeline"] = timeline
                
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ current_luckï¼Œå¾ timeline ä¸­è¨ˆç®—
                current_luck = bazi.get("current_luck")
                if not isinstance(current_luck, dict):
                    current_luck = {}
                
                if not current_luck or not current_luck.get("description"):
                    try:
                        citizen_age = int(citizen.get("age", 30))
                    except:
                        citizen_age = 30
                    for lt in timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                    if not current_luck and timeline:
                        current_luck = {"name": timeline[0]["name"], "description": timeline[0]["description"]}
                    bazi["current_luck"] = current_luck

                # ID é˜²ç¦¦
                cid = str(citizen.get("id")) if citizen.get("id") else f"gen-{random.randint(1000,9999)}"

                arena_comments.append({
                    "sentiment": comment.get("sentiment", "neutral"),
                    "text": comment.get("text", "ï¼ˆç„¡è©•è«–å…§å®¹ï¼‰"),
                    "persona": personas_dict.get(cid)
                })
                
                # DEBUG LOG
                logger.info(f"Generated Primary Comment Persona: Name={citizen['name']}, ID={cid}, Birth={bazi.get('birth_year')}")

        # Ensure personas list for genesis is synced with the comments
        personas = [c["persona"] for c in arena_comments if c.get("persona")]

        # Fallback comments if not enough (ensure at least 8)
        # å¤§å¹…å¢åŠ è©•è«–æ¨¡æ¿ï¼Œæ›´è±å¯Œã€æ›´ç¬¦åˆå…«å­—å€‹æ€§
        bazi_comment_templates = {
            "é£Ÿç¥æ ¼": [
                "é€™ç”¢å“çœ‹èµ·ä¾†æŒºæœ‰è³ªæ„Ÿçš„ï¼Œç”¨èµ·ä¾†æ‡‰è©²å¾ˆäº«å—ï¼ç‰¹åˆ¥å–œæ­¡å®ƒçš„è¨­è¨ˆæ„Ÿï¼Œæ¯å¤©ä½¿ç”¨å¿ƒæƒ…éƒ½æœƒå¾ˆå¥½ã€‚",
                "å“‡ï¼Œé€™è¨­è¨ˆè »æœ‰å“å‘³çš„ï¼æˆ‘ä¸€å‘æ³¨é‡ç”Ÿæ´»å“è³ªï¼Œé€™ç¨®ç´°ç¯€è™•ç†å¾—ä¸éŒ¯ï¼Œå€¼å¾—å…¥æ‰‹ã€‚",
                "æˆ‘æ¯”è¼ƒåœ¨æ„ä½¿ç”¨é«”é©—ï¼Œé€™å€‹ç”¢å“å¾å¤–è§€åˆ°æ‰‹æ„Ÿéƒ½å¾ˆèˆ’æœï¼Œæ„Ÿè¦ºæœƒæ˜¯ç”Ÿæ´»ä¸­çš„å°ç¢ºå¹¸ã€‚",
                "ä½œç‚ºä¸€å€‹æ„›å¥½è€…ï¼Œæˆ‘è¦ºå¾—é€™å€‹ç”¢å“å¾ˆç™‚ç™’ï¼Œå…‰æ˜¯çœ‹è‘—å°±å¾ˆé–‹å¿ƒï¼Œå¯¦ç”¨æ€§å€’æ˜¯å…¶æ¬¡ã€‚"
            ],
            "å‚·å®˜æ ¼": [
                "è¨­è¨ˆé‚„å¯ä»¥ï¼Œä½†æˆ‘è¦ºå¾—æœ‰äº›åœ°æ–¹å¯ä»¥æ›´æœ‰å‰µæ„ä¸€é»ã€‚ä¸éæ•´é«”ä¾†èªªé‚„æ˜¯æœ‰å®ƒçš„ç‰¹è‰²ã€‚",
                "å—¯...æˆ‘æœ‰ä¸€äº›æ”¹é€²çš„æƒ³æ³•ï¼šå¦‚æœèƒ½åŠ å¼·æŸäº›åŠŸèƒ½æœƒæ›´å®Œç¾ã€‚ä¸éæ¦‚å¿µæ˜¯å¥½çš„ã€‚",
                "èªªå¯¦è©±ï¼Œå¸‚é¢ä¸Šé¡ä¼¼çš„ç”¢å“å¾ˆå¤šï¼Œé€™å€‹éœ€è¦åšå‡ºå·®ç•°åŒ–æ‰èƒ½çœŸæ­£å¸å¼•æˆ‘ã€‚",
                "æˆ‘æ¬£è³å‰µæ–°çš„å˜—è©¦ï¼Œä½†åŸ·è¡Œé¢é‚„æœ‰é€²æ­¥ç©ºé–“ã€‚æ½›åŠ›æ˜¯æœ‰çš„ï¼Œå°±çœ‹å¾ŒçºŒè¿­ä»£äº†ã€‚"
            ],
            "æ­£è²¡æ ¼": [
                "CPå€¼å¦‚ä½•ï¼Ÿæˆ‘æ¯”è¼ƒåœ¨æ„æ€§åƒ¹æ¯”ã€‚é€™å€‹åƒ¹æ ¼å¦‚æœå“è³ªç©©å®šï¼Œæˆ‘æœƒè€ƒæ…®å…¥æ‰‹ã€‚",
                "åƒ¹æ ¼å’Œå“è³ªçš„å¹³è¡¡å¾ˆé‡è¦ï¼Œé€™å€‹çœ‹èµ·ä¾†é‚„å¯ä»¥ã€‚å¸Œæœ›ç”¨æ–™å¯¦åœ¨ï¼Œä¸æ˜¯è™›æœ‰å…¶è¡¨ã€‚",
                "ä½œç‚ºä¸€å€‹å‹™å¯¦çš„äººï¼Œæˆ‘æœƒå…ˆçœ‹è©•åƒ¹å’Œå£ç¢‘ï¼Œç¢ºä¿æ¯ä¸€åˆ†éŒ¢éƒ½èŠ±å¾—å€¼å¾—ã€‚",
                "æˆ‘æœƒåšåŠŸèª²æ¯”è¼ƒå¹¾å®¶å†æ±ºå®šã€‚é€™å€‹å¦‚æœæœ‰å„ªæƒ æˆ–åˆ†æœŸï¼Œå¸å¼•åŠ›æœƒæ›´å¤§ã€‚"
            ],
            "åè²¡æ ¼": [
                "æ„Ÿè¦ºæœ‰æ½›åŠ›ï¼å¯ä»¥è€ƒæ…®æŠ•è³‡çœ‹çœ‹ã€‚é€™å€‹å¸‚å ´å®šä½è »è°æ˜çš„ï¼ŒæŠ“ä½äº†ç—›é»ã€‚",
                "é€™å€‹åˆ‡å…¥é»ä¸éŒ¯ï¼Œå•†æ©Ÿè »å¤§çš„ï¼å¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œç™¼å±•å‰æ™¯çœ‹å¥½ã€‚",
                "æˆ‘çœ‹åˆ°äº†æ©Ÿæœƒï¼é€™é¡ç”¢å“ç¾åœ¨æ­£æµè¡Œï¼Œæ™‚æ©Ÿé»æŠ“å¾—ä¸éŒ¯ï¼Œå€¼å¾—é—œæ³¨ã€‚",
                "æœ‰æ„æ€ï¼é€™å€‹å¦‚æœèƒ½åšæˆç³»åˆ—ç”¢å“æˆ–æ‰“é€ å“ç‰Œï¼Œæœªä¾†å¢å€¼ç©ºé–“å¾ˆå¤§ã€‚"
            ],
            "æ­£å®˜æ ¼": [
                "å“è³ªå’Œè¦æ ¼éƒ½ç¬¦åˆæ¨™æº–å—ï¼Ÿæˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªå„é …èªè­‰å’Œä¿å›ºæ¢æ¬¾ã€‚",
                "éœ€è¦å¤šäº†è§£ä¸€ä¸‹ç´°ç¯€ï¼Œå†åšæ±ºå®šã€‚ç©©å®šæ€§å’Œå”®å¾Œæœå‹™æ˜¯æˆ‘æœ€åœ¨æ„çš„ã€‚",
                "é€™å€‹å“ç‰Œå£ç¢‘å¦‚ä½•ï¼Ÿæˆ‘å‚¾å‘é¸æ“‡æœ‰ä¿¡è­½çš„å» å•†ï¼Œé€™æ¨£æ›´æœ‰ä¿éšœã€‚",
                "æœ‰æ²’æœ‰å°ˆæ¥­æ¸¬è©¦å ±å‘Šï¼Ÿä½œç‚ºç†æ€§æ¶ˆè²»è€…ï¼Œæˆ‘éœ€è¦å®¢è§€æ•¸æ“šä¾†æ”¯æŒè³¼è²·æ±ºå®šã€‚"
            ],
            "ä¸ƒæ®ºæ ¼": [
                "ç›´æ¥èªªé‡é»ï¼Œé€™æ±è¥¿èƒ½ä¸èƒ½è§£æ±ºå¯¦éš›ç—›é»ï¼Ÿå¦‚æœæ˜¯ç‚ºäº†è™›æ¦®å¿ƒè²·çš„ï¼Œæˆ‘æ²’èˆˆè¶£ã€‚æ•ˆç‡å’Œçµæœæ‰æ˜¯æˆ‘æœ€åœ¨æ„çš„ï¼Œæˆ‘éœ€è¦èƒ½æ‰“ä»—çš„å·¥å…·ã€‚",
                "åˆ¥è·Ÿæˆ‘ç¹åœˆå­ï¼Œå¸‚å ´å„ªå‹¢åœ¨å“ªï¼Ÿæ†‘ä»€éº¼è®“æˆ‘é¸ä½ ï¼Ÿå¦‚æœçœŸçš„æœ‰ç¡¬å¯¦åŠ›ï¼Œæˆ‘æœƒæ¯«ä¸çŒ¶è±«ä¸‹å–®ï¼Œå¦å‰‡åˆ¥æµªè²»æˆ‘æ™‚é–“ã€‚",
                "æˆ‘åªé—œå¿ƒæ€§èƒ½å’Œå›å ±ã€‚é€™ç”¢å“å¦‚æœèƒ½å¹«æˆ‘çœä¸‹ 20% çš„æ™‚é–“ï¼Œé‚£å®ƒå°±å€¼é€™å€‹åƒ¹ã€‚åŸ·è¡ŒåŠ›ä¸è¶³çš„æ–¹æ¡ˆï¼Œæˆ‘çœ‹éƒ½ä¸çœ‹ã€‚",
                "é€™æ±è¥¿çœ‹èµ·ä¾†å¾ˆæœ‰ä¾µç•¥æ€§ï¼Œé©åˆé–‹æ‹“æ–°å¸‚å ´ã€‚æˆ‘å–œæ­¡é€™ç¨®å¸¶æœ‰çªç ´æ€§çš„è¨­è¨ˆï¼Œåªè¦å®ƒèƒ½æ‰›å¾—èµ·é«˜å¼·åº¦çš„å£“åŠ›ã€‚"
            ],
            "æ­£å°æ ¼": [
                "é€™å°é•·æœŸç™¼å±•æœ‰å¹«åŠ©å—ï¼Ÿæˆ‘æ¯”è¼ƒçœ‹é‡é•·é åƒ¹å€¼ï¼Œä¸å–œæ­¡æ›‡èŠ±ä¸€ç¾çš„æ±è¥¿ã€‚",
                "å“ç‰Œä¿¡è­½å¾ˆé‡è¦ï¼Œé€™å€‹å…¬å¸å¯é å—ï¼Ÿæˆ‘å¯§å¯å¤šèŠ±é»éŒ¢ä¹Ÿè¦è²·å®‰å¿ƒã€‚",
                "æœ‰æ²’æœ‰å­¸ç¿’è³‡æºæˆ–ä½¿ç”¨æŒ‡å—ï¼Ÿæˆ‘å¸Œæœ›èƒ½çœŸæ­£äº†è§£å’ŒæŒæ¡é€™å€‹ç”¢å“ã€‚",
                "æˆ‘æœƒå…ˆè«‹æ•™æœ‰ç¶“é©—çš„æœ‹å‹ï¼Œè½è½ä»–å€‘çš„æ„è¦‹å†æ±ºå®šã€‚è¬¹æ…ä¸€é»ç¸½æ˜¯å¥½çš„ã€‚"
            ],
            "åå°æ ¼": [
                "é€™å€‹æ¦‚å¿µæŒºç‰¹åˆ¥çš„ï¼Œè·Ÿå¸‚é¢ä¸Šçš„ä¸å¤ªä¸€æ¨£ã€‚æˆ‘å–œæ­¡æœ‰ç¨ç‰¹æƒ³æ³•çš„ç”¢å“ã€‚",
                "æœ‰é»æ„æ€ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šæ™‚é–“æ€è€ƒã€‚ç›´è¦ºå‘Šè¨´æˆ‘é€™å€‹æœ‰äº›é–€é“ã€‚",
                "è¨­è¨ˆç†å¿µå¾ˆæœ‰æ·±åº¦ï¼Œä¸æ˜¯ä¸€èˆ¬å¤§çœ¾èƒ½é¦¬ä¸Šç†è§£çš„ã€‚é€™åè€Œå¸å¼•æˆ‘ã€‚",
                "æˆ‘ä¸è·Ÿé¢¨ï¼Œé€™å€‹ç”¢å“æœ‰å®ƒç¨ç‰¹çš„æ°£è³ªï¼Œé©åˆæœ‰å“å‘³çš„äººã€‚"
            ],
            "æ¯”è‚©æ ¼": [
                "é€™å€‹æˆ‘èº«é‚Šå¾ˆå¤šæœ‹å‹éƒ½åœ¨ç”¨ï¼Œçœ‹ä¾†çœŸçš„ä¸éŒ¯ã€‚å¤§å®¶èªªå¥½æ‰æ˜¯çœŸçš„å¥½ã€‚",
                "æˆ‘æœƒå•å•åŒäº‹çš„æ„è¦‹ï¼Œå¦‚æœä»–å€‘ä¹Ÿè¦ºå¾—å¯ä»¥ï¼Œæˆ‘å°±è·Ÿä¸€æ³¢ã€‚",
                "é€™é¡ç”¢å“æˆ‘æœ‰ä½¿ç”¨ç¶“é©—ï¼Œé€™å€‹æ–°å“çœ‹èµ·ä¾†åœ¨ä¸€äº›ç´°ç¯€ä¸Šæœ‰é€²æ­¥ã€‚",
                "åƒ¹æ ¼å…¬é“ï¼Œå“è³ªéå¾—å»ï¼Œç¬¦åˆæˆ‘çš„é æœŸã€‚ä¸æ±‚æœ€å¥½ï¼Œä½†æ±‚å¯¦ç”¨ã€‚"
            ],
            "åŠ«è²¡æ ¼": [
                "é€™å€‹å€¼å¾—è·Ÿæœ‹å‹å€‘åˆ†äº«ï¼å¥½æ±è¥¿å°±æ˜¯è¦ä¸€èµ·ç”¨æ‰æœ‰æ„æ€ã€‚",
                "å¦‚æœæœ‰åœ˜è³¼æˆ–å„ªæƒ æ´»å‹•ï¼Œæˆ‘å¯ä»¥å¹«å¿™æªäººï¼Œå¤§å®¶ä¸€èµ·è²·æ›´åˆ’ç®—ã€‚",
                "æˆ‘å·²ç¶“æƒ³å¥½è¦æ¨è–¦çµ¦èª°äº†ï¼Œé€™å€‹ç”¢å“å‰›å¥½é©åˆæˆ‘å¹¾å€‹æœ‹å‹çš„éœ€æ±‚ã€‚",
                "ç”Ÿæ´»å˜›ï¼Œé–‹å¿ƒæœ€é‡è¦ï¼é€™å€‹èƒ½è®“æœ‹å‹èšæœƒæ›´æœ‰è¶£ï¼Œå€¼å¾—å…¥æ‰‹ã€‚"
            ],
        }
        
        # æ ¹æ“šè·æ¥­å¢åŠ æ›´å¤šå€‹æ€§åŒ–è©•è«–
        occupation_comments = {
            "å·¥ç¨‹å¸«": "å¾æŠ€è¡“è§’åº¦ä¾†çœ‹ï¼Œé€™å€‹ç”¢å“çš„è¨­è¨ˆé‚è¼¯æ˜¯åˆç†çš„ï¼ŒåŸ·è¡Œé¢ä¹Ÿä¸éŒ¯ã€‚",
            "è¨­è¨ˆå¸«": "è¦–è¦ºå‘ˆç¾è »æœ‰è³ªæ„Ÿçš„ï¼Œè‰²å½©æ­é…å’Œæ’ç‰ˆéƒ½å¾ˆç”¨å¿ƒï¼Œçœ‹å¾—å‡ºå°ˆæ¥­åº¦ã€‚",
            "è€å¸«": "é€™å€‹å°å­¸ç”Ÿæˆ–å®¶åº­ä¾†èªªå¯¦ç”¨å—ï¼Ÿæˆ‘æœƒè€ƒæ…®æ•™è‚²æ„ç¾©å’Œå®‰å…¨æ€§ã€‚",
            "é†«ç”Ÿ": "å¥åº·ç›¸é—œçš„ç”¢å“æˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªæœ‰ç„¡ç›¸é—œèªè­‰ã€‚",
            "å‰µæ¥­å®¶": "å•†æ¥­æ¨¡å¼æœ‰å‰µæ„ï¼Œå¦‚æœèƒ½è§£æ±ºçœŸæ­£çš„å¸‚å ´ç—›é»ï¼Œæœƒæœ‰ç™¼å±•ç©ºé–“ã€‚",
            "å­¸ç”Ÿ": "åƒ¹æ ¼æ˜¯æˆ‘æœ€åœ¨æ„çš„ï¼Œå¦‚æœæœ‰å­¸ç”Ÿå„ªæƒ å°±æ›´å¥½äº†ï¼",
            "ç¶“ç†": "åœ˜éšŠå”ä½œæ–¹é¢æœ‰å„ªå‹¢å—ï¼Ÿæˆ‘æœƒè€ƒæ…®å°å…¥å…¬å¸ä½¿ç”¨çš„å¯èƒ½æ€§ã€‚",
            "è‡ªç”±æ¥­": "éˆæ´»æ€§å¾ˆé‡è¦ï¼Œé€™å€‹èƒ½é…åˆæˆ‘ä¸å›ºå®šçš„å·¥ä½œæ¨¡å¼å—ï¼Ÿ",
        }
        
        default_templates = [
            "é€™å€‹ç”¢å“ç¢ºå¯¦æœ‰å®ƒçš„ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®è³¼è²·ï¼Œä½†é‚„éœ€è¦å†è§€å¯Ÿä¸€ä¸‹å¸‚å ´åæ‡‰ã€‚",
            "åƒ¹æ ¼åˆç†çš„è©±æˆ‘é¡˜æ„è©¦è©¦çœ‹ï¼Œç•¢ç«Ÿå˜—è©¦æ–°æ±è¥¿ä¹Ÿæ˜¯ä¸€ç¨®ç”Ÿæ´»æ…‹åº¦ã€‚",
            "è¨­è¨ˆè »æœ‰æƒ³æ³•çš„ï¼Œå¦‚æœè³ªé‡ç©©å®šï¼Œé€™å€‹åƒ¹ä½ç®—æ˜¯å¯ä»¥æ¥å—çš„é¸æ“‡ã€‚",
            "æ•´é«”ä¾†èªªç¬¦åˆæˆ‘çš„é æœŸï¼Œä¸ç®—é©šè‰·ä½†ä¹Ÿæ²’ä»€éº¼å¤§å•é¡Œï¼Œå¯ä»¥åˆ—å…¥è³¼ç‰©æ¸…å–®ã€‚",
            "æˆ‘æœƒæŒçºŒé—œæ³¨é€™å€‹ç”¢å“ï¼Œç­‰æ›´å¤šç”¨æˆ¶è©•åƒ¹å‡ºä¾†å†æ±ºå®šæ˜¯å¦å…¥æ‰‹ã€‚",
            "ç¬¬ä¸€å°è±¡ä¸éŒ¯ï¼Œä½†æˆ‘ç¿’æ…£è²¨æ¯”ä¸‰å®¶ï¼Œç¢ºä¿é€™æ˜¯æœ€ä½³é¸æ“‡å†ä¸‹æ‰‹ã€‚",
            "å°æˆ‘ä¾†èªªé€™æ˜¯å€‹æ–°é ˜åŸŸï¼Œéœ€è¦æ›´å¤šäº†è§£ï¼Œä½†ç”¢å“æœ¬èº«çœ‹èµ·ä¾†æœ‰èª æ„ã€‚",
            "æœ‹å‹æ¨è–¦éé¡ä¼¼çš„ç”¢å“ï¼Œé€™å€‹çœ‹èµ·ä¾†ä¹Ÿå€¼å¾—ä¸€è©¦ï¼Œè€ƒæ…®ä¸­ã€‚"
        ]
        
        import random as rand_module
        while len(arena_comments) < 8 and sampled_citizens:
            # æ‰¾ä¸€å€‹é‚„æ²’è©•è«–éçš„å¸‚æ°‘
            commented_names = {c["persona"]["name"] for c in arena_comments}
            remaining = [c for c in sampled_citizens if c["name"] not in commented_names]
            if not remaining:
                break
            citizen = remaining[0]
            bazi = citizen["bazi_profile"]
            structure = bazi.get("structure", "")
            occupation = citizen.get("occupation", "")
            
            # æ ¹æ“šå…«å­—çµæ§‹é¸æ“‡è©•è«–æ¨¡æ¿
            templates = None
            for pattern, texts in bazi_comment_templates.items():
                if pattern in structure:
                    templates = texts
                    break
            
            # å¦‚æœæ²’æœ‰åŒ¹é…çš„å…«å­—æ ¼å±€ï¼Œå˜—è©¦è·æ¥­åŒ¹é…
            if not templates:
                for occ, comment in occupation_comments.items():
                    if occ in occupation:
                        templates = [comment]
                        break
            
            # æœ€å¾Œä½¿ç”¨é»˜èªæ¨¡æ¿
            if not templates:
                templates = default_templates
            
            # éš¨æ©Ÿé¸æ“‡ä¸€æ¢è©•è«–ï¼Œé¿å…é‡è¤‡
            text = rand_module.choice(templates)
            
            # æ··åˆåˆ†é…æƒ…æ„Ÿ
            sentiments = ["positive", "positive", "neutral", "neutral", "negative"]
            sentiment = sentiments[len(arena_comments) % len(sentiments)]
            
            # å®šç¾© pillars_str
            pillars_str = bazi.get("four_pillars")
            if not pillars_str:
                pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                import random as rand_mod
                pillars_str = f"{rand_mod.choice(pillars)} {rand_mod.choice(pillars)} {rand_mod.choice(pillars)} {rand_mod.choice(pillars)}"
            
            # å–å¾— luck_timeline
            timeline = bazi.get("luck_timeline", [])
            
            # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ luck_timelineï¼Œç”Ÿæˆé è¨­è³‡æ–™
            if not timeline:
                start_age = random.randint(2, 9)
                pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                for i in range(8):
                    timeline.append({
                        "age_start": start_age + i*10,
                        "age_end": start_age + i*10 + 9,
                        "name": f"{pillars_pool[i]}é‹",
                        "description": descs[i]
                    })

            # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ current_luckï¼Œå¾ timeline ä¸­è¨ˆç®—
            current_luck = bazi.get("current_luck")
            if not isinstance(current_luck, dict):
                current_luck = {}

            if not current_luck or not current_luck.get("description"):
                try:
                    citizen_age = int(citizen.get("age", 30))
                except:
                    citizen_age = 30
                for lt in timeline:
                    if lt["age_start"] <= citizen_age <= lt["age_end"]:
                        current_luck = {"name": lt["name"], "description": lt["description"]}
                        break
                if not current_luck and timeline:
                    current_luck = {"name": timeline[0]["name"], "description": timeline[0]["description"]}
                bazi["current_luck"] = current_luck

            # ID é˜²ç¦¦
            cid = str(citizen.get("id")) if citizen.get("id") else f"gen-{random.randint(1000,9999)}"

            # æ§‹å»ºå®Œæ•´çš„ persona è³‡æ–™
            full_persona = {
                "id": cid,
                "name": citizen["name"],
                "age": str(citizen["age"]),
                "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                "element": bazi.get("element", "Fire"),
                "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                "location": citizen.get("location", "å°ç£"),
                "birth_year": bazi.get("birth_year"),
                "birth_month": bazi.get("birth_month"),
                "birth_day": bazi.get("birth_day"),
                "birth_shichen": bazi.get("birth_shichen"),
                "four_pillars": pillars_str,
                "day_master": bazi.get("day_master", "æœªçŸ¥"),
                "strength": bazi.get("strength", "ä¸­å’Œ"),
                "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                "current_luck": current_luck,
                "luck_timeline": timeline,
                "trait": bazi.get("trait", "æ€§æ ¼å‡è¡¡")
            }

            arena_comments.append({
                "sentiment": sentiment,
                "text": text,
                "persona": full_persona
            })
            
            personas.append(full_persona)
            
            # DEBUG LOG
            logger.info(f"Generated Fallback Comment Persona: Name={citizen['name']}, ID={cid}, Pillars={pillars_str}, Birth={bazi.get('birth_year')}")

        result_data = {
            "status": "ready",
            "score": data.get("result", {}).get("score", 75),
            "intent": data.get("result", {}).get("market_sentiment", "è¬¹æ…æ¨‚è§€"),
            "summary": data.get("result", {}).get("summary", "åˆ†æå®Œæˆ"),
            "simulation_metadata": {
                "source_type": sim_metadata_override.get("source_type", "image") if sim_metadata_override else "image",
                "product_category": data.get("simulation_metadata", {}).get("product_category", sim_metadata_override.get("product_category", "other") if sim_metadata_override else "other"),
                "sample_size": len(sampled_citizens),
                "bazi_distribution": bazi_dist
            },
            "bazi_distribution": bazi_dist,
            "genesis": {
                "total_population": 1000,
                "sample_size": max(len(arena_comments), 8),
                "personas": personas
            },
            "arena_comments": arena_comments,
            "objections": data.get("result", {}).get("objections", []),
            "suggestions": data.get("result", {}).get("suggestions", [])
        }
        return result_data

    def _handle_error_db(self, sim_id, error_msg):
        error_data = {
            "status": "error",
            "score": 0,
            "intent": "Error",
            "summary": f"ç³»çµ±éŒ¯èª¤: {error_msg}",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        update_simulation(sim_id, "error", error_data)

    def reply_text(self, reply_token, text):
        try:
            self.line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=text)]
                )
            )
        except Exception:
            pass

    async def _call_gemini_rest(self, api_key, prompt, image_b64=None, pdf_b64=None, mime_type="image/jpeg", timeout=120, image_parts=None):
        """Helper to call Gemini REST API (Async Wrapper with Configurable Timeout)"""
        import requests 

        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 8192,
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_parts:
             payload["contents"][0]["parts"].extend(image_parts)
        elif image_b64:
            # Use dynamic mime_type
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": mime_type, "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        # [Restore] Prioritize Quality (Pro) as per User Request (reverting to GitHub-like behavior)
        models = [
            "gemini-2.5-pro", 
            "gemini-2.5-flash",
            "gemini-2.0-flash",
            "gemini-flash-latest"
        ]
        
        last_error = ""
        for model in models:
            try:
                # print(f"Trying model: {model}...")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                
                # [Fix] Use asyncio.to_thread to unblock Event Loop
                import asyncio
                # Increase timeout for Pro model and PDF/Audio heavy tasks
                current_timeout = timeout
                if "pro" in model:
                    current_timeout = max(timeout, 180) # Pro needs time to think (3 mins)
                
                # PDF needs more time regardless of model
                if pdf_b64:
                    current_timeout = max(current_timeout, 120)

                print(f"[DEBUG] Calling Gemini Model: {model} with Payload Size: {len(json.dumps(payload))} bytes, Timeout: {current_timeout}s")
                response = await asyncio.to_thread(
                    requests.post, 
                    url, 
                    headers={'Content-Type': 'application/json'}, 
                    json=payload, 
                    timeout=current_timeout
                )
                print(f"[DEBUG] Gemini Model {model} returned Status: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        return response.json()['candidates'][0]['content']['parts'][0]['text'], None
                    except:
                        continue
                else:
                    last_error = f"{model}: {response.status_code} {response.text}"
            except Exception as e:
                last_error = str(e)
        
        return None, last_error

    # NOTE: èˆŠç‰ˆ generate_marketing_copy å·²åˆªé™¤ï¼Œç¾ä½¿ç”¨ç¬¬ 480 è¡Œçš„æ–°ç‰ˆæœ¬ (å–®ç¯‡è¼¸å‡º)

    def _run_blocking_gemini_request(self, api_key, prompt, image_b64=None, pdf_b64=None, model_priority=None, mime_type="image/jpeg", image_parts=None):
        """Helper to run synchronous requests in a thread"""
        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 8192,
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_parts:
             payload["contents"][0]["parts"].extend(image_parts)
        elif image_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": mime_type, "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        # Default models if not specified
        if model_priority:
            models = model_priority
        else:
            # [Fix] Prioritize Gemini 2.5 Pro as requested by the user
            models = [
                "gemini-2.5-pro",
                "gemini-2.5-flash",
                "gemini-flash-latest"
            ]
        
        last_error = ""
        for model in models:
            try:
                print(f"[AI] å˜—è©¦ä½¿ç”¨æ¨¡å‹: {model}...")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                # Increased timeout to 90s for complex prompts with detailed strategic advice
                response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                if response.status_code == 200:
                    try:
                        return response.json()['candidates'][0]['content']['parts'][0]['text'], None
                    except:
                        continue
                else:
                    error_msg = f"{model}: {response.status_code} {response.text}"
                    print(f"[AI] æ¨¡å‹ {model} å¤±æ•—: {error_msg}")
                    last_error = error_msg
            except Exception as e:
                last_error = str(e)
        
        return None, last_error
# LINE Bot å¤šåœ–è™•ç†è¼”åŠ©å‡½æ•¸
# é€™äº›å‡½æ•¸å°‡è¢«é›†æˆåˆ° line_bot_service.py ä¸­

async def _identify_from_multiple_images(self, user_id):
    """
    å¾ session ä¸­çš„å¤šå¼µåœ–ç‰‡é€²è¡Œ AI è­˜åˆ¥èˆ‡å¸‚å ´æ¯”åƒ¹
    """
    session = self.user_session.get(user_id)
    if not session or not session.get("images"):
        self._push_text(user_id, "âŒ æ‰¾ä¸åˆ°åœ–ç‰‡ï¼Œè«‹é‡æ–°ä¸Šå‚³")
        return
    
    images = session["images"]
    image_count = len(images)
    
    try:
        # 1. AI ç”¢å“è­˜åˆ¥ï¼ˆä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ï¼‰
        print(f"ğŸ” [Multi-Image] é–‹å§‹è­˜åˆ¥ {image_count} å¼µåœ–ç‰‡...")
        ai_name, ai_price = await self.identify_product_from_image(images[0])
        
        # 2. å¸‚å ´æ¯”åƒ¹æŸ¥è©¢ï¼ˆå¦‚æœæœ‰ç”¢å“åç¨±ï¼‰
        market_prices = {}
        if ai_name and ai_name != "æœªçŸ¥ç”¢å“":
            from app.services.price_search import search_market_prices_sync
            try:
                print(f"ğŸ’° [Market] æŸ¥è©¢å¸‚å ´åƒ¹æ ¼: {ai_name}")
                market_result = search_market_prices_sync(ai_name)
                if market_result.get("success"):
                    market_prices = market_result
                    print(f"ğŸ’° [Market] æ‰¾åˆ° {len(market_result.get('prices', []))} ç­†åƒ¹æ ¼è³‡æ–™")
            except Exception as e:
                print(f"âš ï¸ [Market] æ¯”åƒ¹æŸ¥è©¢å¤±æ•—: {e}")
        
        # 3. æ›´æ–° session
        session["image_bytes"] = images[0]  # å…¼å®¹æ€§ï¼šä¿ç•™ç¬¬ä¸€å¼µåšç‚ºä¸»åœ–
        session["product_name"] = ai_name or ""
        session["product_price"] = ai_price or "æœªå®š"  
        session["market_prices"] = market_prices
        session["stage"] = "waiting_for_name_confirmation"
        
        print(f"âœ… [Multi-Image] è­˜åˆ¥å®Œæˆ: {ai_name} / {ai_price}")
        
        # 4. æ§‹å»ºå›è¦†è¨Šæ¯ï¼ˆåŒ…å«å¸‚å ´æ¯”åƒ¹è³‡æ–™ï¼‰
        confirm_msg = f"ğŸ‘ï¸ **AI è¦–è¦ºåˆ†æçµæœ**ï¼ˆ{image_count} å¼µåœ–ç‰‡ï¼‰\n\n"
        confirm_msg += f"ğŸ“¦ ç”¢å“ï¼š{ai_name or 'æœªçŸ¥'}\n"
        
        # é¡¯ç¤ºå¸‚å ´æ¯”åƒ¹
        if market_prices.get("success"):
            prices = market_prices.get("prices", [])
            if prices:
                min_price = market_prices.get("min_price", ai_price)
                max_price = market_prices.get("max_price", ai_price)
                confirm_msg += f"ğŸ’° å¸‚å ´åƒ¹æ ¼å€é–“ï¼š${min_price} - ${max_price}\n"
                confirm_msg += f"ğŸ“Š å·²æ¯”å° {len(prices)} å€‹å¹³å°\n"
            else:
                confirm_msg += f"ğŸ’° ä¼°åƒ¹ï¼š{ai_price or 'æœªçŸ¥'}\n"
        else:
            confirm_msg += f"ğŸ’° ä¼°åƒ¹ï¼š{ai_price or 'æœªçŸ¥'}\n"
        
        confirm_msg += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        confirm_msg += "âœ… è‹¥è³‡æ–™æ­£ç¢ºï¼Œè«‹å›è¦†ã€Œ**Y**ã€\n"
        confirm_msg += "âœï¸ è‹¥éœ€ä¿®æ”¹ï¼Œè«‹ç›´æ¥è¼¸å…¥ã€Œ**åç¨± / å”®åƒ¹**ã€"
        
        self._push_text(user_id, confirm_msg)
        
    except Exception as e:
        print(f"âŒ [Multi-Image] è­˜åˆ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        self._push_text(user_id, "âŒ AI è­˜åˆ¥å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")
        # é‡ç½® session
        if user_id in self.user_session:
            del self.user_session[user_id]


async def _handle_upload_complete(self, user_id):
    """
    è™•ç†ç”¨æˆ¶é»é¸ã€Œå®Œæˆä¸Šå‚³ã€å¾Œçš„é‚è¼¯
    """
    session = self.user_session.get(user_id)
    if not session:
        self._push_text(user_id, "âŒ æ‰¾ä¸åˆ°ä¸Šå‚³çš„åœ–ç‰‡ï¼Œè«‹é‡æ–°é–‹å§‹")
        return
    
    images = session.get("images", [])
    if not images:
        self._push_text(user_id, "âŒ å°šæœªä¸Šå‚³ä»»ä½•åœ–ç‰‡ï¼Œè«‹å…ˆä¸Šå‚³ç”¢å“åœ–ç‰‡")
        return
    
    # é–‹å§‹è­˜åˆ¥
    await self._identify_from_multiple_images(user_id)
