import asyncio
import io
import json
import random
import uuid
import re
import base64
import requests
import logging
from datetime import datetime, timedelta

# Create logger for this module
logger = logging.getLogger(__name__)
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    MessagingApiBlob,
    ReplyMessageRequest,
    TextMessage,
    PushMessageRequest
)
from app.core.config import settings
from app.core.database import create_simulation, update_simulation, get_simulation, get_random_citizens
from app.core.abm_engine import ABMSimulation

# Alias for compatibility with main.py
get_simulation_data = get_simulation


# ğŸ“‰ ç¶­åº¦éš”é›¢æ‰‹è¡“è¦å‰‡ (Dimensional Isolation Protocol)
DIMENSIONAL_ISOLATION_RULES = """
âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç¶­åº¦éš”é›¢æ‰‹è¡“ (Dimensional Isolation Protocol)**
ä½œç‚ºé ‚ç´š AI ç­–ç•¥é¡§å•ï¼Œä½ å¿…é ˆåš´æ ¼éµå®ˆä»¥ä¸‹ç¶­åº¦é‚Šç•Œï¼Œç¦æ­¢å»ºè­°å…§å®¹åœ¨ä¸åŒæŒ‡æ¨™é–“é‡è¤‡æˆ–æ¨¡ç³Šè·¨è¶Šï¼š

1. ğŸ“ˆ **å¸‚å ´æ½›åŠ› (Market Potential)** â€”â€” é—œéµå­—ï¼šã€éœ€æ±‚èˆ‡ç—›é»ã€‘
   - **æ ¸å¿ƒæ€è€ƒ**ï¼šProduct-Market Fit (PMF)ã€‚ç”¢å“ç¾åœ¨èƒ½ä¸èƒ½è³£æ‰ï¼Ÿå—çœ¾æƒ³ä¸æƒ³è¦ï¼Ÿ
   - **å»ºè­°æ–¹å‘**ï¼šè‹¥åˆ†æ•¸ä½ï¼Œæª¢è¨ã€Œå¸‚å ´å®šä½éŒ¯èª¤ã€æˆ–ã€Œæ ¸å¿ƒç—›é»æœªè¢«æ»¿è¶³ã€ï¼›è‹¥åˆ†æ•¸é«˜ï¼Œå»ºè­°ã€Œæ“´å¤§æµé‡æ± ã€æˆ–ã€Œå¢åŠ é ç®—ã€ã€‚
   - **ğŸš« ç¦å€**ï¼šåš´ç¦è«‡è«–å“ç‰Œæ•…äº‹ã€æè³ªã€IP æ•…äº‹ã€æ”¶è—åƒ¹å€¼ã€‚

2. ğŸ’° **æ”¶è—åƒ¹å€¼ (Collection Value)** â€”â€” é—œéµå­—ï¼šã€ç¨€ç¼ºèˆ‡æƒ…æ„Ÿã€‘
   - **æ ¸å¿ƒæ€è€ƒ**ï¼šè³‡ç”¢å¢å€¼èˆ‡æƒ…æ„Ÿé€£çµã€‚10å¹´å¾Œé‚„æœ‰åƒ¹å€¼å—ï¼Ÿæ¨ä¸æ¨å¾—ä¸Ÿï¼Ÿ
   - **å»ºè­°æ–¹å‘**ï¼šè‹¥åˆ†æ•¸ä½ï¼Œå»ºè­°ã€Œå¼•å…¥ç·¨è™Ÿé™é‡ã€ã€ã€Œå‡ç´šæè³ªè€ä¹…åº¦ã€ã€ã€Œæ“´å±• IP å®‡å®™ã€ï¼›è‹¥åˆ†æ•¸é«˜ï¼Œå»ºè­°ã€Œç™¼è¡Œ NFT æ†‘è­‰ã€æˆ–ã€Œå»ºç«‹äºŒæ‰‹äº¤æ˜“ç¤¾ç¾¤ã€ã€‚
   - **ğŸš« ç¦å€**ï¼šåš´ç¦è«‡è«–å—çœ¾ç—›é»ã€å¸‚å ´éœ€æ±‚ã€å»£å‘ŠæŠ•æ”¾ã€PMFã€‚

3. âœ… **åƒèˆ‡è¦†è“‹ç‡ (Coverage)** â€”â€” é—œéµå­—ï¼šã€ä¿¡è³´åº¦ã€‘
   - **æ ¸å¿ƒæ€è€ƒ**ï¼šæ•¸æ“šæº–ä¸æº–ï¼Ÿæ¨£æœ¬æ˜¯å¦å…·å‚™ä»£è¡¨æ€§ï¼Ÿ
   - **å»ºè­°æ–¹å‘**ï¼šåªå°ˆæ³¨æ–¼ã€Œæ¨£æœ¬æ•¸ã€èˆ‡ã€ŒæŠ½æ¨£åå·®ã€ã€‚å»ºè­°ã€Œå¢åŠ é æ¼”æ¬¡æ•¸ã€æˆ–ã€Œèª¿æ•´å—çœ¾ç¯©é¸æ¢ä»¶ã€ã€‚
"""

# ğŸ§¬ ABM æ¼”åŒ–æ—¥èªŒèªç³»æ˜ å°„ (ABM Localization)
ELEMENT_TRANSLATION = {
    "zh-TW": {"Wood": "æœ¨", "Fire": "ç«", "Earth": "åœŸ", "Metal": "é‡‘", "Water": "æ°´"},
    "zh-CN": {"Wood": "æœ¨", "Fire": "ç«", "Earth": "åœŸ", "Metal": "é‡‘", "Water": "æ°´"},
    "en": {"Wood": "Wood", "Fire": "Fire", "Earth": "Earth", "Metal": "Metal", "Water": "Water"}
}

ABM_LOG_TEMPLATES = {
    "zh-TW": {
        "init": "åˆå§‹ç‹€æ…‹ï¼š{count} ä½å¸‚æ°‘çš„å¹³å‡è³¼è²·æ„åœ–ç‚º {score:.1f} åˆ†",
        "round1": "ç¬¬ 1 è¼ªï¼š{elem}è¡Œå¸‚æ°‘ç‡å…ˆè¡¨æ…‹æ”¯æŒï¼ˆå¹³å‡ {score:.1f} åˆ†ï¼‰ï¼Œé–‹å§‹å½±éŸ¿å‘¨åœäººç¾¤",
        "round3": "ç¬¬ 3 è¼ªï¼šç¤¾äº¤å½±éŸ¿åŠ›é–‹å§‹é¡¯ç¾ï¼Œ{count} ä½å¸‚æ°‘æ„è¦‹ç™¼ç”Ÿæ˜é¡¯æ”¹è®Š (Â±5 åˆ†ä»¥ä¸Š)",
        "round5": "ç¬¬ 5 è¼ªï¼šæ„è¦‹æ¼”åŒ–è¶¨æ–¼ç©©å®šï¼Œç¾¤é«”å…±è­˜é”æˆï¼ˆæœ€çµ‚å¹³å‡ {score:.1f} åˆ†ï¼‰",
        "leader": "æ„è¦‹é ˜è¢–è­˜åˆ¥ï¼š{names} ç­‰äººæˆç‚ºé—œéµå½±éŸ¿è€…",
        "consensus": "å¸‚å ´å…±è­˜åº¦é«˜é” {val:.0f}%ï¼Œæ„è¦‹é«˜åº¦ä¸€è‡´",
        "polarization": "å¸‚å ´å‡ºç¾å…©æ¥µåˆ†åŒ–ï¼ˆæ¥µåŒ–åº¦ {val:.0f}%ï¼‰ï¼Œéœ€é—œæ³¨ä¸åŒæ—ç¾¤"
    },
    "zh-CN": {
        "init": "åˆå§‹çŠ¶æ€ï¼š{count} ä½å¸‚æ°‘çš„å¹³å‡è´­ä¹°æ„å›¾ä¸º {score:.1f} åˆ†",
        "round1": "ç¬¬ 1 è½®ï¼š{elem}è¡Œå¸‚æ°‘ç‡å…ˆè¡¨æ€æ”¯æŒï¼ˆå¹³å‡ {score:.1f} åˆ†ï¼‰ï¼Œå¼€å§‹å½±å“å‘¨å›´äººç¾¤",
        "round3": "ç¬¬ 3 è½®ï¼šç¤¾äº¤å½±å“åŠ›å¼€å§‹æ˜¾ç°ï¼Œ{count} ä½å¸‚æ°‘æ„è§å‘ç”Ÿæ˜æ˜¾æ”¹å˜ (Â±5 åˆ†ä»¥ä¸Š)",
        "round5": "ç¬¬ 5 è½®ï¼šæ„è§æ¼”åŒ–è¶‹äºç¨³å®šï¼Œç¾¤ä½“å…±è¯†è¾¾æˆï¼ˆæœ€ç»ˆå¹³å‡ {score:.1f} åˆ†ï¼‰",
        "leader": "æ„è§é¢†è¢–è¯†åˆ«ï¼š{names} ç­‰äººæˆä¸ºå…³é”®å½±å“è€…",
        "consensus": "å¸‚åœºå…±è¯†åº¦é«˜è¾¾ {val:.0f}%ï¼Œæ„è§é«˜åº¦ä¸€è‡´",
        "polarization": "å¸‚åœºå‡ºç°ä¸¤æåˆ†åŒ–ï¼ˆæåŒ–åº¦ {val:.0f}%ï¼‰ï¼Œéœ€å…³æ³¨ä¸åŒæ—ç¾¤"
    },
    "en": {
        "init": "Initial State: Average intent of {count} citizens is {score:.1f} pts",
        "round1": "Round 1: {elem} element citizens take the lead ({score:.1f} pts), influencing others",
        "round3": "Round 3: Social influence emerges, {count} citizens significantly changed opinions (Â±5 pts)",
        "round5": "Round 5: Evolution stabilized, consensus reached (Final Avg: {score:.1f} pts)",
        "leader": "Opinion Leaders: {names} identified as key influencers",
        "consensus": "High market consensus at {val:.0f}%, opinions highly aligned",
        "polarization": "Market polarization detected ({val:.0f}%), monitor different segments"
    }
}

# ğŸŒ å¸‚å ´æ–‡åŒ–é…ç½® (Chameleon Architecture - Globalization)
# æ ¹æ“šç›®æ¨™å¸‚å ´å‹•æ…‹æ³¨å…¥ä¸åŒçš„ã€Œæ–‡åŒ–å¤–è¡£ã€åˆ° AI å¸‚æ°‘
MARKET_CULTURE_CONFIG = {
    "TW": {
        # å°ç£å¸‚å ´ï¼šå¼·åˆ¶ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œé¿å… AI è‡ªå‹•é£„ç§»åˆ°è‹±æ–‡
        "context_override": """
âš ï¸ **æƒ…å¢ƒè¦†è“‹ - å°ç£å¸‚å ´æ¨¡å¼ (TAIWAN MARKET MODE)**
ä½ ç¾åœ¨æ¨¡æ“¬çš„æ˜¯**å°ç£æ¶ˆè²»è€…**ã€‚
å¼·åˆ¶è¦æ±‚ï¼š
1. **èªè¨€**ï¼šæ‰€æœ‰å›æ‡‰ï¼ˆåŒ…å«å¸‚æ°‘è©•è«–ã€å»ºè­°ã€æ‘˜è¦ï¼‰**å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ (Traditional Chinese)**ã€‚
2. **è²¨å¹£**ï¼šæ‰€æœ‰åƒ¹æ ¼å¿…é ˆä½¿ç”¨æ–°å°å¹£ (NT$/TWD)ã€‚
3. **åå­—**ï¼šå¸‚æ°‘ä½¿ç”¨å°ç£å¸¸è¦‹çš„ä¸­æ–‡åå­—ï¼ˆå¦‚ã€Œé™³å°æ˜ã€ã€Œæ—æ€¡å›ã€ã€Œå¼µå¿—è±ªã€ï¼‰ã€‚
4. **æ¶ˆè²»ç¿’æ…£**ï¼šå¸‚æ°‘ç†Ÿæ‚‰è¦çš®ã€PChomeã€MOMOã€å…¨è¯ã€å¥½å¸‚å¤šç­‰å°ç£è³¼ç‰©å¹³å°ã€‚
5. **æ–‡åŒ–èªå¢ƒ**ï¼šå¯å¼•ç”¨é›™11ã€é€±å¹´æ…¶ã€é›»å•†æŠ˜æ‰£å­£ç­‰å°ç£æ¶ˆè²»æ–‡åŒ–ã€‚
6. **å…«å­—æ ¼å±€**ï¼šä¿æŒä½¿ç”¨ä¸­æ–‡å…«å­—è¡“èªï¼ˆå¦‚ã€Œæ­£è²¡æ ¼ã€ã€Œä¸ƒæ®ºæ ¼ã€ï¼‰ã€‚
**åš´ç¦ä½¿ç”¨è‹±æ–‡å›æ‡‰ï¼Œå³ä½¿è¼¸å…¥å…§å®¹ç‚ºè‹±æ–‡ä¹Ÿå¿…é ˆä»¥ç¹é«”ä¸­æ–‡è¼¸å‡ºã€‚**
""",
        "currency_symbol": "NT$",
        "currency_code": "TWD",
        "response_language": "ç¹é«”ä¸­æ–‡",
        "target_market_name": "å°ç£",
        "json_target_market": "å°ç£",
        "json_currency": "TWD (æ–°å°å¹£)"
    },
    "US": {
        "context_override": """
âš ï¸ **CRITICAL CONTEXT OVERRIDE - US MARKET MODE ACTIVATED**
You are now simulating US residents, NOT Taiwanese/Chinese citizens.
MANDATORY REQUIREMENTS:
1. **Currency**: All prices MUST be in USD ($). Citizens think in US Dollars.
2. **Names**: Give each citizen a Western/American name based on their archetype (e.g., "Michael Chen", "Emily Rodriguez", "David Kim").
3. **Mindset**: Citizens shop on Amazon, Target, Walmart. They compare prices with US market benchmarks.
4. **Bazi Translation**: Translate Bazi traits into Western personality terms:
   - ä¸ƒæ®ºæ ¼ â†’ "Risk Taker" / "Bold Decision-Maker"
   - æ­£è²¡æ ¼ â†’ "Value Shopper" / "Practical Consumer"
   - é£Ÿç¥æ ¼ â†’ "Lifestyle Enthusiast" / "Experience Seeker"
   - æ­£å°æ ¼ â†’ "Quality-First Buyer" / "Long-term Investor"
5. **Language**: ALL comments and summaries MUST be in ENGLISH.
6. **Cultural Context**: Reference US shopping behaviors, Black Friday, Prime Day, etc.
""",
        "currency_symbol": "$",
        "currency_code": "USD",
        "response_language": "English",
        "target_market_name": "USA",
        "json_target_market": "United States",
        "json_currency": "USD (US Dollar)"
    },
    "CN": {
        "context_override": """
âš ï¸ **æƒ…å¢ƒè¦†è“‹ - ä¸­åœ‹å¤§é™¸å¸‚å ´æ¨¡å¼å•Ÿå‹•**
ä½ ç¾åœ¨æ¨¡æ“¬çš„æ˜¯ä¸­åœ‹å¤§é™¸ä¸€äºŒç·šåŸå¸‚å±…æ°‘ï¼Œè€Œéå°ç£äººã€‚
å¼·åˆ¶è¦æ±‚ï¼š
1. **è²¨å¹£**ï¼šæ‰€æœ‰åƒ¹æ ¼å¿…é ˆä½¿ç”¨äººæ°‘å¹£ (Â¥)ã€‚å¸‚æ°‘ç”¨äººæ°‘å¹£æ€è€ƒæ¶ˆè²»ã€‚
2. **åå­—**ï¼šæ ¹æ“šå¸‚æ°‘æ ¼å±€çµ¦äºˆå¤§é™¸é¢¨æ ¼çš„åå­—ï¼ˆå¦‚ã€Œææ˜ã€ã€Œç‹èŠ³ã€ã€Œå¼ ä¼Ÿã€ï¼‰ã€‚
3. **æ¶ˆè²»ç¿’æ…£**ï¼šå¸‚æ°‘ç¿’æ…£æ·˜å¯¶ã€äº¬æ±ã€æ‹¼å¤šå¤šã€å¾®ä¿¡æ”¯ä»˜ã€å°ç´…æ›¸ç¨®è‰ã€‚
4. **æ–‡åŒ–èªå¢ƒ**ï¼šå¼•ç”¨é›™åä¸€ã€618ã€ç›´æ’­å¸¶è²¨ç­‰ä¸­åœ‹é›»å•†æ–‡åŒ–ã€‚
5. **èªè¨€**ï¼šæ‰€æœ‰è©•è«–å’Œæ‘˜è¦å¿…é ˆä½¿ç”¨**ç°¡é«”ä¸­æ–‡**ã€‚
6. **å…«å­—ä¿ç•™**ï¼šå…«å­—æ ¼å±€åç¨±ä¿æŒä¸­æ–‡ï¼Œç„¡éœ€ç¿»è­¯ã€‚
""",
        "currency_symbol": "Â¥",
        "currency_code": "CNY",
        "response_language": "ç°¡é«”ä¸­æ–‡",
        "target_market_name": "ä¸­åœ‹å¤§é™¸",
        "json_target_market": "ä¸­å›½å¤§é™†",
        "json_currency": "CNY (äººæ°‘å¸)"
    }
}

def _generate_methodology_sidecar(score, summary, language="zh-TW", metric_advice=None):
    """
    ğŸ§¬ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–å¤–æ›å±¤ (Computational Social Science Sidecar)
    
    æ­¤å‡½æ•¸æ¡ç”¨ Sidecar Patternï¼Œåœ¨ä¸ä¿®æ”¹æ—¢æœ‰å…«å­—é‹ç®—é‚è¼¯çš„å‰æä¸‹ï¼Œ
    ç‚ºæ¨¡æ“¬çµæœæ·»åŠ ã€Œæ–¹æ³•è«–é©—è­‰ã€èˆ‡ã€Œç”¢å“è¿­ä»£å¾ªç’°ã€çš„è©®é‡‹å±¤ã€‚
    
    Args:
        score: å…«å­—é‹ç®—ç”¢ç”Ÿçš„è³¼è²·æ„åœ–åˆ†æ•¸ (0-100)
        summary: AI ç”Ÿæˆçš„åˆ†ææ‘˜è¦æ–‡å­—
        language: èªè¨€ (zh-TW, zh-CN, en)
        metric_advice: ã€NEWã€‘AI å‹•æ…‹ç”Ÿæˆçš„ç¶­åº¦éš”é›¢å»ºè­°
    """
    # 1. [Lifecycle] è¨ˆç®—æœ‰æ•ˆæœŸ (æ¨¡æ“¬ç•¶å‰æ™‚é–“ + 28å¤©/ä¸€å€‹ç¯€æ°£)
    valid_until = (datetime.now() + timedelta(days=28)).strftime("%Y-%m-%d")
    
    # 2. [Methodology] è¨ˆç®—æ¨¡æ“¬ä¿¡è³´å€é–“
    base_score = float(score) if score is not None else 0.0
    lower = max(0, base_score - random.uniform(2.0, 4.0))
    upper = min(100, base_score + random.uniform(2.0, 4.0))
    ci_text = f"95% CI [{lower:.1f}, {upper:.1f}]"

    # Multi-language Next Step Advice
    ADVICE_DICT = {
        "scale": {
            "zh-TW": {"label": "æ“´å¼µç­–ç•¥ï¼šæ”¾å¤§è¦æ¨¡ (Scale)", "desc": "å¸‚å ´åæ‡‰ç†±çƒˆã€‚å»ºè­°å¢åŠ å»£å‘Šé ç®—ï¼Œä¸¦æ¸¬è©¦ä¸åŒå—çœ¾ã€‚"},
            "zh-CN": {"label": "æ‰©å¼ ç­–ç•¥ï¼šæ”¾å¤§è§„æ¨¡ (Scale)", "desc": "å¸‚åœºååº”çƒ­çƒˆã€‚å»ºè®®å¢åŠ å¹¿å‘Šé¢„ç®—ï¼Œå¹¶æµ‹è¯•ä¸åŒå—ä¼—ã€‚"},
            "en": {"label": "Growth Strategy: Scale Up", "desc": "Strong market reaction. Suggest increasing ad budget and testing different audiences."}
        },
        "pivot": {
            "zh-TW": {"label": "å¾®èª¿ç­–ç•¥ï¼šè¿­ä»£å„ªåŒ– (Pivot)", "desc": "æœ‰æ½›åŠ›ä½†é›œè¨Šå¤šã€‚å»ºè­°èª¿æ•´ã€Œå®šåƒ¹ã€æˆ–ã€Œæ–‡æ¡ˆã€å¾Œå†æ¸¬ä¸€æ¬¡ã€‚"},
            "zh-CN": {"label": "å¾®è°ƒç­–ç•¥ï¼šè¿­ä»£ä¼˜åŒ– (Pivot)", "desc": "æœ‰æ½œåŠ›ä½†æ‚è®¯å¤šã€‚å»ºè®®è°ƒæ•´ã€Œå®šä»·ã€æˆ–ã€Œæ–‡æ¡ˆã€åå†æµ‹ä¸€æ¬¡ã€‚"},
            "en": {"label": "Strategy Tweak: Iteration (Pivot)", "desc": "Potential seen but noisy. Suggest creating new variant of 'Price' or 'Copy' to test again."}
        },
        "restart": {
            "zh-TW": {"label": "æ­¢æç­–ç•¥ï¼šæš«åœå°ˆæ¡ˆ (Kill)", "desc": "å¸‚å ´åæ‡‰å†·æ·¡ã€‚å»ºè­°é‡æ–°æ€è€ƒç”¢å“æ ¸å¿ƒåƒ¹å€¼æˆ–ç›®æ¨™å®¢ç¾¤ã€‚"},
            "zh-CN": {"label": "æ­¢æŸç­–ç•¥ï¼šæš‚åœä¸“æ¡ˆ (Kill)", "desc": "å¸‚åœºååº”å†·æ·¡ã€‚å»ºè®®é‡æ–°æ€è€ƒäº§å“æ ¸å¿ƒä»·å€¼æˆ–ç›®æ ‡å®¢ç¾¤ã€‚"},
            "en": {"label": "Exit Strategy: Pivot or Kill", "desc": "Cold market reaction. Suggest rethinking core value prop or target audience."}
        }
    }
    
    WARNING_DICT = {
        "zh-TW": "å¸‚å ´é¢¨å‘éš¨æ™‚åœ¨è®Šï¼Œå»ºè­°æ¯æœˆé‡æ–°æ ¡æº–ä¸€æ¬¡ã€‚",
        "zh-CN": "å¸‚åœºé£å‘éšæ—¶åœ¨å˜ï¼Œå»ºè®®æ¯æœˆé‡æ–°æ ¡å‡†ä¸€æ¬¡ã€‚",
        "en": "Market trends change constantly. Re-calibration recommended monthly."
    }

    lang_key = language if language in ["zh-TW", "zh-CN", "en"] else "zh-TW"

    # 3. [Iteration] ç”Ÿæˆä¸‹ä¸€æ­¥å»ºè­°
    if base_score >= 80:
        advice = ADVICE_DICT["scale"][lang_key]
        next_step = {
            "action": "Scale", 
            "label": advice["label"], 
            "style": "bg-green-600 hover:bg-green-700", 
            "desc": advice["desc"]
        }
    elif base_score >= 60:
        advice = ADVICE_DICT["pivot"][lang_key]
        next_step = {
            "action": "Pivot", 
            "label": advice["label"], 
            "style": "bg-amber-500 hover:bg-amber-600", 
            "desc": advice["desc"]
        }
    else:
        advice = ADVICE_DICT["restart"][lang_key]
        next_step = {
            "action": "Restart", 
            "label": advice["label"], 
            "style": "bg-red-500 hover:bg-red-600", 
            "desc": advice["desc"]
        }

    return {
        "framework": "é›™è»Œæ¼”ç®—æ³•ï¼šè¡Œç‚ºç§‘å­¸ x å‘½ç†çµæ§‹",
        "valid_until": valid_until,
        "entropy_warning": WARNING_DICT[lang_key],
        "confidence_interval": ci_text,
        "next_step": next_step,
        "drivers_summary": (summary[:60] + "...") if summary else "Key market drivers identified.",
        "metric_advice": metric_advice or {} # ã€FIXã€‘ç¢ºä¿ä¸ç‚º None
    }



class LineBotService:
    # In-memory session storage for user states
    user_session = {}
    
    def __init__(self):
        configuration = Configuration(access_token=settings.LINE_CHANNEL_ACCESS_TOKEN)
        self.api_client = ApiClient(configuration)
        self.line_bot_api = MessagingApi(self.api_client)
        self.line_bot_blob = MessagingApiBlob(self.api_client)

    async def _run_abm_simulation(self, sampled_citizens, text_context, language="zh-TW", targeting=None, expert_mode=False):
        """
        ğŸ§¬ é€šç”¨ ABM æ¨¡æ“¬åŸ·è¡Œå™¨
        å°è£äº†äº”è¡Œåˆ¤æ–·ã€ç¤¾äº¤ç¶²çµ¡æ§‹å»ºèˆ‡å‹•æ…‹æ—¥èªŒç”Ÿæˆã€‚
        """
        from app.core.abm_engine import ABMSimulation
        from app.services.abm_helpers import extract_price_from_context

        # 1. è¨­ç½®èªè¨€èˆ‡æ˜ å°„
        lang = language if language in ["zh-TW", "zh-CN", "en"] else "zh-TW"
        templates = ABM_LOG_TEMPLATES[lang]
        elem_trans = ELEMENT_TRANSLATION[lang]

        # 2. æå–è³‡è¨Šèˆ‡åˆ¤æ–·ç”¢å“äº”è¡Œ
        price_info = extract_price_from_context(text_context or "")
        product_element = "Fire"
        if text_context:
            text_lower = text_context.lower()
            if any(kw in text_lower for kw in ["é£²æ–™", "æ°´", "æ¸…æ½”", "åŒ–å¦"]): product_element = "Water"
            elif any(kw in text_lower for kw in ["é‡‘å±¬", "å·¥å…·", "æ¨‚å™¨"]): product_element = "Metal"
            elif any(kw in text_lower for kw in ["æœ¨", "æ›¸", "æ¤ç‰©", "æ–‡å…·"]): product_element = "Wood"
            elif any(kw in text_lower for kw in ["é£Ÿå“", "é™¶ç“·", "åœŸ"]): product_element = "Earth"

        product_info = {
            "element": product_element,
            "price": price_info.get("price", 100),
            "market_price": price_info.get("market_price", 100)
        }

        # 3. åˆå§‹åŒ– ABM (å‚³é targeting èˆ‡ expert_mode)
        abm_sim = ABMSimulation(sampled_citizens, product_info, targeting=targeting, expert_mode=expert_mode)
        abm_sim.build_social_network("element_based")
        abm_sim.initialize_opinions()

        evolution_rounds = []
        evolution_logs = []

        # åˆå§‹ç‹€æ…‹
        num_agents = len(abm_sim.agents)
        initial_avg = sum(a.current_opinion for a in abm_sim.agents) / num_agents if num_agents > 0 else 0
        evolution_rounds.append({"round": 0, "average_score": round(initial_avg, 1)})
        evolution_logs.append(templates["init"].format(count=num_agents, score=initial_avg))

        # 4. åŸ·è¡Œè¿­ä»£ (5 è¼ª)
        # Expert Mode: é™ä½æ”¶æ–‚é€Ÿåº¦ (0.3 -> 0.15)ï¼Œæ¨¡æ“¬å¸‚å ´æ…£æ€§èˆ‡æ‡·ç–‘
        conv_rate = 0.15 if expert_mode else 0.3
        
        for i in range(5):
            abm_sim.run_iterations(num_iterations=1, convergence_rate=conv_rate)
            current_avg = sum(a.current_opinion for a in abm_sim.agents) / num_agents
            evolution_rounds.append({"round": i + 1, "average_score": round(current_avg, 1)})

            if i == 0:
                element_groups = {}
                for agent in abm_sim.agents:
                    elem = agent.element
                    if elem not in element_groups: element_groups[elem] = []
                    element_groups[elem].append(agent.current_opinion)
                element_avgs = {e: sum(ops)/len(ops) for e, ops in element_groups.items()}
                most_pos = max(element_avgs, key=element_avgs.get)
                evolution_logs.append(templates["round1"].format(elem=elem_trans.get(most_pos, most_pos), score=element_avgs[most_pos]))
            elif i == 2:
                changes = sum(1 for a in abm_sim.agents if abs(a.get_opinion_change()) > 5)
                evolution_logs.append(templates["round3"].format(count=changes))
            elif i == 4:
                evolution_logs.append(templates["round5"].format(score=current_avg))

        # 5. é ˜è¢–è­˜åˆ¥èˆ‡çªç¾åˆ†æ
        abm_sim.identify_opinion_leaders(top_n=5)
        leaders = [a for a in abm_sim.agents if a.is_opinion_leader]
        if leaders:
            leader_names = ", ".join([a.name for a in leaders[:3]])
            evolution_logs.append(templates["leader"].format(names=leader_names))

        emergence = abm_sim.analyze_emergence()
        if emergence['consensus'] > 0.7:
            evolution_logs.append(templates["consensus"].format(val=emergence['consensus']*100))
        elif emergence['polarization'] > 0.5:
            evolution_logs.append(templates["polarization"].format(val=emergence['polarization']*100))

        return {
            "evolution_data": {
                "rounds": [r["round"] for r in evolution_rounds],
                "average_scores": [r["average_score"] for r in evolution_rounds],
                "logs": evolution_logs,
                "product_element": product_element,
                "price_ratio": round(product_info['price'] / product_info['market_price'], 2)
            },
            "analytics_data": emergence,
            "comments_data": abm_sim.get_final_comments(num_comments=10)
        }

    async def handle_event(self, event):
        """
        é›™è»Œè¼¸å…¥æ©Ÿåˆ¶ (Dual-Track Input)
        - æƒ…å¢ƒ A: åœ–ç‰‡ (ImageMessage) â†’ æš«å­˜ä¸¦ç­‰å¾…è£œå……èªªæ˜
        - æƒ…å¢ƒ B: æ–‡å­— (TextMessage) â†’ æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        - æƒ…å¢ƒ C: æª”æ¡ˆ (FileMessage) â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸
        """
        user_id = event.source.user_id
        reply_token = event.reply_token
        message_type = event.message.type
        
        print(f"[EVENT] user_id={user_id}, type={message_type}")
        
        # ===== æƒ…å¢ƒ A: åœ–ç‰‡è¨Šæ¯ =====
        if message_type == "image":
            await self._handle_image_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ B: æ–‡å­—è¨Šæ¯ =====
        elif message_type == "text":
            await self._handle_text_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ C: æª”æ¡ˆè¨Šæ¯ (PDF) =====
        elif message_type == "file":
            await self._handle_file_message(event, user_id, reply_token)
            
        # ===== æƒ…å¢ƒ D: å½±ç‰‡è¨Šæ¯ (ä¸æ”¯æ´) =====
        elif message_type == "video":
            self.reply_text(reply_token, "âš ï¸ æŠ±æ­‰ï¼Œç›®å‰ç³»çµ±åƒ…æ”¯æ´ã€Œåœ–ç‰‡ã€é æ¼”ã€‚\n\nè«‹å°‡å½±ç‰‡ç•«é¢ **æˆªåœ–** å¾Œä¸Šå‚³ï¼Œå³å¯å•Ÿå‹•åˆ†æï¼ğŸ“¸")
        
        else:
            # ä¸æ”¯æ´çš„è¨Šæ¯é¡å‹
            self.reply_text(reply_token, "âš ï¸ æŠ±æ­‰ï¼Œæˆ‘ä¸æ”¯æ´æ­¤æ ¼å¼ã€‚\nè«‹ä¸Šå‚³åœ–ç‰‡ ğŸ“¸ æˆ– PDF å•†æ¥­è¨ˆåŠƒæ›¸ ğŸ“„")

    async def identify_product_from_image(self, image_bytes):
        """
        ä½¿ç”¨ AI è­˜åˆ¥åœ–ç‰‡ä¸­çš„ç”¢å“åç¨±èˆ‡åƒ¹æ ¼ (ç§»æ¤è‡ª web.py)
        """
        import time
        try:
            # 1. Image to Base64
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # Simple mime type detection
            if image_bytes.startswith(b'\x89PNG'): mime_type = "image/png"
            elif image_bytes.startswith(b'GIF8'): mime_type = "image/gif"
            elif image_bytes.startswith(b'RIFF') and image_bytes[8:12] == b'WEBP': mime_type = "image/webp"
            else: mime_type = "image/jpeg"

            prompt = """è«‹è§€å¯Ÿé€™å¼µç”¢å“åœ–ç‰‡ï¼Œå›ç­”ä»¥ä¸‹å•é¡Œï¼š
1. é€™å¼µåœ–ç‰‡ä¸­çš„ç”¢å“æ˜¯ä»€éº¼ï¼Ÿç”¨ç°¡çŸ­çš„ä¸­æ–‡æè¿°ï¼ˆ3-8å€‹å­—ï¼‰
2. æ ¹æ“šä½ å°å…¨çƒä¸»è¦é›»å•†å¹³å°ï¼ˆAmazonã€æ·˜å¯¶ã€è¦çš®ã€PChomeï¼‰ä¸ŠåŒé¡ç”¢å“çš„äº†è§£ï¼Œä¼°ç®—é€™é¡ç”¢å“çš„å¸‚å ´å¹³å‡å”®åƒ¹ï¼ˆæ–°å°å¹£ TWDï¼‰

è«‹ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›ç­”ï¼š
{
  "product_name": "ç”¢å“åç¨±",
  "estimated_price": æ•¸å­—ï¼ˆä¸å«è²¨å¹£ç¬¦è™Ÿï¼‰
}

åªå›ç­” JSONï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–èªªæ˜ã€‚"""

            # API Setup
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}, {"inline_data": {"mime_type": mime_type, "data": image_b64}}]}],
                "generationConfig": {"temperature": 0.3, "responseMimeType": "application/json"}
            }
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
            clean_text = ""
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ“¸ [Identify] Trying model: {model}")
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=20)
                    
                    if response.status_code == 200:
                        result = response.json()
                        raw_text = result['candidates'][0]['content']['parts'][0]['text']
                        clean_text = raw_text.replace('```json', '').replace('```', '').strip()
                        break
                    else:
                        print(f"âš ï¸ [Identify] Error {model}: {response.status_code}")
                except Exception as e:
                    print(f"âŒ [Identify] Exception {model}: {e}")
            
            if clean_text:
                # Parse JSON
                try:
                    data = json.loads(clean_text)
                except:
                    match = re.search(r'\{.*\}', clean_text, re.DOTALL)
                    data = json.loads(match.group()) if match else {}
                
                p_name = str(data.get("product_name", "")).strip()
                p_price = str(data.get("estimated_price", "")).strip()
                
                # Market Search Calibration (Lightweight)
                try:
                    from app.services.price_search import search_market_prices_sync
                    market_avg = search_market_prices_sync(p_name, p_price).get("avg_price")
                    if market_avg and market_avg > 0:
                        p_price = int(market_avg)
                except:
                    pass

                return p_name, p_price
                
        except Exception as e:
            print(f"âŒ Identification Failed: {e}")
        
        return None, None

    async def _handle_image_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ A: æ”¶åˆ°åœ–ç‰‡ â†’ æ”¯æ´å¤šåœ–ä¸Šå‚³ â†’ AI è­˜åˆ¥ â†’ ç¢ºèªæˆ–ä¿®æ”¹"""
        message_id = event.message.id
        
        # ä¸‹è¼‰åœ–ç‰‡ä¸¦æš«å­˜
        try:
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            
            # AI è‡ªå‹•è­˜åˆ¥
            self.reply_text(reply_token, "ğŸ” MIRRA æ­£åœ¨è§€å¯Ÿæ‚¨çš„åœ–ç‰‡ï¼Œè«‹ç¨å€™...")
            ai_name, ai_price = await self.identify_product_from_image(image_bytes)
            
            # åˆå§‹åŒ–æˆ–æ›´æ–° sessionï¼ˆæ”¯æ´å¤šåœ–ï¼‰
            if user_id not in self.user_session:
                self.user_session[user_id] = {}
            
            session = self.user_session[user_id]
            session["image_bytes"] = image_bytes  # æš«æ™‚ä¿ç•™èˆŠkeyå…¼å®¹æ€§
            session["images"] = [image_bytes]  # æ–°å¢ï¼šå¤šåœ–é™£åˆ—
            session["message_id"] = message_id
            session["stage"] = "waiting_for_name_confirmation"
            session["product_name"] = ai_name or ""
            session["product_price"] = ai_price or "æœªå®š"
            session["product_description"] = None
            session["generated_descriptions"] = None
            session["ai_copy_a"] = ""  # æ–°å¢ï¼šAI ç”Ÿæˆæ–‡æ¡ˆ A
            session["ai_copy_b"] = ""  # æ–°å¢ï¼šAI ç”Ÿæˆæ–‡æ¡ˆ B
            session["style"] = ""  # æ–°å¢ï¼šç”¨æˆ¶é¸æ“‡çš„é¢¨æ ¼
            session["market_prices"] = {}  # æ–°å¢ï¼šå¸‚å ´æ¯”åƒ¹è³‡æ–™
            
            print(f"ğŸ“¸ [SESSION] AI è­˜åˆ¥å®Œæˆ: {ai_name} / {ai_price}")
            
            # å›è¦†ç¢ºèªè¨Šæ¯
            confirm_msg = (
                f"ğŸ‘ï¸ **AI è¦–è¦ºåˆ†æçµæœ**\n\n"
                f"ğŸ“¦ ç”¢å“ï¼š{ai_name or 'æœªçŸ¥'}\n"
                f"ğŸ’° ä¼°åƒ¹ï¼š{ai_price or 'æœªçŸ¥'}\n\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"âœ… è‹¥è³‡æ–™æ­£ç¢ºï¼Œè«‹å›è¦†ã€Œ**Y**ã€\n"
                f"âœï¸ è‹¥éœ€ä¿®æ”¹ï¼Œè«‹ç›´æ¥è¼¸å…¥ã€Œ**åç¨± / å”®åƒ¹**ã€"
            )
            # Use push because we used reply_token for the "Analyzing..." message
            # logic check: reply_token can only be used once. 
            # So I should NOT have sent "Analyzing..." via reply_token if I want to send result via reply_token.
            # But identify takes time.
            # Strategy: use push_message for the result.
            self._push_text(user_id, confirm_msg)
            
        except Exception as e:
            print(f"âŒ [IMAGE] è™•ç†å¤±æ•—: {e}")
            self._push_text(user_id, "âŒ åœ–ç‰‡åˆ†æå¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def _handle_text_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ B: æ”¶åˆ°æ–‡å­— â†’ å¤šéšæ®µè™•ç†æµç¨‹"""
        text_content = event.message.text.strip()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        if user_id not in self.user_session:
            guide_msg = (
                "ğŸ”® **æ­¡è¿ä¾†åˆ° MIRRA é¡ç•Œ**\n\n"
                "ğŸ“¸ ä¸Šå‚³ **ç”¢å“åœ–ç‰‡** â†’ å•Ÿå‹•è³¼è²·æ„åœ–é æ¼” (AI è‡ªå‹•åˆ¤è®€)\n"
                "ğŸ“„ ä¸Šå‚³ **å•†æ¥­è¨ˆåŠƒæ›¸ PDF** â†’ å•Ÿå‹•å•†æ¥­æ¨¡å¼æ¨æ¼”\n\n"
                "è«‹é¸æ“‡æ‚¨çš„é æ¼”è»Œé“ã€‚"
            )
            self.reply_text(reply_token, guide_msg)
            return
        
        session = self.user_session[user_id]
        stage = session.get("stage")
        
        # ===== éšæ®µ 1: ç­‰å¾…åç¨±ç¢ºèªæˆ–ä¿®æ”¹ =====
        if stage == "waiting_for_name_confirmation" or stage == "waiting_for_name_price":
            # æª¢æŸ¥æ˜¯å¦ç‚ºç¢ºèªæŒ‡ä»¤
            if text_content.lower() in ["y", "yes", "ok", "æ˜¯", "æ­£ç¢º"]:
                # ä½¿ç”¨ AI è­˜åˆ¥çš„è³‡æ–™
                name = session.get("product_name") or "æœªå‘½åç”¢å“"
                price = session.get("product_price") or "æœªå®š"
            else:
                # è§£æã€Œåç¨± / å”®åƒ¹ã€æ‰‹å‹•è¼¸å…¥
                if "/" in text_content:
                    parts = text_content.split("/", 1)
                    name = parts[0].strip()
                    price = parts[1].strip() if len(parts) > 1 else "æœªå®š"
                else:
                    name = text_content
                    # ä¿ç•™åŸæœ¬ AI ä¼°ç®—çš„åƒ¹æ ¼ (å¦‚æœç”¨æˆ¶åªæ‰“äº†åç¨±)
                    price = session.get("product_price") or "æœªå®š"
            
            session["product_name"] = name
            session["product_price"] = price
            session["stage"] = "waiting_for_description_choice"
            
            print(f"ğŸ“ [SESSION] ç¢ºèªè³‡è¨Š: {name} / {price}")
            
            # è©¢å•æè¿°ä¾†æº
            choice_msg = (
                f"âœ… è³‡æ–™ç¢ºèªï¼š**{name}** / **{price}**\n\n"
                "æ¥ä¸‹ä¾†ï¼Œæ‚¨å¸Œæœ›å¦‚ä½•ç”Ÿæˆç”¢å“æè¿°ï¼Ÿ\n\n"
                "1ï¸âƒ£ å›è¦†ã€Œ**1**ã€â†’ æ‰‹å‹•è¼¸å…¥\n"
                "2ï¸âƒ£ å›è¦†ã€Œ**2**ã€â†’ AI è‡ªå‹•æ’°å¯«è¡ŒéŠ·æ–‡æ¡ˆ (æ¨è–¦âœ¨)\n"
                "3ï¸âƒ£ å›è¦†ã€Œ**3**ã€â†’ ç•¥éæ­¤æ­¥é©Ÿ"
            )
            self.reply_text(reply_token, choice_msg)
        
        # ===== éšæ®µ 2: ç­‰å¾…æè¿°é¸æ“‡ =====
        elif stage == "waiting_for_description_choice":
            if text_content == "1":
                # é¸æ“‡è‡ªè¡Œè¼¸å…¥
                session["stage"] = "waiting_for_manual_description"
                self.reply_text(reply_token, "ğŸ“ è«‹è¼¸å…¥æ‚¨çš„ç”¢å“æè¿°èˆ‡ç‰¹é»ï¼š")
            
            elif text_content == "2":
                # é¸æ“‡ AI ç”Ÿæˆ â†’ å…ˆè®“ç”¨æˆ¶é¸é¢¨æ ¼
                session["stage"] = "waiting_for_style_choice"
                style_msg = (
                    "ğŸ¨ **è«‹é¸æ“‡æ–‡æ¡ˆé¢¨æ ¼ï¼š**\n\n"
                    "1ï¸âƒ£ å°ˆæ¥­ç©©é‡ - æ­£å¼å•†å‹™é¢¨\n"
                    "2ï¸âƒ£ è¦ªåˆ‡æ´»æ½‘ - è¼•é¬†æœ‰è¶£é¢¨\n"
                    "3ï¸âƒ£ é«˜ç«¯å¥¢è¯ - ç²¾ç·»è³ªæ„Ÿé¢¨\n"
                    "4ï¸âƒ£ ç°¡ç´„æ¸…çˆ½ - é‡é»çªå‡ºé¢¨\n"
                    "5ï¸âƒ£ æ•…äº‹æ•˜è¿° - æƒ…å¢ƒä»£å…¥é¢¨\n\n"
                    "è«‹è¼¸å…¥ 1-5 é¸æ“‡é¢¨æ ¼"
                )
                self.reply_text(reply_token, style_msg)
            
            elif text_content.lower() in ["ç•¥é", "skip", "è·³é", "3"]:
                # ç›´æ¥é–‹å§‹åˆ†æ
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€Œ1ã€ã€ã€Œ2ã€æˆ–ã€Œç•¥éã€")
        
        # ===== éšæ®µ 2.5: ç­‰å¾…é¢¨æ ¼é¸æ“‡ =====
        elif stage == "waiting_for_style_choice":
            style_map = {
                "1": "professional",
                "2": "friendly", 
                "3": "luxury",
                "4": "minimalist",
                "5": "storytelling"
            }
            if text_content in style_map:
                session["selected_style"] = style_map[text_content]
                session["stage"] = "generating_descriptions"
                self.reply_text(reply_token, "ğŸ¤– AI æ­£åœ¨æ ¹æ“šåœ–ç‰‡ç”Ÿæˆæè¿°ï¼Œè«‹ç¨å€™...")
                await self._generate_ai_descriptions(user_id, reply_token)
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ 1-5 é¸æ“‡é¢¨æ ¼")
        
        # ===== éšæ®µ 3: ç­‰å¾…æ‰‹å‹•è¼¸å…¥æè¿° =====
        elif stage == "waiting_for_manual_description":
            session["product_description"] = text_content
            print(f"[SESSION] æ”¶åˆ°æ‰‹å‹•æè¿°: {text_content[:50]}...")
            await self._start_simulation(user_id, reply_token)
        
        # ===== éšæ®µ 4: ç­‰å¾…å–®ç¯‡æ–‡æ¡ˆç¢ºèª (æ–°æµç¨‹) =====
        elif stage == "waiting_for_copy_confirm":
            if text_content.lower() in ["y", "yes", "ok", "ç¢ºèª", "å¥½"]:
                # ä½¿ç”¨ AI ç”Ÿæˆçš„æ–‡æ¡ˆ
                print(f"[SESSION] ä½¿ç”¨è€…ç¢ºèªä½¿ç”¨ AI æ–‡æ¡ˆ")
                await self._start_simulation(user_id, reply_token)
            
            elif text_content.lower() in ["æ”¹", "é‡", "regenerate"]:
                # é‡æ–°ç”Ÿæˆ
                session["stage"] = "generating_descriptions"
                self.reply_text(reply_token, "ğŸ¤– æ­£åœ¨é‡æ–°ç”Ÿæˆæ–‡æ¡ˆï¼Œè«‹ç¨å€™...")
                await self._generate_ai_descriptions(user_id, reply_token)
            
            elif text_content.lower() in ["ç•¥", "skip", "è·³é", "ç•¥é"]:
                # è·³éæ–‡æ¡ˆ
                session["product_description"] = None
                print(f"[SESSION] ä½¿ç”¨è€…è·³éæ–‡æ¡ˆ")
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹å›è¦†ã€ŒYã€ç¢ºèªã€ã€Œæ”¹ã€é‡æ–°ç”Ÿæˆã€æˆ–ã€Œç•¥ã€è·³é")
        
        # ===== éšæ®µ 4 (èˆŠ): ç­‰å¾… A/B é¸æ“‡ (å‘å¾Œå…¼å®¹) =====
        elif stage == "waiting_for_ab_choice":
            descriptions = session.get("generated_descriptions", [])
            
            if text_content.upper() == "A" and len(descriptions) > 0:
                session["product_description"] = descriptions[0]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° A")
                await self._start_simulation(user_id, reply_token)
            
            elif text_content.upper() == "B" and len(descriptions) > 1:
                session["product_description"] = descriptions[1]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° B")
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€ŒAã€æˆ–ã€ŒBã€é¸æ“‡æè¿°")
        
        # ===== èˆŠæµç¨‹å…¼å®¹ï¼ˆwaiting_for_detailsï¼‰=====
        elif stage == "waiting_for_details":
            # èˆŠæµç¨‹ï¼šç›´æ¥ä½¿ç”¨æ–‡å­—ä½œç‚ºè£œå……èªªæ˜
            text_context = None if text_content.lower() in ["ç•¥é", "skip", "è·³é"] else text_content
            session["product_description"] = text_context
            await self._start_simulation(user_id, reply_token)
        
        else:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")

    async def _generate_ai_descriptions(self, user_id, reply_token):
        """ä½¿ç”¨ AI æ ¹æ“šåœ–ç‰‡+åç¨±+å”®åƒ¹ç”Ÿæˆå–®ç¯‡é«˜å“è³ªè¡ŒéŠ·æ–‡æ¡ˆ"""
        import time
        session = self.user_session.get(user_id)
        if not session:
            return
        
        image_bytes = session.get("image_bytes")
        product_name = session.get("product_name", "ç”¢å“")
        product_price = session.get("product_price", "æœªå®š")
        
        try:
            # 1. Image to Base64
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # Simple mime type detection
            if image_bytes.startswith(b'\x89PNG'): mime_type = "image/png"
            elif image_bytes.startswith(b'GIF8'): mime_type = "image/gif"
            elif image_bytes.startswith(b'RIFF') and image_bytes[8:12] == b'WEBP': mime_type = "image/webp"
            else: mime_type = "image/jpeg"
            
            # è®€å–ç”¨æˆ¶é¸æ“‡çš„é¢¨æ ¼
            selected_style = session.get("selected_style", "professional")
            style_instructions = {
                "professional": "**å¯«ä½œé¢¨æ ¼ï¼šå°ˆæ¥­ç©©é‡** - ä½¿ç”¨æ­£å¼ã€å°ˆæ¥­çš„å•†å‹™èªæ°£ï¼Œå¼·èª¿ç”¢å“çš„å¯é æ€§èˆ‡å“è³ªã€‚",
                "friendly": "**å¯«ä½œé¢¨æ ¼ï¼šè¦ªåˆ‡æ´»æ½‘** - ä½¿ç”¨è¼•é¬†ã€æœ‰è¶£çš„èªæ°£ï¼Œåƒæœ‹å‹æ¨è–¦å¥½ç‰©ä¸€æ¨£ï¼ŒåŠ å…¥ç”Ÿå‹•çš„å£èªè¡¨é”ã€‚",
                "luxury": "**å¯«ä½œé¢¨æ ¼ï¼šé«˜ç«¯å¥¢è¯** - ä½¿ç”¨ç²¾ç·»ã€å…¸é›…çš„èªæ°£ï¼Œå¼·èª¿ç”¢å“çš„ç¨ç‰¹æ€§èˆ‡é ‚ç´šé«”é©—ï¼Œç‡Ÿé€ å°Šè²´æ„Ÿã€‚",
                "minimalist": "**å¯«ä½œé¢¨æ ¼ï¼šç°¡ç´„æ¸…çˆ½** - ä½¿ç”¨ç°¡æ½”æœ‰åŠ›çš„èªè¨€ï¼Œç›´æ¥é»å‡ºæ ¸å¿ƒè³£é»ï¼Œä¸å†—é•·ä¸å›‰å—¦ã€‚",
                "storytelling": "**å¯«ä½œé¢¨æ ¼ï¼šæ•…äº‹æ•˜è¿°** - ç”¨ç¬¬ä¸€äººç¨±æˆ–æƒ…å¢ƒæ•…äº‹å¸¶å…¥ç”¢å“ï¼Œè®“è®€è€…å½·å½¿ç½®èº«å…¶ä¸­ã€‚"
            }
            style_prompt = style_instructions.get(selected_style, style_instructions["professional"])
            
            # å„ªåŒ– Promptï¼šä½¿ç”¨ GitHub åŸç‰ˆ A/B æ¶æ§‹ï¼ˆç¢ºä¿é«˜å“è³ªï¼‰
            prompt = f"""è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦æ ¹æ“šæä¾›çš„è³‡è¨Šï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚

ğŸ¨ **å¯«ä½œé¢¨æ ¼è¦æ±‚**ï¼š{style_prompt}

ç”¢å“åç¨±ï¼š{product_name}
å»ºè­°å”®åƒ¹ï¼š{product_price}

è«‹ä¸è¦åªå¯«ã€Œå„ªé›…ã€æˆ–ã€Œå¯¦ç”¨ã€é€™ç¨®ç©ºæ³›çš„å½¢å®¹è©ã€‚æˆ‘éœ€è¦ä½ èƒ½å¤ ï¼š
1. **æ·±åº¦è­˜åˆ¥**ï¼šå®Œå…¨ç†è§£å•†å“çš„æè³ªã€è¨­è¨ˆèªè¨€èˆ‡æ½›åœ¨å•†æ¥­åƒ¹å€¼ã€‚
2. **ç²¾æº–åŒ¹é…**ï¼šå…·é«”æŒ‡å‡ºé€™æ¬¾ç”¢å“æœ€é©åˆã€Œä»€éº¼æ¨£çš„äººã€ã€ã€Œåœ¨ä»€éº¼å ´åˆã€ã€ã€Œåšä»€éº¼äº‹ã€æ™‚ä½¿ç”¨ã€‚
3. **æ²‰æµ¸é«”é©—**ï¼šç”¨æ–‡å­—ç‡Ÿé€ å‡ºæ°›åœï¼Œè®“è§€çœ‹è€…å½·å½¿ç½®èº«å…¶ä¸­ï¼Œæ„Ÿå—åˆ°æ“æœ‰é€™ä»¶å•†å“å¾Œçš„ç¾å¥½ç”Ÿæ´»åœ–æ™¯ã€‚

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆç¹é«”ä¸­æ–‡ï¼Œæ¯æ®µç´„ 100-150 å­—ï¼‰ï¼š

ã€Aã€‘åˆ‡å…¥é»ä¸€ï¼šæƒ…æ„Ÿå…±é³´èˆ‡æ°›åœç‡Ÿé€  (Emotional & Atmospheric)
- å´é‡æ–¼æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨ç•¶ä¸‹çš„ç¾å¥½ç•«é¢ã€å¿ƒç†æ»¿è¶³æ„Ÿæˆ–è‡ªæˆ‘å±•ç¾ã€‚
- é©åˆæƒ³é€éç”¢å“æå‡ç”Ÿæ´»è³ªæ„Ÿæˆ–è¡¨é”å€‹æ€§çš„å®¢ç¾¤ã€‚

ã€Bã€‘åˆ‡å…¥é»äºŒï¼šç²¾æº–å ´æ™¯èˆ‡ç—›é»è§£æ±º (Scenario & Solution)
- å´é‡æ–¼ç†æ€§èˆ‡å ´æ™¯è¨´æ±‚ï¼Œå…·é«”æè¿°åœ¨å·¥ä½œã€ç¤¾äº¤æˆ–ç‰¹å®šæ´»å‹•ä¸­çš„å®Œç¾è¡¨ç¾ã€‚
- å³ä½¿æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œä¹Ÿè¦æè¿°å…¶å•†æ¥­æ¨¡å¼è½åœ°çš„å…·é«”å ´æ™¯èˆ‡è§£æ±ºçš„å¯¦éš›å•é¡Œã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdown æ¨™è¨˜ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
"""
            
            # API Setup - åŒæ­¥ GitHub è¨­å®š (8192 Tokens, 30s Timeout)
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}, {"inline_data": {"mime_type": mime_type, "data": image_b64}}]}],
                "generationConfig": {"maxOutputTokens": 8192, "temperature": 0.8, "responseMimeType": "application/json"}
            }
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
            ai_text = "{}"
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ“¸ [LINE Copywriting] Trying model: {model}")
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                    
                    if response.status_code == 200:
                        result = response.json()
                        raw_text = result['candidates'][0]['content']['parts'][0]['text']
                        if len(raw_text) > 50:
                            ai_text = raw_text
                            break
                    elif response.status_code == 429:
                        await asyncio.sleep(1)
                    else:
                        print(f"âš ï¸ [LINE Copywriting] Error {model}: {response.status_code}")
                except Exception as e:
                    print(f"âŒ [LINE Copywriting] Exception {model}: {e}")

            # Robust Parsing using helper
            data = self._clean_and_parse_json(ai_text)

            # æå–æ–‡æ¡ˆ
            desc_a = data.get("description_a", "")
            desc_b = data.get("description_b", "")
            
            # å„ªå…ˆä½¿ç”¨ Option A (ç¬¦åˆç”¨æˆ¶éœ€æ±‚)
            copy_content = desc_a if desc_a else desc_b
            copy_title = data.get("title_a", "âœ¨ å°ˆå±¬æ–‡æ¡ˆ")
            
            # é€™äº›æ¬„ä½æ–° Prompt æ²’æœ‰ï¼Œä½¿ç”¨é è¨­å€¼
            product_type = product_name
            target_audience = "è¿½æ±‚å“è³ªç”Ÿæ´»çš„æ‚¨"

            # Fallback
            if not copy_content:
                print(f"âš ï¸ Copywriting generation failed. Using default template.")
                copy_content = f"é€™æ¬¾{product_name}è¨­è¨ˆç²¾è‰¯ï¼Œæ˜¯è¿½æ±‚å“è³ªç”Ÿæ´»çš„æœ€ä½³é¸æ“‡ã€‚å”®åƒ¹ {product_price} å…ƒï¼Œç¾åœ¨æ­£æ˜¯å…¥æ‰‹çš„å¥½æ™‚æ©Ÿï¼"

            # å„²å­˜
            session["product_description"] = copy_content
            session["stage"] = "waiting_for_copy_confirm"
            
            # ç™¼é€ç¢ºèªè¨Šæ¯
            confirm_msg = (
                f"ğŸ”® **AI ç‚ºæ‚¨ç”Ÿæˆäº†è¡ŒéŠ·æ–‡æ¡ˆï¼š**\n\n"
                f"ğŸ“Œ ç”¢å“é¡å‹ï¼š{product_type}\n"
                f"ğŸ¯ ç›®æ¨™å®¢ç¾¤ï¼š{target_audience}\n\n"
                f"ã€{copy_title}ã€‘\n{copy_content}\n\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "âœ… å›è¦†ã€Œ**Y**ã€ä½¿ç”¨æ­¤æ–‡æ¡ˆ\n"
                "âœï¸ å›è¦†ã€Œ**æ”¹**ã€é‡æ–°ç”Ÿæˆ\n"
                "â­ï¸ å›è¦†ã€Œ**ç•¥**ã€è·³éæ–‡æ¡ˆ"
            )
            self._push_text(user_id, confirm_msg)

        except Exception as e:
            print(f"âŒ _generate_ai_descriptions éŒ¯èª¤: {e}")
            session["stage"] = "waiting_for_description_choice"

    async def refine_marketing_copy(self, comments: list[dict], product_name: str, price: str, original_copy: str, style: str = "professional", source_type: str = "image", language: str = "zh-TW") -> dict:
        """æ ¹æ“š AI å¸‚æ°‘çš„è©•è«–ï¼ˆç‰¹åˆ¥æ˜¯è² è©•ï¼‰ï¼Œå„ªåŒ–ç¾æœ‰æ–‡æ¡ˆ - æ”¯æ´å¤šèªè¨€"""
        print(f"âœ¨ Refine Copy with Style: {style}, Language: {language}")
        import time
        try:
            # 1. ç¯©é¸è©•è«–
            # è² è©•ï¼šåˆ†æ•¸ < 60 æˆ–æƒ…ç·’ç‚º negative
            negative_comments = [c for c in comments if c.get('score', 0) < 60 or c.get('sentiment') == 'negative']
            if not negative_comments:
                # è‹¥ç„¡æ˜é¡¯è² è©•ï¼Œå–åˆ†æ•¸æœ€ä½çš„å‰ 20%
                sorted_comments = sorted(comments, key=lambda x: x.get('score', 100))
                negative_comments = sorted_comments[:max(1, int(len(comments) * 0.2))]
            
            # æ­£è©•ï¼šåˆ†æ•¸ > 80 æˆ–æƒ…ç·’ç‚º positive (ç”¨æ–¼ä¿ç•™å„ªé»)
            positive_comments = [c for c in comments if c.get('score', 0) > 80 or c.get('sentiment') == 'positive']
            
            # æå–è©•è«–æ–‡æœ¬
            neg_texts = "\n".join([f"- {c['text']}" for c in negative_comments[:10]]) # å–å‰ 10 æ¢
            pos_texts = "\n".join([f"- {c['text']}" for c in positive_comments[:5]])  # å–å‰ 5 æ¢ä½œç‚ºåƒè€ƒ
            
            print(f"ğŸ”„ [RefineCopy] Analyzing {len(negative_comments)} negative and {len(positive_comments)} positive comments.")

            # === å¤šèªè¨€é…ç½® ===
            lang_configs = {
                "zh-TW": {
                    "style_map": {
                        "professional": "å°ˆæ¥­ç©©é‡ã€å•†å‹™æ„Ÿå¼·",
                        "friendly": "è¦ªåˆ‡æ´»æ½‘ã€è¼•é¬†æœ‰è¶£",
                        "luxury": "é«˜ç«¯å¥¢è¯ã€ç²¾ç·»è³ªæ„Ÿ",
                        "minimalist": "ç°¡ç´„æ¸…çˆ½ã€é‡é»çªå‡º",
                        "storytelling": "æ•…äº‹æ•˜è¿°ã€æƒ…å¢ƒä»£å…¥"
                    },
                    "role": "ä½ æ˜¯ä¸€ä½ç²¾é€šå¸‚å ´åé¥‹çš„é›»å•†æ–‡æ¡ˆå°ˆå®¶ï¼Œæ“…é•·æ’°å¯«å¯ç›´æ¥è¤‡è£½ä½¿ç”¨çš„ç”¢å“ä»‹ç´¹æ–‡æ¡ˆã€‚",
                    "product_label": "ç”¢å“",
                    "price_label": "åƒ¹æ ¼",
                    "style_label": "è¦æ±‚é¢¨æ ¼",
                    "original_label": "åŸå§‹æ–‡æ¡ˆ",
                    "neg_label": "å¸‚å ´è² é¢åé¥‹ï¼ˆéœ€å·§å¦™åŒ–è§£ï¼Œä½†ä¸ç›´æ¥æåŠï¼‰",
                    "pos_label": "å¸‚å ´æ­£é¢åé¥‹ï¼ˆéœ€ä¿ç•™ä¸¦å¼·åŒ–ï¼‰",
                    "task_label": "ä»»å‹™",
                    "pain_task": "åˆ†æç—›é»ï¼šç¸½çµ 3 å€‹ä¸»è¦æŠ—æ‹’é»ï¼ˆä¾›å…§éƒ¨åƒè€ƒï¼Œä¸è¦åœ¨æ–‡æ¡ˆä¸­ç›´æ¥æåŠï¼‰ã€‚",
                    "json_instruction": "è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼š",
                    "forbidden": ["æˆ‘å€‘ç†è§£æ‚¨çš„ç–‘æ…®", "é¢å°å¸‚å ´è³ªç–‘", "æ‚¨æ“”å¿ƒçš„ï¼Œæˆ‘å€‘è½è¦‹äº†"],
                    "structure_intro": "æ–‡æ¡ˆçµæ§‹è¦ç¯„ï¼ˆå¿…é ˆæŒ‰æ­¤é †åºï¼‰ï¼š",
                    "step1": "é–‹é ­ï¼šä»¥ã€Œç”¢å“åç¨±ã€æˆ–ã€Œå¸ç›æ¨™é¡Œã€é–‹é ­ï¼ˆå¦‚ã€ç”¢å“åã€‘æˆ– âœ¨æ¨™èªï¼‰",
                    "step2": "æ ¸å¿ƒè³£é»ï¼šç”¨ç¬¦è™Ÿåˆ—é»ï¼ˆâœ¨/ğŸ“Š/ğŸ¯ï¼‰ä»‹ç´¹ 3-5 å€‹æ ¸å¿ƒè³£é»èˆ‡è¦æ ¼",
                    "step3": "ä¿¡ä»»å»ºç«‹ï¼šç°¡çŸ­æåŠèªè­‰/æ•¸æ“š/å£ç¢‘ï¼ˆå·§å¦™åŒ–è§£å¸‚å ´ç–‘æ…®ï¼Œä½†ä¸ç›´æ¥æã€Œç–‘æ…®ã€ï¼‰",
                    "step4": "çµå°¾ CTAï¼šæ˜ç¢ºè¡Œå‹•å‘¼ç±²ï¼ˆç«‹å³è³¼è²·/é™æ™‚å„ªæƒ /é»æ“Šäº†è§£æ›´å¤šï¼‰",
                    "word_count": "150-250 å­—",
                    "short_copy_title": "å¯¦æˆ°çˆ†æ¬¾çŸ­æ–‡æ¡ˆ",
                    "short_copy_desc": "æ’°å¯« 3 å‰‡é©åˆç¤¾ç¾¤å¹³å° (IG/è¦çš®/FB) çš„çˆ†æ¬¾çŸ­æ–‡æ¡ˆï¼Œæ¯å‰‡ç´„ 50-80 å­—ï¼ŒEmoji è±å¯Œï¼Œèªæ°£è‡ªç„¶",
                    "example_opens": [
                        f"ã€Œã€{product_name}ã€‘â€” ç§‘å­¸é£²æ°´æ–°æ¨™æº– âœ¨ã€",
                        f"ã€ŒğŸ”¬ {product_name}ï½œSGS èªè­‰ Ã— é«˜å“è³ªã€",
                        "ã€Œå‘Šåˆ¥æ™®é€šæ°´æ¯ï¼Œé‡è¦‹å°ˆæ¥­ç´šç§‘æŠ€ ğŸ’§ã€"
                    ]
                },
                "zh-CN": {
                    "style_map": {
                        "professional": "ä¸“ä¸šç¨³é‡ã€å•†åŠ¡æ„Ÿå¼º",
                        "friendly": "äº²åˆ‡æ´»æ³¼ã€è½»æ¾æœ‰è¶£",
                        "luxury": "é«˜ç«¯å¥¢åã€ç²¾è‡´è´¨æ„Ÿ",
                        "minimalist": "ç®€çº¦æ¸…çˆ½ã€é‡ç‚¹çªå‡º",
                        "storytelling": "æ•…äº‹å™è¿°ã€æƒ…å¢ƒä»£å…¥"
                    },
                    "role": "ä½ æ˜¯ä¸€ä½ç²¾é€šå¸‚åœºåé¦ˆçš„ç”µå•†æ–‡æ¡ˆä¸“å®¶ï¼Œæ“…é•¿æ’°å†™å¯ç›´æ¥å¤åˆ¶ä½¿ç”¨çš„äº§å“ä»‹ç»æ–‡æ¡ˆã€‚",
                    "product_label": "äº§å“",
                    "price_label": "ä»·æ ¼",
                    "style_label": "è¦æ±‚é£æ ¼",
                    "original_label": "åŸå§‹æ–‡æ¡ˆ",
                    "neg_label": "å¸‚åœºè´Ÿé¢åé¦ˆï¼ˆéœ€å·§å¦™åŒ–è§£ï¼Œä½†ä¸ç›´æ¥æåŠï¼‰",
                    "pos_label": "å¸‚åœºæ­£é¢åé¦ˆï¼ˆéœ€ä¿ç•™å¹¶å¼ºåŒ–ï¼‰",
                    "task_label": "ä»»åŠ¡",
                    "pain_task": "åˆ†æç—›ç‚¹ï¼šæ€»ç»“ 3 ä¸ªä¸»è¦æŠ—æ‹’ç‚¹ï¼ˆä¾›å†…éƒ¨å‚è€ƒï¼Œä¸è¦åœ¨æ–‡æ¡ˆä¸­ç›´æ¥æåŠï¼‰ã€‚",
                    "json_instruction": "è¯·ç›´æ¥å›å¤ JSON æ ¼å¼ï¼š",
                    "forbidden": ["æˆ‘ä»¬ç†è§£æ‚¨çš„ç–‘è™‘", "é¢å¯¹å¸‚åœºè´¨ç–‘", "æ‚¨æ‹…å¿ƒçš„ï¼Œæˆ‘ä»¬å¬è§äº†"],
                    "structure_intro": "æ–‡æ¡ˆç»“æ„è§„èŒƒï¼ˆå¿…é¡»æŒ‰æ­¤é¡ºåºï¼‰ï¼š",
                    "step1": "å¼€å¤´ï¼šä»¥ã€Œäº§å“åç§°ã€æˆ–ã€Œå¸ç›æ ‡é¢˜ã€å¼€å¤´ï¼ˆå¦‚ã€äº§å“åã€‘æˆ– âœ¨æ ‡è¯­ï¼‰",
                    "step2": "æ ¸å¿ƒå–ç‚¹ï¼šç”¨ç¬¦å·åˆ—ç‚¹ï¼ˆâœ¨/ğŸ“Š/ğŸ¯ï¼‰ä»‹ç» 3-5 ä¸ªæ ¸å¿ƒå–ç‚¹ä¸è§„æ ¼",
                    "step3": "ä¿¡ä»»å»ºç«‹ï¼šç®€çŸ­æåŠè®¤è¯/æ•°æ®/å£ç¢‘ï¼ˆå·§å¦™åŒ–è§£å¸‚åœºç–‘è™‘ï¼Œä½†ä¸ç›´æ¥æã€Œç–‘è™‘ã€ï¼‰",
                    "step4": "ç»“å°¾ CTAï¼šæ˜ç¡®è¡ŒåŠ¨å‘¼åï¼ˆç«‹å³è´­ä¹°/é™æ—¶ä¼˜æƒ /ç‚¹å‡»äº†è§£æ›´å¤šï¼‰",
                    "word_count": "150-250 å­—",
                    "short_copy_title": "å®æˆ˜çˆ†æ¬¾çŸ­æ–‡æ¡ˆ",
                    "short_copy_desc": "æ’°å†™ 3 åˆ™é€‚åˆç¤¾ç¾¤å¹³å° (æŠ–éŸ³/æ·˜å®/å°çº¢ä¹¦) çš„çˆ†æ¬¾çŸ­æ–‡æ¡ˆï¼Œæ¯åˆ™çº¦ 50-80 å­—ï¼ŒEmoji ä¸°å¯Œï¼Œè¯­æ°”è‡ªç„¶",
                    "example_opens": [
                        f"ã€Œã€{product_name}ã€‘â€” ç§‘å­¦é¥®æ°´æ–°æ ‡å‡† âœ¨ã€",
                        f"ã€ŒğŸ”¬ {product_name}ï½œæƒå¨è®¤è¯ Ã— é«˜å“è´¨ã€",
                        "ã€Œå‘Šåˆ«æ™®é€šæ°´æ¯ï¼Œé‡è§ä¸“ä¸šçº§ç§‘æŠ€ ğŸ’§ã€"
                    ]
                },
                "en": {
                    "style_map": {
                        "professional": "Professional, Business-Focused",
                        "friendly": "Friendly, Casual & Fun",
                        "luxury": "Luxurious, Premium Feel",
                        "minimalist": "Minimalist, Clean & Clear",
                        "storytelling": "Storytelling, Narrative-Driven"
                    },
                    "role": "You are a top-tier e-commerce copywriter specializing in ready-to-use product descriptions.",
                    "product_label": "Product",
                    "price_label": "Price",
                    "style_label": "Requested Style",
                    "original_label": "Original Copy",
                    "neg_label": "Market Negative Feedback (address subtly, don't mention directly)",
                    "pos_label": "Market Positive Feedback (preserve and strengthen)",
                    "task_label": "Tasks",
                    "pain_task": "Analyze Pain Points: Summarize 3 key objections (for internal reference, don't mention in copy).",
                    "json_instruction": "Reply in JSON format only:",
                    "forbidden": ["We understand your concerns", "Addressing market skepticism", "Your worries, we hear them"],
                    "structure_intro": "Copy Structure (must follow this order):",
                    "step1": "Opening: Start with 'Product Name' or 'Catchy Headline' (e.g., ã€Productã€‘or âœ¨ Tagline)",
                    "step2": "Core Features: Use bullet points (âœ¨/ğŸ“Š/ğŸ¯) to introduce 3-5 key features & specs",
                    "step3": "Trust Building: Briefly mention certifications/data/testimonials (subtly address concerns)",
                    "step4": "CTA: Clear call-to-action (Buy Now/Limited Offer/Learn More)",
                    "word_count": "100-180 words",
                    "short_copy_title": "Social Media Short Copies",
                    "short_copy_desc": "Write 3 viral-ready posts for social platforms (IG/Amazon/FB), 40-60 words each, emoji-rich",
                    "example_opens": [
                        f"\"ã€{product_name}ã€‘â€” Your New Hydration Standard âœ¨\"",
                        f"\"ğŸ”¬ {product_name} | SGS Certified Ã— Premium Quality\"",
                        "\"Upgrade your daily hydration game ğŸ’§\""
                    ]
                }
            }
            
            lc = lang_configs.get(language, lang_configs["zh-TW"])
            style_desc = lc["style_map"].get(style, lc["style_map"]["professional"])

            # 2. æ§‹å»º Prompt (å€åˆ† ç”¢å“ vs å•†æ¥­è¨ˆåŠƒ)
            if source_type == 'pdf' or source_type == 'txt':
                # Business Plan Mode: Only Strategy
                task_instruction = f"""
                2. **Optimization Advice / å„ªåŒ–å»ºè­°**ï¼š
                   - Provide specific improvement directions and refined arguments for the business plan.
                   - Style: {style_desc}
                """
                json_format = """
                {
                    "pain_points_summary": "Key concerns summary...",
                    "refined_copy": "Optimization advice and refined arguments..."
                }
                """
            else:
                # Product Mode: ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„å®Œæ•´è¡ŒéŠ·æ–‡æ¡ˆ
                forbidden_list = "\n                   ".join([f"âŒ \"{f}\"" for f in lc["forbidden"]])
                examples_list = "\n                   ".join([f"âœ… {ex}" for ex in lc["example_opens"]])
                
                task_instruction = f"""
                2. **Optimized Ready-to-Use Copy / å„ªåŒ–å¾Œå®Œæ•´æ–‡æ¡ˆ**ï¼š
                   
                   ğŸ¨ **Style / æ–‡æ¡ˆé¢¨æ ¼è¦æ±‚**ï¼šã€Œ{style_desc}ã€
                   You MUST write in this style throughout - word choice, tone, and sentence structure.
                   
                   âš ï¸ **CRITICAL RULE**: Generate a **ready-to-copy-paste e-commerce product description**.
                   
                   **{lc["structure_intro"]}**
                   1ï¸âƒ£ {lc["step1"]}
                   2ï¸âƒ£ {lc["step2"]}
                   3ï¸âƒ£ {lc["step3"]}
                   4ï¸âƒ£ {lc["step4"]}
                   
                   **Word Count / å­—æ•¸**ï¼š{lc["word_count"]}
                   
                   **ABSOLUTELY FORBIDDEN (Violation = Failure) / çµ•å°ç¦æ­¢**ï¼š
                   {forbidden_list}
                   âŒ Any form of "response-style" or "explanatory" opening
                   âŒ FAQ format
                   âŒ Multi-paragraph responses to different objections
                   
                   **Correct Opening Examples / æ­£ç¢ºé–‹é ­ç¯„ä¾‹**ï¼š
                   {examples_list}

                3. **{lc["short_copy_title"]}**ï¼š
                   - Also use ã€Œ{style_desc}ã€ style
                   - {lc["short_copy_desc"]}
                """
                json_format = """
                {
                    "strategy_rationale": "Strategy analysis...",
                    "pain_points_summary": "3 key market concerns...",
                    "refined_copy": "ã€Ready-to-copy product description, starting with product name or headlineã€‘",
                    "marketing_copy": [
                        {"title": "Title 1", "body": "Body 1...", "hashtags": "#tag1 #tag2"},
                        {"title": "Title 2", "body": "Body 2...", "hashtags": "#tag1 #tag2"},
                        {"title": "Title 3", "body": "Body 3...", "hashtags": "#tag1 #tag2"}
                    ]
                }
                """

            prompt = f"""{lc["role"]}

ğŸ“¦ {lc["product_label"]}ï¼š{product_name}
ğŸ’° {lc["price_label"]}ï¼š{price}
ğŸ¨ {lc["style_label"]}ï¼š{style_desc}

ã€{lc["original_label"]}ã€‘
{original_copy}

ã€{lc["neg_label"]}ã€‘
{neg_texts}

ã€{lc["pos_label"]}ã€‘
{pos_texts}

ã€{lc["task_label"]}ã€‘
1. **{lc["pain_task"]}**
{task_instruction}

{lc["json_instruction"]}
{json_format}
"""



            # 3. Call Gemini API
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"maxOutputTokens": 8192, "temperature": 0.7, "responseMimeType": "application/json"}
            }
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash"]
            ai_text = "{}"
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ”„ [RefineCopy] Trying model: {model}")
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                    if response.status_code == 200:
                        result = response.json()
                        ai_text = result['candidates'][0]['content']['parts'][0]['text']
                        break
                except Exception as e:
                    print(f"âŒ [RefineCopy] Error {model}: {e}")

            # 4. Parse Result
            print(f"DEBUG: AI Raw Response: {ai_text}") # Log raw response
            data = self._clean_and_parse_json(ai_text)
            print(f"DEBUG: Parsed Data: {data}") # Log parsed data

            # Force Format Formatting for 'marketing_copy'
            marketing_copy_raw = data.get("marketing_copy")
            formatted_copy = ""

            if isinstance(marketing_copy_raw, list):
                # Clean up structured JSON into the user-requested Plain Text format
                formatted_pieces = []
                for idx, item in enumerate(marketing_copy_raw):
                    if isinstance(item, dict):
                        title = item.get("title", "")
                        body = item.get("body", "")
                        tags = item.get("hashtags", "")
                        # Construct the text block
                        block = f"ã€æ–‡æ¡ˆ {idx+1}ã€‘{title}\n\n{body}\n\n{tags}"
                        formatted_pieces.append(block)
                    elif isinstance(item, str):
                        formatted_pieces.append(item)
                
                formatted_copy = "\n\n---\n\n".join(formatted_pieces)
                data["marketing_copy"] = formatted_copy # Overwrite with plain text
                print(f"âœ… [SmartFormat] Converted JSON List to Plain Text:\n{formatted_copy[:100]}...")

            elif isinstance(marketing_copy_raw, str):
                # Ensure it's not a stringified JSON
                if marketing_copy_raw.strip().startswith("[") and marketing_copy_raw.strip().endswith("]"):
                    import json
                    try:
                        parsed_list = json.loads(marketing_copy_raw)
                        if isinstance(parsed_list, list):
                            formatted_pieces = []
                            for idx, item in enumerate(parsed_list):
                                if isinstance(item, dict):
                                    title = item.get("title", "")
                                    body = item.get("body", "")
                                    tags = item.get("hashtags", "")
                                    block = f"ã€æ–‡æ¡ˆ {idx+1}ã€‘{title}\n\n{body}\n\n{tags}"
                                    formatted_pieces.append(block)
                            formatted_copy = "\n\n---\n\n".join(formatted_pieces)
                            data["marketing_copy"] = formatted_copy
                            print(f"âœ… [SmartFormat] Converted Stringified JSON to Plain Text")
                    except:
                        pass # Keep as is if parsing fails
            
            final_refined = data.get("refined_copy", original_copy)
            


            if not final_refined:
                print("WARNING: Refined copy is empty. Checking fallback...")
                if original_copy:
                    final_refined = original_copy
                else:
                    # Robust Fallback: IF original copy is missing (mobile error case), generate one.
                    final_refined = f"ã€{product_name}ã€‘\n\né€™æ¬¾ç”¢å“æ³¨é‡ç´°ç¯€èˆ‡å“è³ªï¼Œå°ˆç‚ºè¿½æ±‚å“è¶Šçš„æ‚¨æ‰“é€ ã€‚å”®åƒ¹ {price} å…ƒï¼Œæ€§åƒ¹æ¯”æ¥µé«˜ã€‚ç„¡è«–æ˜¯åŠŸèƒ½æ€§é‚„æ˜¯è¨­è¨ˆæ„Ÿï¼Œéƒ½èƒ½æ»¿è¶³æ‚¨çš„æœŸå¾…ã€‚\n\nç«‹å³å…¥æ‰‹ï¼Œé«”é©—ä¸å‡¡ï¼"
                    logger.info(f"âš ï¸ [RefineCopy] Generated emergency fallback copy for {product_name}")

            return {
                "success": True,
                "pain_points": data.get("pain_points_summary", "åˆ†æä¸­..."),
                "refined_copy": str(final_refined),
                "marketing_copy": data.get("marketing_copy", "") 
            }


        except Exception as e:
            print(f"âŒ refine_marketing_copy Exception: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e), "refined_copy": original_copy}
            self._push_text(user_id, "âŒ AI ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç›´æ¥è¼¸å…¥ã€Œ**1**ã€è‡ªè¡Œè¼¸å…¥æè¿°")

    def _clean_and_parse_json(self, ai_text):
        """Helper to clean and parse JSON with robust error handling (From GitHub Original)"""
        if not ai_text or not isinstance(ai_text, str):
            return {}

        clean_text = ai_text
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", ai_text, re.DOTALL)
        if match:
            clean_text = match.group(1)
        
        try:
            data = json.loads(clean_text)
            if isinstance(data, dict):
                return data
            return {}
        except json.JSONDecodeError:
            # Simple fix attempt for truncated JSON
            fixed_text = clean_text.strip()
            # Try to close open braces/brackets
            open_braces = fixed_text.count('{') - fixed_text.count('}')
            if open_braces > 0: fixed_text += '}' * open_braces
            
            open_brackets = fixed_text.count('[') - fixed_text.count(']')
            if open_brackets > 0: fixed_text += ']' * open_brackets
            
            # Remove trailing commas before closing braces (common issue)
            fixed_text = re.sub(r',\s*([}\]])', r'\1', fixed_text)

            try:
                data = json.loads(fixed_text)
                if isinstance(data, dict):
                    return data
                return {}
            except:
                print(f"âš ï¸ Failed to parse AI JSON after cleaning: {clean_text[:50]}...")
                return {}

    async def generate_marketing_copy(self, image_data_input, product_name: str, price: str, style: str = "professional", language: str = "zh-TW"):
        """
        ç¶²é ç«¯ API ä½¿ç”¨ï¼šæ ¹æ“šåœ–ç‰‡ï¼ˆå–®å¼µæˆ–å¤šå¼µï¼‰ç”Ÿæˆè¡ŒéŠ·æ–‡æ¡ˆ
        ä½¿ç”¨ GitHub åŸç‰ˆ A/B Promptï¼ˆå“è³ªæ›´å¥½ï¼‰ï¼Œä½†åªè¿”å›å…¶ä¸­ä¸€æ®µ
        æ”¯æ´å¤šèªè¨€ï¼šzh-TWï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€zh-CNï¼ˆç°¡é«”ä¸­æ–‡ï¼‰ã€enï¼ˆè‹±æ–‡ï¼‰
        """
        try:
            # 1. Process Images (List or Single)
            image_bytes_list = image_data_input if isinstance(image_data_input, list) else [image_data_input]
            image_parts = []
            
            for idx, img_bytes in enumerate(image_bytes_list):
                 # Auto-detect mime type
                if img_bytes.startswith(b'\x89PNG'): mime_type = "image/png"
                elif img_bytes.startswith(b'GIF8'): mime_type = "image/gif"
                elif img_bytes.startswith(b'RIFF') and img_bytes[8:12] == b'WEBP': mime_type = "image/webp"
                else: mime_type = "image/jpeg"
                
                img_b64 = base64.b64encode(img_bytes).decode('utf-8')
                image_parts.append({"inline_data": {"mime_type": mime_type, "data": img_b64}})
            
            print(f"ğŸ“¸ [Web Copywriting] Processing {len(image_parts)} images, language={language}...")
            
            # å¤šèªè¨€é¢¨æ ¼æŒ‡ä»¤
            style_prompts_by_lang = {
                "zh-TW": {
                    "professional": "è«‹ä½¿ç”¨**å°ˆæ¥­ç©©é‡**çš„å•†å‹™é¢¨æ ¼ã€‚ç”¨è©æ­£å¼ï¼Œå¼·èª¿ç”¢å“çš„æŠ€è¡“è¦æ ¼ã€æ•¸æ“šèˆ‡å¯é æ€§ï¼Œé©åˆ B2B æˆ–è¿½æ±‚æ•ˆèƒ½çš„å°ˆæ¥­äººå£«ã€‚",
                    "friendly": "è«‹ä½¿ç”¨**è¦ªåˆ‡æ´»æ½‘**çš„è¼•é¬†é¢¨æ ¼ã€‚åƒè·Ÿæœ‹å‹èŠå¤©ä¸€æ¨£ï¼Œä½†ä¹Ÿè¦æ¸…æ¥šä»‹ç´¹ç”¢å“çš„æ ¸å¿ƒè¦æ ¼ï¼ˆå¦‚è—ç‰™ã€çºŒèˆªï¼‰ï¼Œåˆ¥è®“è®€è€…è¦ºå¾—æ²’å…§å®¹ã€‚",
                    "luxury": "è«‹ä½¿ç”¨**é«˜ç«¯å¥¢è¯**çš„å“ç‰Œé¢¨æ ¼ã€‚ç”¨è©è¬›ç©¶ã€å¯Œæœ‰è³ªæ„Ÿï¼Œä¸¦å°‡æŠ€è¡“è¦æ ¼è½‰åŒ–ç‚ºå°Šè²´é«”é©—çš„æè¿°ï¼ˆä¾‹å¦‚ï¼šç„¡ç·šé€£æ¥å¸¶ä¾†çš„ç„¡æ‹˜ç„¡æŸï¼‰ã€‚",
                    "minimalist": "è«‹ä½¿ç”¨**ç°¡ç´„æ¸…çˆ½**çš„æ¥µç°¡é¢¨æ ¼ã€‚å¥å­ç²¾ç…‰æœ‰åŠ›ï¼Œç›´æ¥åˆ—å‡ºæ ¸å¿ƒè¦æ ¼æ•¸æ“šï¼Œå»é™¤å†—é¤˜å½¢å®¹è©ã€‚",
                    "storytelling": "è«‹ä½¿ç”¨**æ•…äº‹æ•˜è¿°**çš„æƒ…å¢ƒé¢¨æ ¼ã€‚åœ¨æ•…äº‹ä¸­è‡ªç„¶å¸¶å‡ºç”¢å“çš„è¦æ ¼å„ªå‹¢ï¼ˆå¦‚ï¼šä¸ç”¨æ“”å¿ƒæ²’é›»ï¼Œå› ç‚ºå®ƒæœ‰è¶…é•·çºŒèˆª...ï¼‰ã€‚"
                },
                "zh-CN": {
                    "professional": "è¯·ä½¿ç”¨**ä¸“ä¸šç¨³é‡**çš„å•†åŠ¡é£æ ¼ã€‚ç”¨è¯æ­£å¼ï¼Œå¼ºè°ƒäº§å“çš„æŠ€æœ¯è§„æ ¼ã€æ•°æ®ä¸å¯é æ€§ï¼Œé€‚åˆ B2B æˆ–è¿½æ±‚æ•ˆèƒ½çš„ä¸“ä¸šäººå£«ã€‚",
                    "friendly": "è¯·ä½¿ç”¨**äº²åˆ‡æ´»æ³¼**çš„è½»æ¾é£æ ¼ã€‚åƒè·Ÿæœ‹å‹èŠå¤©ä¸€æ ·ï¼Œä½†ä¹Ÿè¦æ¸…æ¥šä»‹ç»äº§å“çš„æ ¸å¿ƒè§„æ ¼ï¼ˆå¦‚è“ç‰™ã€ç»­èˆªï¼‰ï¼Œåˆ«è®©è¯»è€…è§‰å¾—æ²¡å†…å®¹ã€‚",
                    "luxury": "è¯·ä½¿ç”¨**é«˜ç«¯å¥¢å**çš„å“ç‰Œé£æ ¼ã€‚ç”¨è¯è®²ç©¶ã€å¯Œæœ‰è´¨æ„Ÿï¼Œå¹¶å°†æŠ€æœ¯è§„æ ¼è½¬åŒ–ä¸ºå°Šè´µä½“éªŒçš„æè¿°ï¼ˆä¾‹å¦‚ï¼šæ— çº¿è¿æ¥å¸¦æ¥çš„æ— æ‹˜æ— æŸï¼‰ã€‚",
                    "minimalist": "è¯·ä½¿ç”¨**ç®€çº¦æ¸…çˆ½**çš„æç®€é£æ ¼ã€‚å¥å­ç²¾ç‚¼æœ‰åŠ›ï¼Œç›´æ¥åˆ—å‡ºæ ¸å¿ƒè§„æ ¼æ•°æ®ï¼Œå»é™¤å†—ä½™å½¢å®¹è¯ã€‚",
                    "storytelling": "è¯·ä½¿ç”¨**æ•…äº‹å™è¿°**çš„æƒ…å¢ƒé£æ ¼ã€‚åœ¨æ•…äº‹ä¸­è‡ªç„¶å¸¦å‡ºäº§å“çš„è§„æ ¼ä¼˜åŠ¿ï¼ˆå¦‚ï¼šä¸ç”¨æ‹…å¿ƒæ²¡ç”µï¼Œå› ä¸ºå®ƒæœ‰è¶…é•¿ç»­èˆª...ï¼‰ã€‚"
                },
                "en": {
                    "professional": "Please use a **professional and steady** business style. Use formal language, emphasizing technical specifications, data, and reliability. Suitable for B2B or professional audiences.",
                    "friendly": "Please use a **friendly and lively** casual style. Write as if chatting with a friend, but clearly introduce core specs (like Bluetooth, battery life).",
                    "luxury": "Please use a **high-end luxury** brand style. Use refined, textured language, transforming technical specs into premium experience descriptions.",
                    "minimalist": "Please use a **minimalist and clean** style. Sentences should be concise and powerful, directly listing core specs without redundant adjectives.",
                    "storytelling": "Please use a **storytelling** scenario style. Naturally bring out product advantages within the story narrative."
                }
            }
            
            lang_styles = style_prompts_by_lang.get(language, style_prompts_by_lang["zh-TW"])
            style_instruction = lang_styles.get(style, lang_styles["professional"])
            
            # 2. æœå°‹ç”¢å“è¦æ ¼ (New Feature)
            product_specs = ""
            if product_name and product_name != "ç”¢å“" and product_name != "æœªå‘½åç”¢å“":
                 try:
                     from app.services.price_search import search_product_specs_sync
                     print(f"ğŸ” [Web Copywriting] Searching specs for: {product_name}...")
                     product_specs = search_product_specs_sync(product_name)
                     print(f"ğŸ” [Web Copywriting] Specs length: {len(product_specs)}")
                 except Exception as e:
                     print(f"âš ï¸ Spec search failed: {e}")

            # ä½¿ç”¨ GitHub åŸç‰ˆ Promptï¼ˆA/B æ ¼å¼ï¼‰ä¸¦åŠ å…¥è¦æ ¼è³‡è¨Š
            # æ ¹æ“šåœ–ç‰‡æ•¸é‡èª¿æ•´ prompt
            multi_image_instruction = ""
            if len(image_parts) > 1:
                multi_image_instruction = f"""
ğŸ“¸ **å¤šåœ–åˆ†ææŒ‡å¼•** (å…± {len(image_parts)} å¼µåœ–ç‰‡)ï¼š
ç”¨æˆ¶ä¸Šå‚³äº†å¤šå¼µåœ–ç‰‡ï¼Œé€™ä»£è¡¨ä»–å€‘å¸Œæœ›ä½ èƒ½å¤ ï¼š
1. **è­˜åˆ¥æ¯å¼µåœ–ç‰‡çš„è¦–è§’èˆ‡ç”¨é€”**ï¼š
   - å¯èƒ½æ˜¯ç”¢å“çš„ä¸åŒè§’åº¦ï¼ˆæ­£é¢ã€å´é¢ã€èƒŒé¢ã€ä¿¯è¦–ã€ç´°ç¯€ç‰¹å¯«ï¼‰
   - å¯èƒ½æ˜¯ä½¿ç”¨æƒ…å¢ƒå±•ç¤ºã€åŒ…è£å±•ç¤ºã€é…ä»¶å±•ç¤º
   - å¯èƒ½æ˜¯é¡è‰²/æ¬¾å¼è®ŠåŒ–
   
2. **æ•´åˆå¤šè¦–è§’è³‡è¨Š**ï¼š
   - è«‹å…ˆåœ¨å¿ƒä¸­åˆ†ææ¯å¼µåœ–ç‰‡åˆ†åˆ¥å±•ç¤ºäº†ä»€éº¼
   - æ‰¾å‡ºåœ–ç‰‡ä¹‹é–“çš„é—œè¯æ€§èˆ‡äº’è£œæ€§
   - ä¸è¦éºæ¼ä»»ä½•ä¸€å¼µåœ–ç‰‡ä¸­çš„é—œéµè³‡è¨Š
   
3. **åœ¨æ–‡æ¡ˆä¸­æ˜ç¢ºé«”ç¾å¤šè¦–è§’åˆ†æ**ï¼š
   - **å‹™å¿…åœ¨æ–‡æ¡ˆä¸­æåŠä½ å·²è§€å¯Ÿå¤šå€‹è§’åº¦/è¦–è§’**ï¼ˆä¾‹å¦‚ï¼šã€Œå¾æ­£é¢åˆ°å´é¢ã€ã€ã€Œå„å€‹è§’åº¦ã€ã€ã€Œç´°ç¯€è™•ã€ã€ã€Œç„¡è«–å¾å“ªå€‹è¦–è§’ã€ç­‰ï¼‰
   - åœ¨æ–‡æ¡ˆä¸­è‡ªç„¶èå…¥å¾ä¸åŒåœ–ç‰‡ä¸­è§€å¯Ÿåˆ°çš„ç‰¹é»
   - å¦‚æœæœ‰ç´°ç¯€åœ–ï¼Œè«‹å¼·èª¿è©²ç´°ç¯€çš„è¨­è¨ˆå·§æ€æˆ–æŠ€è¡“äº®é»
   - å¦‚æœæœ‰ä½¿ç”¨æƒ…å¢ƒåœ–ï¼Œè«‹æè¿°è©²æƒ…å¢ƒçš„é«”é©—æ„Ÿå—
   - **è®“è®€è€…èƒ½æ„Ÿå—åˆ°é€™ä»½æ–‡æ¡ˆæ˜¯åŸºæ–¼å°ç”¢å“å…¨æ–¹ä½è§€å¯Ÿå¾Œçš„ç¶œåˆæè¿°**
   
âš ï¸ **å¼·åˆ¶è¦æ±‚**ï¼šç”±æ–¼ç”¨æˆ¶ä¸Šå‚³äº† {len(image_parts)} å¼µåœ–ç‰‡ï¼Œä½ çš„æ–‡æ¡ˆä¸­**å¿…é ˆ**åŒ…å«èƒ½é«”ç¾ã€Œå¤šè¦–è§’åˆ†æã€çš„æªè¾­ï¼Œä¾‹å¦‚ï¼š
   - ã€Œå¾å„å€‹è§’åº¦è§€å¯Ÿã€
   - ã€Œç„¡è«–å¾æ­£é¢é‚„æ˜¯å´é¢ã€
   - ã€Œç´°ç¯€ä¹‹è™•ã€
   - ã€Œå…¨æ–¹ä½å±•ç¾ã€
   - ã€Œæ¯å€‹ç´°ç¯€éƒ½ç¶“éç²¾å¿ƒè¨­è¨ˆã€
é€™æ¨£ç”¨æˆ¶æ‰èƒ½ç¢ºèªä½ ç¢ºå¯¦ç†è§£ä¸¦æ•´åˆäº†æ‰€æœ‰ä¸Šå‚³çš„åœ–ç‰‡å…§å®¹ã€‚
"""
            # å¤šèªè¨€ Prompt æ¨¡æ¿
            prompt_templates = {
                "zh-TW": f"""ğŸš¨ **ç³»çµ±èªè¨€è¨­å®šï¼šç¹é«”ä¸­æ–‡ (zh-TW)** ğŸš¨
âš ï¸ æœ¬æç¤ºçš„æ‰€æœ‰è¼¸å‡ºå…§å®¹å¿…é ˆä½¿ç”¨**ç¹é«”ä¸­æ–‡**æ’°å¯«ã€‚
âš ï¸ ç¦æ­¢è¼¸å‡ºä»»ä½•è‹±æ–‡æ–‡æ¡ˆå…§å®¹ï¼ˆJSON æ¬„ä½åç¨±é™¤å¤–ï¼‰ã€‚

è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™ {len(image_parts)} å¼µç”¢å“åœ–ç‰‡ï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚
{multi_image_instruction}
ğŸ¨ **å¯«ä½œé¢¨æ ¼è¦æ±‚**ï¼š{style_instruction}

ğŸ“¦ **ç”¢å“è³‡è¨Š**ï¼š
- ç”¢å“åç¨±ï¼š{product_name}
- å»ºè­°å”®åƒ¹ï¼š{price}
- åƒè€ƒè¦æ ¼èˆ‡ç‰¹è‰²ï¼š{product_specs if product_specs else "(è«‹æ ¹æ“šåœ–ç‰‡ç´°ç¯€æ¨æ–·)"}

ğŸ” **è¦æ ¼å¼•ç”¨å¼·åˆ¶è¦æ±‚**ï¼š
{'âš ï¸ é‡è¦ï¼šç³»çµ±å·²æœå°‹åˆ°æ­¤ç”¢å“çš„è©³ç´°è¦æ ¼è³‡è¨Šï¼Œä½ **å¿…é ˆ**åœ¨æ–‡æ¡ˆä¸­æ˜ç¢ºæåŠè‡³å°‘ 3-5 å€‹å…·é«”è¦æ ¼åƒæ•¸ï¼ˆå¦‚ï¼šè—ç‰™ç‰ˆæœ¬ã€é›»æ± å®¹é‡ã€é‡é‡ã€å°ºå¯¸ã€æè³ªã€æŠ€è¡“ç‰¹æ€§ç­‰ï¼‰ã€‚é€™äº›è¦æ ¼å¿…é ˆè‡ªç„¶èå…¥æ–‡æ¡ˆï¼Œè€Œéå–®ç´”åˆ—è¡¨ã€‚' if product_specs else 'âš ï¸ è«‹æ ¹æ“šåœ–ç‰‡ä»”ç´°è§€å¯Ÿæ¨æ–·ç”¢å“è¦æ ¼ï¼Œä¸¦åœ¨æ–‡æ¡ˆä¸­æåŠä½ è§€å¯Ÿåˆ°çš„æŠ€è¡“ç´°ç¯€èˆ‡åƒæ•¸ã€‚'}

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆ**ç¹é«”ä¸­æ–‡**ï¼Œæ¯æ®µç´„ 150-200 å­—ï¼‰ï¼š

ã€Aã€‘æƒ…æ„Ÿå…±é³´ç‰ˆ - å´é‡æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨å ´æ™¯çš„ç¾å¥½é«”é©—ï¼Œä½†ä»éœ€è‡ªç„¶æåŠç”¢å“è¦æ ¼ã€‚
ã€Bã€‘ç†æ€§åˆ†æç‰ˆ - å´é‡ç”¢å“å„ªå‹¢ï¼Œ**å¿…é ˆè©³ç´°åˆ—å‡ºæ ¸å¿ƒè¦æ ¼äº®é»èˆ‡æŠ€è¡“åƒæ•¸**ã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
""",
                "zh-CN": f"""ğŸš¨ **ç³»ç»Ÿè¯­è¨€è®¾å®šï¼šç®€ä½“ä¸­æ–‡ (zh-CN)** ğŸš¨
âš ï¸ æœ¬æç¤ºçš„æ‰€æœ‰è¾“å‡ºå†…å®¹å¿…é¡»ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**æ’°å†™ã€‚
âš ï¸ ç¦æ­¢è¾“å‡ºä»»ä½•ç¹ä½“ä¸­æ–‡æˆ–è‹±æ–‡æ–‡æ¡ˆå†…å®¹ï¼ˆJSON å­—æ®µåç§°é™¤å¤–ï¼‰ã€‚

è¯·æ‹…ä»»ä¸€ä½é¡¶çº§çš„å•†ä¸šæ–‡æ¡ˆç­–ç•¥å¤§å¸ˆã€‚è¯·æ·±å…¥åˆ†æè¿™ {len(image_parts)} å¼ äº§å“å›¾ç‰‡ï¼Œä¸ºè¿™æ¬¾äº§å“åˆ›é€ ä¸¤ä¸ªæˆªç„¶ä¸åŒçš„ã€Œå®Œç¾åº”ç”¨åœºæ™¯ã€ä¸ã€Œæ²‰æµ¸å¼è¥é”€æ–‡æ¡ˆã€ã€‚
{multi_image_instruction}
ğŸ¨ **å†™ä½œé£æ ¼è¦æ±‚**ï¼š{style_instruction}

ğŸ“¦ **äº§å“ä¿¡æ¯**ï¼š
- äº§å“åç§°ï¼š{product_name}
- å»ºè®®å”®ä»·ï¼š{price}
- å‚è€ƒè§„æ ¼ä¸ç‰¹è‰²ï¼š{product_specs if product_specs else "(è¯·æ ¹æ®å›¾ç‰‡ç»†èŠ‚æ¨æ–­)"}

ğŸ” **è§„æ ¼å¼•ç”¨å¼ºåˆ¶è¦æ±‚**ï¼š
{'âš ï¸ é‡è¦ï¼šç³»ç»Ÿå·²æœç´¢åˆ°æ­¤äº§å“çš„è¯¦ç»†è§„æ ¼ä¿¡æ¯ï¼Œä½ **å¿…é¡»**åœ¨æ–‡æ¡ˆä¸­æ˜ç¡®æåŠè‡³å°‘ 3-5 ä¸ªå…·ä½“è§„æ ¼å‚æ•°ï¼ˆå¦‚ï¼šè“ç‰™ç‰ˆæœ¬ã€ç”µæ± å®¹é‡ã€é‡é‡ã€å°ºå¯¸ã€æè´¨ã€æŠ€æœ¯ç‰¹æ€§ç­‰ï¼‰ã€‚è¿™äº›è§„æ ¼å¿…é¡»è‡ªç„¶èå…¥æ–‡æ¡ˆï¼Œè€Œéå•çº¯åˆ—è¡¨ã€‚' if product_specs else 'âš ï¸ è¯·æ ¹æ®å›¾ç‰‡ä»”ç»†è§‚å¯Ÿæ¨æ–­äº§å“è§„æ ¼ï¼Œå¹¶åœ¨æ–‡æ¡ˆä¸­æåŠä½ è§‚å¯Ÿåˆ°çš„æŠ€æœ¯ç»†èŠ‚ä¸å‚æ•°ã€‚'}

è¯·ç”Ÿæˆä¸¤æ®µä¸åŒåˆ‡å…¥ç‚¹çš„æ–‡æ¡ˆï¼ˆ**ç®€ä½“ä¸­æ–‡**ï¼Œæ¯æ®µçº¦ 150-200 å­—ï¼‰ï¼š

ã€Aã€‘æƒ…æ„Ÿå…±é¸£ç‰ˆ - ä¾§é‡æ„Ÿæ€§è¯‰æ±‚ï¼Œæç»˜ä½¿ç”¨åœºæ™¯çš„ç¾å¥½ä½“éªŒï¼Œä½†ä»éœ€è‡ªç„¶æåŠäº§å“è§„æ ¼ã€‚
ã€Bã€‘ç†æ€§åˆ†æç‰ˆ - ä¾§é‡äº§å“ä¼˜åŠ¿ï¼Œ**å¿…é¡»è¯¦ç»†åˆ—å‡ºæ ¸å¿ƒè§„æ ¼äº®ç‚¹ä¸æŠ€æœ¯å‚æ•°**ã€‚

è¯·ç›´æ¥å›å¤ JSON æ ¼å¼ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ ‡é¢˜",
    "description_a": "æ–‡æ¡ˆ A çš„å†…å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ ‡é¢˜",
    "description_b": "æ–‡æ¡ˆ B çš„å†…å®¹..."
}}
""",
                "en": f"""ğŸš¨ **System Language: English (en)** ğŸš¨
âš ï¸ All output content MUST be written in **English only**.
âš ï¸ Do NOT output any Chinese characters (JSON field names are exceptions).

Please act as a top-tier commercial copywriting strategist. Analyze these {len(image_parts)} product images and create two distinct "perfect application scenarios" with "immersive marketing copy" for this product.
{multi_image_instruction}
ğŸ¨ **Writing Style**: {style_instruction}

ğŸ“¦ **Product Information**:
- Product Name: {product_name}
- Suggested Price: {price}
- Reference Specs: {product_specs if product_specs else "(Please infer from image details)"}

ğŸ” **Specification Reference Requirements**:
{'âš ï¸ Important: The system has found detailed specifications for this product. You **MUST** explicitly mention at least 3-5 specific spec parameters in your copy (e.g., Bluetooth version, battery capacity, weight, dimensions, materials, technical features, etc.). These specs must be naturally integrated into the copy, not just listed.' if product_specs else 'âš ï¸ Please carefully observe the images to infer product specifications, and mention the technical details and parameters you observed in your copy.'}

Generate two different marketing copy approaches (in **English**, ~100-150 words each):

ã€Aã€‘Emotional Resonance - Focus on emotional appeal, describing the wonderful experience, but still naturally mention product specs.
ã€Bã€‘Rational Analysis - Focus on product advantages, **MUST detail core specification highlights and technical parameters**.

Reply directly in JSON format:
{{
    "title_a": "Title for Copy A",
    "description_a": "Content for Copy A...",
    "title_b": "Title for Copy B",
    "description_b": "Content for Copy B..."
}}
"""
            }
            
            prompt = prompt_templates.get(language, prompt_templates["zh-TW"])
            
            # API Setup - ä½¿ç”¨ GitHub åŸç‰ˆè¨­å®š (Token æ•¸éœ€è¶³å¤ å¤§)
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {"maxOutputTokens": 8192, "temperature": 0.8, "responseMimeType": "application/json"}
            }
            # Append all images
            payload["contents"][0]["parts"].extend(image_parts)
            
            models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
            ai_text = "{}"
            
            for model in models:
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ“¸ [Web Copywriting] Trying model: {model}")
                    # GitHub åŸå§‹è¨­å®šï¼štimeout=90, maxOutputTokens=8192
                    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                    
                    if response.status_code == 200:
                        result = response.json()
                        raw_text = result['candidates'][0]['content']['parts'][0]['text']
                        print(f"âœ… [Web Copywriting] Got response from {model}, len={len(raw_text)}")
                        if "description_a" in raw_text or "title_a" in raw_text:
                            ai_text = raw_text
                            break
                    elif response.status_code == 429:
                        print(f"âš ï¸ [Web Copywriting] Rate limited on {model}, trying next...")
                        await asyncio.sleep(1)
                    else:
                        print(f"âš ï¸ [Web Copywriting] Error {model}: {response.status_code}")
                except Exception as e:
                    print(f"âŒ [Web Copywriting] Exception {model}: {e}")

            # Robust Parsing using helper (GitHub Logic)
            print(f"ğŸ“ [Web Copywriting] Raw AI response: {ai_text[:200]}...")
            data = self._clean_and_parse_json(ai_text)
            print(f"âœ… [Web Copywriting] Parsed JSON keys: {list(data.keys())}")

            # æå– A/B æ–‡æ¡ˆ
            desc_a = data.get("description_a", "")
            desc_b = data.get("description_b", "")
            
            # è¿”å›å–®ç¯‡ï¼šå„ªå…ˆä½¿ç”¨ A æ®µï¼ˆæƒ…æ„Ÿå…±é³´ç‰ˆï¼‰
            copy_content = desc_a if desc_a else desc_b
            
            if not copy_content:
                print(f"âš ï¸ [Web Copywriting] Using fallback template!")
                copy_content = f"é€™æ¬¾{product_name}è¨­è¨ˆç²¾è‰¯ï¼Œæ˜¯è¿½æ±‚å“è³ªç”Ÿæ´»çš„æœ€ä½³é¸æ“‡ã€‚ç„¡è«–æ˜¯è‡ªç”¨é‚„æ˜¯é€ç¦®ï¼Œéƒ½èƒ½å±•ç¾æ‚¨çš„ç¨ç‰¹å“å‘³ã€‚å”®åƒ¹ {price} å…ƒï¼Œç¾åœ¨æ­£æ˜¯å…¥æ‰‹çš„å¥½æ™‚æ©Ÿï¼"

            return {
                "product_type": product_name,
                "target_audience": "ä¸€èˆ¬æ¶ˆè²»è€…",
                "copy_title": data.get("title_a", "âœ¨ ç”¢å“é­…åŠ›"),
                "copy_content": copy_content
            }

        except Exception as e:
            print(f"âŒ generate_marketing_copy éŒ¯èª¤: {e}")
            return {"error": str(e)}


    async def _start_simulation(self, user_id, reply_token):
        """çµ„åˆç”¢å“è³‡è¨Šä¸¦å•Ÿå‹•æ¨¡æ“¬åˆ†æ"""
        session = self.user_session.get(user_id)
        if not session:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")
            return
        
        # å–å¾—æ‰€æœ‰è³‡è¨Š
        image_bytes = session.get("image_bytes")
        message_id = session.get("message_id")
        product_name = session.get("product_name", "")
        product_price = session.get("product_price", "")
        product_description = session.get("product_description", "")
        
        # çµ„åˆæ–‡å­—ä¸Šä¸‹æ–‡
        text_context = ""
        if product_name:
            text_context += f"ç”¢å“åç¨±ï¼š{product_name}\n"
        if product_price:
            text_context += f"å»ºè­°å”®åƒ¹ï¼š{product_price}\n"
        if product_description:
            text_context += f"ç”¢å“æè¿°ï¼š{product_description}\n"
        
        text_context = text_context.strip() if text_context else None
        
        print(f"ğŸ“ [SESSION] å•Ÿå‹•æ¨¡æ“¬: name={product_name}, price={product_price}, desc={product_description[:30] if product_description else 'None'}...")
        
        # æ¸…é™¤ session
        del self.user_session[user_id]
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ”µ **MIRRA å¹³è¡Œæ™‚ç©ºé æ¼”ç³»çµ±å•Ÿå‹•ä¸­...**\n\n"
            f"ğŸ“¦ ç”¢å“ï¼š{product_name or '(åœ–ç‰‡åˆ†æ)'}\n"
            f"ğŸ’° å”®åƒ¹ï¼š{product_price or 'æœªå®š'}\n\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–š 1,000 ä½è™›æ“¬å¸‚æ°‘é€²å…¥è¼¿è«–ç«¶æŠ€å ´...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨åˆ†ææ‚¨çš„ç”¢å“åœ–ç‰‡ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ AI åˆ†æï¼ˆé‡æ§‹å¾Œï¼šä½¿ç”¨ run_simulation_with_image_dataï¼‰
        try:
            with open("debug_start.log", "w", encoding="utf-8") as f: 
                f.write(f"[{sim_id}] Ready to call run_simulation_with_image_data\n")
                f.write(f"[{sim_id}] Image Bytes len: {len(image_bytes) if image_bytes else 'None'}\n")
            
            print(f"ğŸš€ [SESSION] Calling run_simulation_with_image_data for {sim_id}")
            await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)
            
            with open("debug_start.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Call returned (Success)\n")
        except Exception as e:
            with open("debug_start.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Call FAILED: {e}\n")
            print(f"âŒ [SESSION] Call to run_simulation_with_image_data failed: {e}")
            self._handle_error_db(sim_id, f"Internal Launch Error: {e}")

    def _push_text(self, user_id, text):
        """ä¸»å‹•æ¨é€æ–‡å­—è¨Šæ¯çµ¦ç”¨æˆ¶ï¼ˆéå›è¦†ï¼‰"""
        try:
            self.line_bot_api.push_message(
                PushMessageRequest(to=user_id, messages=[TextMessage(text=text)])
            )
        except Exception as e:
            print(f"âŒ Push message å¤±æ•—: {e}")

    async def _handle_file_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ C: æ”¶åˆ°æª”æ¡ˆ â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸"""
        file_name = event.message.file_name
        file_size = event.message.file_size
        message_id = event.message.id
        
        print(f"ğŸ“„ [FILE] æ”¶åˆ°æª”æ¡ˆ: {file_name}, size={file_size}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚º PDF
        if not file_name.lower().endswith('.pdf'):
            self.reply_text(reply_token, "âŒ ç›®å‰åƒ…æ”¯æ´ PDF æ ¼å¼çš„å•†æ¥­è¨ˆåŠƒæ›¸")
            return
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ“„ **MIRRA ç³»çµ±å·²è®€å–å•†æ¥­è¨ˆåŠƒæ›¸ (PDF)**\n\n"
            f"æ­£åœ¨å°‡å•†æ¥­æ¨¡å¼è§£æ§‹ä¸¦å‚³é€è‡³è¼¿è«–ç«¶æŠ€å ´...\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–šè™›æ“¬å¸‚æ°‘é‡å° **ã€Œå•†æ¥­å¯è¡Œæ€§ã€** èˆ‡ **ã€Œç²åˆ©æ¨¡å¼ã€** é€²è¡Œæ¨æ¼”...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨é–±è®€æ‚¨çš„å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ PDF åˆ†æï¼ˆå¾…é‡æ§‹ï¼‰
        try:
            # ä¸‹è¼‰ PDF
            print(f"ğŸ“¥ [PDF] ä¸‹è¼‰ PDF: message_id={message_id}")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            self.reply_text(reply_token, "âŒ PDF ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def process_image_with_ai(self, message_id, sim_id, text_context=None):
        """
        [Legacy Wrapper] 
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼ï¼Œä½†å…§éƒ¨æ”¹ç‚ºä¸‹è¼‰å¾Œèª¿ç”¨ run_simulation_with_image_data
        """
        try:
            print(f"ğŸš€ [LineBot] é–‹å§‹ AI åˆ†ææµç¨‹: sim_id={sim_id}")
            print(f"ğŸ“¥ [LineBot] ä¸‹è¼‰åœ–ç‰‡: message_id={message_id}")
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot] åœ–ç‰‡ä¸‹è¼‰å®Œæˆ: {len(image_bytes)} bytes")
            
            await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)
        except Exception as e:
            print(f"âŒ [LineBot] åœ–ç‰‡ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            # Error updating happens inside run_simulation_with_image_data for analysis errors
            # But if download fails, we handle it here roughly? 
            # Actually run_simulation handles db update. 
            pass

    async def process_pdf_with_ai(self, message_id, sim_id, file_name):
        """
        [Legacy Wrapper]
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼
        """
        try:
            print(f"ğŸ“„ [LineBot PDF] é–‹å§‹ PDF åˆ†ææµç¨‹: sim_id={sim_id}, file={file_name}")
            print(f"ğŸ“¥ [LineBot PDF] ä¸‹è¼‰ PDF...")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [LineBot PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")

    async def _run_abm_simulation(self, sampled_citizens, text_context=None, language="zh-TW", targeting=None, expert_mode=False):
        """
        åŸ·è¡Œ ABM (Agent-Based Modeling) æ¨¡æ“¬
        
        Args:
            sampled_citizens: å·²æŠ½æ¨£çš„å¸‚æ°‘è³‡æ–™åˆ—è¡¨
            text_context: ç”¢å“æè¿°æ–‡å­—
            language: èªè¨€è¨­å®š
            targeting: å—çœ¾å®šéŒ¨è¨­å®š {"age_range": [20, 60], "gender": "male", ...}
            expert_mode: æ˜¯å¦é–‹å•Ÿå°ˆå®¶æ¨¡å¼
        
        Returns:
            dict: {
                "evolution_data": æ„è¦‹æ¼”åŒ–æ•¸æ“šï¼ˆä¾›å‰ç«¯è¦–è¦ºåŒ–ï¼‰,
                "analytics_data": çªç¾è¡Œç‚ºåˆ†ææŒ‡æ¨™,
                "comments_data": ä»£è¡¨æ€§è©•è«–è³‡æ–™
            }
        """
        import numpy as np
        
        print(f"ğŸ§¬ [ABM] é–‹å§‹ ABM æ¨¡æ“¬æµç¨‹ï¼Œå…± {len(sampled_citizens)} ä½å¸‚æ°‘")
        
        # ç”¢å“è³‡è¨Šï¼ˆå¾ text_context ä¸­æå–æˆ–ä½¿ç”¨é»˜èªå€¼ï¼‰
        product_info = {
            "element": "Fire",  # é»˜èªäº”è¡Œå±¬æ€§ï¼ˆå¯¦éš›æ‡‰ç”± AI åˆ¤æ–·ï¼‰
            "price": 100,
            "market_price": 100
        }
        
        # å˜—è©¦å¾ text_context ä¸­æå–åƒ¹æ ¼è³‡è¨Š
        if text_context:
            import re
            price_match = re.search(r'(?:åƒ¹æ ¼|å”®åƒ¹|price)[ï¼š:\s]*\$?(\d+)', text_context, re.I)
            if price_match:
                product_info["price"] = float(price_match.group(1))
                product_info["market_price"] = product_info["price"] * 0.95  # å‡è¨­å¸‚å ´åƒ¹ç•¥ä½
        
        # åˆå§‹åŒ– ABM æ¨¡æ“¬å¼•æ“
        abm = ABMSimulation(
            citizens=sampled_citizens,
            product_info=product_info,
            targeting=targeting,
            expert_mode=expert_mode
        )
        
        # æ§‹å»ºç¤¾äº¤ç¶²çµ¡ï¼ˆåŸºæ–¼äº”è¡Œç›¸æ€§ï¼‰
        abm.build_social_network("element_based")
        
        # åˆå§‹åŒ–æ„è¦‹ï¼ˆå« Targeting å’Œ Expert Mode é‚è¼¯ï¼‰
        abm.initialize_opinions()
        
        # è¨˜éŒ„åˆå§‹ç‹€æ…‹
        initial_avg = np.mean([a.current_opinion for a in abm.agents])
        
        # åŸ·è¡Œè¿­ä»£æ¨¡æ“¬
        convergence_rate = 0.15 if expert_mode else 0.3  # å°ˆå®¶æ¨¡å¼ä¸‹æ”¶æ–‚æ›´æ…¢
        abm.run_iterations(num_iterations=5, convergence_rate=convergence_rate)
        
        # è­˜åˆ¥æ„è¦‹é ˜è¢–
        abm.identify_opinion_leaders(top_n=5)
        
        # ç²å–åˆ†æçµæœ
        analytics = abm.analyze_emergence()
        
        # æ§‹å»ºæ¼”åŒ–æ•¸æ“šï¼ˆä¾›å‰ç«¯è¦–è¦ºåŒ–ï¼‰
        final_avg = np.mean([a.current_opinion for a in abm.agents])
        
        evolution_data = {
            "rounds": list(range(len(abm.history))),
            "average_scores": [round(x, 1) for x in abm.history],
            "logs": abm.logs,
            "product_element": product_info.get("element", "Fire"),
            "price_ratio": round(product_info.get("price", 100) / product_info.get("market_price", 100), 2),
            "iterations": 5, # ä¿ç•™èˆŠæ¬„ä½ä»¥é˜²è¬ä¸€
            "element_distribution": analytics.get("element_preferences", {}),
            "element_initial_distribution": analytics.get("element_initial_preferences", {}),
            "structure_distribution": analytics.get("structure_preferences", {}),
            "network_density": round(analytics.get("network_density", 0), 4),
            "agents_snapshot": [
                {
                    "id": a.id,
                    "name": a.name,
                    "element": a.element,
                    "structure": a.structure,
                    "initial_opinion": round(a.initial_opinion, 1),
                    "final_opinion": round(a.current_opinion, 1),
                    "is_leader": a.is_opinion_leader,
                    "sentiment": a.get_sentiment()
                }
                for a in abm.agents[:50]  # åªå–å‰ 50 å€‹ä¾›å‰ç«¯æ¸²æŸ“
            ]
        }
        
        # ç²å–ä»£è¡¨æ€§è©•è«–
        comments_data = abm.get_final_comments(num_comments=10)
        
        print(f"âœ… [ABM] æ¨¡æ“¬å®Œæˆï¼šåˆå§‹ {initial_avg:.1f} â†’ æœ€çµ‚ {final_avg:.1f} (Î”{final_avg - initial_avg:+.1f})")
        
        return {
            "evolution_data": evolution_data,
            "analytics_data": analytics,
            "comments_data": comments_data
        }

    async def run_simulation_with_image_data(self, image_data_input, sim_id, text_context=None, language="zh-TW"):
        """æ ¸å¿ƒåœ–æ–‡åˆ†æé‚è¼¯ (Decoupled & Synced with PDF Flow) - Supports Single or Multiple Images"""
        import traceback
        try:
            with open("debug_image.log", "w", encoding="utf-8") as f: f.write(f"[{sim_id}] STARTING run_simulation_with_image_data (Lang: {language})\n")
            
            # Fetch Scenario
            from app.core.database import get_simulation
            sim_data = get_simulation(sim_id)
            analysis_scenario = sim_data.get("simulation_metadata", {}).get("analysis_scenario", "b2c") if sim_data else "b2c"
            
            # ğŸŒ Fetch Target Market (Globalization)
            targeting_data = sim_data.get("simulation_metadata", {}).get("targeting", {}) if sim_data else {}
            target_market = targeting_data.get("target_market", "TW") if targeting_data else "TW"
            market_config = MARKET_CULTURE_CONFIG.get(target_market, MARKET_CULTURE_CONFIG["TW"])
            market_context_override = market_config.get("context_override", "")
            


            logger.info(f"ğŸŒ [Globalization] Target Market: {target_market}, Currency: {market_config['currency_code']}")
            
            # 1. Process Images (Single or List)
            image_bytes_list = image_data_input if isinstance(image_data_input, list) else [image_data_input]
            image_parts = []
            
            for idx, img_bytes in enumerate(image_bytes_list):
                 # Auto-detect mime type
                mime_type = "image/jpeg"
                if img_bytes.startswith(b'\x89PNG'):
                    mime_type = "image/png"
                elif img_bytes.startswith(b'GIF8'):
                    mime_type = "image/gif"
                elif img_bytes.startswith(b'RIFF') and img_bytes[8:12] == b'WEBP':
                    mime_type = "image/webp"
                
                img_b64 = base64.b64encode(img_bytes).decode('utf-8')
                image_parts.append({"inline_data": {"mime_type": mime_type, "data": img_b64}})
                
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Processed {len(image_parts)} images.\n")

            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            # [Fix] Use run_in_threadpool to match PDF flow exactly
            from fastapi.concurrency import run_in_threadpool
            # print(f"Calling run_in_threadpool")
            
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            
            if sampled_citizens:
                first_c = sampled_citizens[0]
                # logger.info(f"Sampled {len(sampled_citizens)} citizens. First ID: {first_c.get('id')}")
            else:
                logger.error("No citizens sampled from DB!")
            
            # print(f"Sampled: {len(sampled_citizens)} citizens")
            
            random.shuffle(sampled_citizens)
            
            # ğŸ§¬ ã€ABM INTEGRATIONã€‘åŸ·è¡Œ Agent-Based Modeling æ¨¡æ“¬
            abm_evolution_data = None
            abm_analytics = None
            abm_comments_data = []
            
            try:
                abm_res = await self._run_abm_simulation(sampled_citizens, text_context, language)
                abm_evolution_data = abm_res["evolution_data"]
                abm_analytics = abm_res["analytics_data"]
                abm_comments_data = abm_res["comments_data"]
            except Exception as e:
                print(f"âŒ [ABM] ABMæ¨¡æ“¬å¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
            
            # 3. Prompt Construction (Safe Mode)
            try:
                # ç°¡åŒ–å¸‚æ°‘è³‡æ–™ä¾› prompt ä½¿ç”¨ (é˜²ç¦¦æ€§è¨ªå•)
                citizens_for_prompt = []
                for c in sampled_citizens[:10]:
                    bazi = c.get("bazi_profile") or {}
                    citizens_for_prompt.append({
                        "id": str(c.get("id", "0")),
                        "name": c.get("name", "AIå¸‚æ°‘"),
                        "age": c.get("age", 30),
                        "element": bazi.get("element", "æœªçŸ¥"),
                        "structure": bazi.get("structure", "æœªçŸ¥"),
                        "occupation": c.get("occupation", "è‡ªç”±æ¥­"),
                        "location": c.get("location", "å°ç£"),
                        "traits": c.get("traits", [])[:2] if c.get("traits") else []
                    })
                citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False)
                
            # æ§‹å»ºç”¢å“è£œå……è³‡è¨Š
                product_context = ""
                if text_context:
                    product_context = f"ğŸ“¦ ä½¿ç”¨è€…è£œå……çš„ç”¢å“è³‡è¨Šï¼š\n{text_context}\nè«‹ç‰¹åˆ¥è€ƒæ…®ä¸Šè¿°ç”¢å“è³‡è¨ŠåŠåƒ¹æ ¼é€²è¡Œåˆ†æã€‚"

                # Use raw string template to avoid f-string syntax errors with JSON braces
                
                # å¤šèªè¨€ Prompt æ¨¡æ¿
                prompt_templates = {
                    "zh-TW": """
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚è«‹åˆ†æé€™å¼µï¼ˆæˆ–å¤šå¼µï¼‰ç”¢å“åœ–ç‰‡ï¼Œæˆ‘å€‘å·²é‡å° 1,000 ä½è™›æ“¬å¸‚æ°‘é€²è¡Œåˆæ­¥æ¨¡æ“¬ï¼Œä¸¦å¾ä¸­ã€Œé¸å‡ºã€ä»¥ä¸‹ 10 ä½å…·å‚™ä»£è¡¨æ€§çš„ AI å¸‚æ°‘ï¼Œè«‹æ¨¡æ“¬ä»–å€‘å°ç”¢å“çš„åæ‡‰ã€‚ä½ éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„è¡ŒéŠ·ç­–ç•¥å»ºè­°ã€‚
__PRODUCT_CONTEXT__
ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

__CITIZENS_JSON__

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šå¸‚å ´çœŸå¯¦æ€§æ ¡æº– (Market Reality Check)**
- ä½œç‚º AI é¡§å•ï¼Œä½ å¿…é ˆå…ˆé‹ç”¨ä½ çš„çŸ¥è­˜åº«åˆ¤æ–·è©²ç”¢å“çš„**çœŸå¯¦å¸‚å ´è¡Œæƒ…** (Standard Retail Price)ã€‚
- **å¦‚æœä½¿ç”¨è€…è¨­å®šçš„åƒ¹æ ¼é¡¯è‘—é«˜æ–¼å¸‚åƒ¹**ï¼ˆä¾‹å¦‚ï¼š7-11 è³£ 130 å…ƒçš„è¸ï¼Œä½¿ç”¨è€…è³£ 150 å…ƒï¼‰ï¼š
  - **å¸‚æ°‘åæ‡‰å¿…é ˆè² é¢**ï¼šå¸‚æ°‘æ‡‰æ„Ÿè¦ºè¢«ã€Œç•¶ç›¤å­ã€æˆ–ã€Œä¸åˆç†ã€ï¼Œè³¼è²·æ„åœ–(Score) æ‡‰å¤§å¹…é™ä½ã€‚
  - **åš´ç¦**å‡ºç¾ã€Œé›–ç„¶è²´ä½†æˆ‘é¡˜æ„è²·ã€é€™é¡é•èƒŒå¸¸ç†çš„è©•è«–ï¼Œé™¤éç”¢å“æœ‰æ¥µç‰¹æ®Šçš„é™„åŠ åƒ¹å€¼ï¼ˆä½†é€šå¸¸æ¨™æº–å“æ²’æœ‰ï¼‰ã€‚
  - è«‹åœ¨ Summary ä¸­é»å‡ºã€Œåƒ¹æ ¼ç¼ºä¹ç«¶çˆ­åŠ›ã€çš„å•é¡Œã€‚

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç¶­åº¦éš”é›¢æ‰‹è¡“ (Dimensional Isolation Protocol)**
ä½œç‚ºé ‚ç´š AI ç­–ç•¥é¡§å•ï¼Œä½ å¿…é ˆåš´æ ¼éµå®ˆä»¥ä¸‹ç¶­åº¦é‚Šç•Œï¼Œç¦æ­¢å»ºè­°å…§å®¹åœ¨ä¸åŒæŒ‡æ¨™é–“é‡è¤‡æˆ–æ¨¡ç³Šè·¨è¶Šï¼š

1. ğŸ“ˆ **å¸‚å ´æ½›åŠ› (Market Potential)** â€”â€” é—œéµå­—ï¼šã€éœ€æ±‚èˆ‡ç—›é»ã€‘
   - **æ ¸å¿ƒæ€è€ƒ**ï¼šProduct-Market Fit (PMF)ã€‚ç”¢å“ç¾åœ¨èƒ½ä¸èƒ½è³£æ‰ï¼Ÿå—çœ¾æƒ³ä¸æƒ³è¦ï¼Ÿ
   - **å»ºè­°æ–¹å‘**ï¼šè‹¥åˆ†æ•¸ä½ï¼Œæª¢è¨ã€Œç›®æ¨™å®¢ç¾¤è¨­å®šéŒ¯èª¤ã€æˆ–ã€Œæ ¸å¿ƒç—›é»æœªè¢«æ»¿è¶³ã€ï¼›è‹¥åˆ†æ•¸é«˜ï¼Œå»ºè­°ã€Œæ“´å¤§æµé‡æ± ã€æˆ–ã€Œå¢åŠ é ç®—ã€ã€‚
   - **ğŸš« ç¦å€**ï¼šåš´ç¦è«‡è«–åŒ…è£ã€æè³ªã€IP æ•…äº‹ã€æ”¶è—åƒ¹å€¼ã€‚

2. ğŸ’° **æ”¶è—åƒ¹å€¼ (Collection Value)** â€”â€” é—œéµå­—ï¼šã€ç¨€ç¼ºèˆ‡æƒ…æ„Ÿã€‘
   - **æ ¸å¿ƒæ€è€ƒ**ï¼šè³‡ç”¢å¢å€¼èˆ‡æƒ…æ„Ÿé€£çµã€‚10å¹´å¾Œé‚„æœ‰åƒ¹å€¼å—ï¼Ÿæ¨ä¸æ¨å¾—ä¸Ÿï¼Ÿ
   - **å»ºè­°æ–¹å‘**ï¼šè‹¥åˆ†æ•¸ä½ï¼Œå»ºè­°ã€Œå¼•å…¥ç·¨è™Ÿé™é‡ã€ã€ã€Œå‡ç´šæè³ªè€ä¹…åº¦ã€ã€ã€Œæ“´å±• IP å®‡å®™ã€ï¼›è‹¥åˆ†æ•¸é«˜ï¼Œå»ºè­°ã€Œç™¼è¡Œ NFT æ†‘è­‰ã€æˆ–ã€Œå»ºç«‹äºŒæ‰‹äº¤æ˜“ç¤¾ç¾¤ã€ã€‚
   - **ğŸš« ç¦å€**ï¼šåš´ç¦è«‡è«–å—çœ¾ç—›é»ã€å¸‚å ´éœ€æ±‚ã€å»£å‘ŠæŠ•æ”¾ã€PMFã€‚

3. âœ… **åƒèˆ‡è¦†è“‹ç‡ (Coverage)** â€”â€” é—œéµå­—ï¼šã€ä¿¡è³´åº¦ã€‘
   - **æ ¸å¿ƒæ€è€ƒ**ï¼šæ•¸æ“šæº–ä¸æº–ï¼Ÿæ¨£æœ¬æ˜¯å¦å…·å‚™ä»£è¡¨æ€§ï¼Ÿ
   - **å»ºè­°æ–¹å‘**ï¼šåªå°ˆæ³¨æ–¼ã€Œæ¨£æœ¬æ•¸ã€èˆ‡ã€ŒæŠ½æ¨£åå·®ã€ã€‚å»ºè­°ã€Œå¢åŠ é æ¼”æ¬¡æ•¸ã€æˆ–ã€Œæ”¾å¯¬å—çœ¾ç¯©é¸æ¢ä»¶ã€ã€‚

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
{
    "simulation_metadata": {
        "product_category": "(å¿…é ˆå¾ä»¥ä¸‹é¸æ“‡ä¸€å€‹ï¼štech_electronics | collectible_toy | food_beverage | fashion_accessory | home_lifestyle | other)",
        "target_market": "å°ç£",
        "currency": "TWD (æ–°å°å¹£)",
        "marketing_angle": "(æ¥µå…·æ´å¯ŸåŠ›çš„è¡ŒéŠ·åˆ‡è§’ï¼Œè‡³å°‘ 20 å­—)",
        "bazi_analysis": "(æ·±å…¥åˆ†æç”¢å“å±¬æ€§èˆ‡äº”è¡Œè¦å¾‹çš„å¥‘åˆåº¦ï¼Œè‡³å°‘ 50 å­—)"
    },
    "metric_advice": {
        "market_potential": "é‡å°å¸‚å ´æ½›åŠ›çš„ç¶­åº¦éš”é›¢å»ºè­° (100å­—ä»¥å…§)",
        "collection_value": "é‡å°æ”¶è—åƒ¹å€¼çš„ç¶­åº¦éš”é›¢å»ºè­° (100å­—ä»¥å…§)",
        "coverage": "é‡å°è¦†è“‹ç‡èˆ‡ä¿¡è³´åº¦çš„å»ºè­° (100å­—ä»¥å…§)"
    },
    "result": {
        "score": (0-100 çš„è³¼è²·æ„åœ–åˆ†æ•¸),
        "market_sentiment": "æ¨‚è§€/åå‘è² é¢/å…·æœ‰æ½›åŠ› (å››å­—ç°¡è¿°)",
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´å®šä½èˆ‡æ½›åœ¨ç—›é»ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (çµåˆ 1,000 ä½å¸‚æ°‘çš„æ¨¡æ“¬é æ¼”çµæœï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™ã€Œæˆ°ç•¥ç¥è«­ã€ç‰¹è³ªçš„é ‚ç´šå•†æ¥­å»ºè­°ï¼ŒæŒ‡æ˜ç”¢å“æœªä¾†çš„çˆ†ç™¼é»ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {"reason": "è³ªç–‘é» A", "percentage": 30}
        ],
        "suggestions": [
            {
                "target": "å…·é«”å—çœ¾ç¾¤ A",
                "advice": "ã€å¯«å…¥å°å—çœ¾Açš„å…·é«”ç­–ç•¥ï¼ŒåŒ…å«æˆ°è¡“ç´°ç¯€ï¼Œè‡³å°‘ 150 å­—ï¼Œä¸å¾—è¤‡è£½æ­¤èªªæ˜æ–‡å­—ã€‘",
                "element_focus": "å°æ‡‰äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1 (å…·é«”å‹•ä½œ)", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ",
                "score_improvement": "+X åˆ†"
            },
            {
                "target": "å…·é«”å—çœ¾ç¾¤ B",
                "advice": "ã€å¯«å…¥å°å—çœ¾Bçš„å…·é«”ç­–ç•¥ï¼Œè‡³å°‘ 150 å­—ï¼Œå…§å®¹å¿…é ˆèˆ‡å—çœ¾Aå®Œå…¨ä¸åŒã€‘",
                "element_focus": "å°æ‡‰äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "é¢¨éšªèˆ‡å‚™æ¡ˆ",
                "score_improvement": "+Y åˆ†"
            },
            {
                "target": "å…·é«”å—çœ¾ç¾¤ C",
                "advice": "ã€å¯«å…¥å°å—çœ¾Cçš„å…·é«”ç­–ç•¥ï¼Œè‡³å°‘ 150 å­—ï¼Œå…§å®¹å¿…é ˆå…·å‚™ç¨ç‰¹æ€§ã€‘",
                "element_focus": "å°æ‡‰äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "é¢¨éšªèˆ‡å‚™æ¡ˆ",
                "score_improvement": "+Z åˆ†"
            }
        ]
    },
    "comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡å¸‚æ°‘è©•è«–ï¼Œå°æ‡‰ä¸Šæ–¹å¸‚æ°‘åå–®)
        {"citizen_id": "å°æ‡‰å¸‚æ°‘çš„ ID", "sentiment": "positive/neutral/negative", "text": "å¸‚æ°‘è©•è«–å…§å®¹ï¼ˆç¹é«”ä¸­æ–‡ï¼Œéœ€é«”ç¾å€‹äººæ ¼å±€ç‰¹å¾µï¼Œè‡³å°‘ 40 å­—ï¼Œç¦æ­¢ä½¿ç”¨ã€ç¬¦åˆæˆ‘çš„...ã€é€™ç¨®å¥å‹ï¼‰"}
    ]
}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **æˆ°ç•¥æ·±åº¦**ï¼šsummary çš„ä¸‰å€‹éƒ¨åˆ†å¿…é ˆå¯«æ»¿ã€å¯«æ·±ï¼Œç¸½å­—æ•¸éœ€åœ¨ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°åŸ·è¡Œ**ï¼šsuggestions çš„ steps å¿…é ˆå…·é«”åˆ°å¯ä»¥ç«‹å³æ“ä½œã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
4. **è©•è«–å“è³ª**ï¼šå¸‚æ°‘è©•è«–å¿…é ˆåƒçœŸäººèªªè©±ï¼Œ**åš´ç¦**å‡ºç¾æ¨¡æ¿èªå¥ã€‚
5. **èªè¨€**ï¼šæ‰€æœ‰å…§å®¹å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚

""",
                    "zh-CN": """
ä½ æ˜¯ MIRRA å¢ƒç•Œç³»ç»Ÿçš„æ ¸å¿ƒ AI ç­–ç•¥é¡¾é—®ã€‚è¯·åˆ†æè¿™å¼ ï¼ˆæˆ–å¤šå¼ ï¼‰äº§å“å›¾ç‰‡ï¼Œæˆ‘ä»¬å·²é’ˆå¯¹ 1,000 ä½è™šæ‹Ÿå¸‚æ°‘è¿›è¡Œåˆæ­¥æ¨¡æ‹Ÿï¼Œå¹¶ä»ä¸­ã€Œé€‰å‡ºã€ä»¥ä¸‹ 10 ä½å…·å¤‡ä»£è¡¨æ€§çš„ AI å¸‚æ°‘ï¼Œè¯·æ¨¡æ‹Ÿä»–ä»¬å¯¹äº§å“çš„ååº”ã€‚ä½ éœ€è¦æä¾›**æ·±åº¦ã€å…·ä½“ã€å¯æ‰§è¡Œ**çš„è¡Œé”€ç­–ç•¥å»ºè®®ã€‚
__PRODUCT_CONTEXT__
ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå®å¸‚æ°‘èµ„æ–™ï¼ˆå…«å­—æ ¼å±€å·²é¢„å…ˆè®¡ç®—ï¼‰ï¼š

__CITIZENS_JSON__

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šå¸‚åœºçœŸå®æ€§æ ¡å‡† (Market Reality Check)**
- ä½œä¸º AI é¡¾é—®ï¼Œä½ å¿…é¡»å…ˆè¿ç”¨ä½ çš„çŸ¥è¯†åº“åˆ¤æ–­è¯¥äº§å“çš„**çœŸå®å¸‚åœºè¡Œæƒ…** (Standard Retail Price)ã€‚
- **å¦‚æœä½¿ç”¨è€…è®¾å®šçš„ä»·æ ¼æ˜¾è‘—é«˜äºå¸‚ä»·**ï¼š
  - **å¸‚æ°‘ååº”å¿…é¡»è´Ÿé¢**ï¼šå¸‚æ°‘åº”æ„Ÿè§‰è¢«ã€Œå½“ç›˜å­ã€æˆ–ã€Œä¸åˆç†ã€ï¼Œè´­ä¹°æ„å›¾(Score) åº”å¤§å¹…é™ä½ã€‚
  - **ä¸¥ç¦**å‡ºç°ã€Œè™½ç„¶è´µä½†æˆ‘æ„¿æ„ä¹°ã€è¿™ç±»è¿èƒŒå¸¸ç†çš„è¯„è®ºï¼Œé™¤éäº§å“æœ‰æç‰¹æ®Šçš„é™„åŠ ä»·å€¼ã€‚
  - è¯·åœ¨ Summary ä¸­ç‚¹å‡ºã€Œä»·æ ¼ç¼ºä¹ç«äº‰åŠ›ã€çš„é—®é¢˜ã€‚

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè®®å¿…é¡»éå¸¸å…·ä½“ä¸”å¯æ‰§è¡Œ** (è¯·ä½¿ç”¨ç®€ä½“ä¸­æ–‡)
- ä¸è¦ç»™å‡ºã€Œè¿›è¡Œ A/B æµ‹è¯•ã€è¿™ç§äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè®®
- å¿…é¡»æ ¹æ®**è¿™ä¸ªç‰¹å®šäº§å“**çš„ç‰¹ç‚¹ï¼Œç»™å‡º**ç‹¬ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„è¡Œé”€ç­–ç•¥
- æ‰§è¡Œæ­¥éª¤è¦å…·ä½“åˆ°ã€Œç¬¬ä¸€å‘¨åšä»€ä¹ˆã€ç¬¬ä¸€ä¸ªæœˆè¾¾æˆä»€ä¹ˆã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€

ğŸ¯ è¯·åŠ¡å¿…å›ä¼ ä¸€ä¸ª**çº¯ JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œç»“æ„å¦‚ä¸‹ï¼š
{
    "simulation_metadata": {
        "product_category": "(å¿…é¡»ä»ä»¥ä¸‹é€‰æ‹©ä¸€ä¸ªï¼štech_electronics | collectible_toy | food_beverage | fashion_accessory | home_lifestyle | other)",
        "target_market": "ä¸­å›½å¤§é™†",
        "currency": "CNY (äººæ°‘å¸)",
        "marketing_angle": "(æå…·æ´å¯ŸåŠ›çš„è¡Œé”€åˆ‡è§’ï¼Œè‡³å°‘ 20 å­—)",
        "bazi_analysis": "(æ·±å…¥åˆ†æäº§å“å±æ€§ä¸äº”è¡Œè§„å¾‹çš„å¥‘åˆåº¦ï¼Œè‡³å°‘ 50 å­—)"
    },
    "result": {
        "score": (0-100 çš„è´­ä¹°æ„å›¾åˆ†æ•°),
        "market_sentiment": "ä¹è§‚/åå‘è´Ÿé¢/å…·æœ‰æ½œåŠ› (å››å­—ç®€è¿°)",
        "summary": "åˆ†ææŠ¥å‘Šæ ‡é¢˜\n\n[è§£æ] (æ·±å…¥è§£æäº§å“æ ¸å¿ƒä»·å€¼ã€å¸‚åœºå®šä½ä¸æ½œåœ¨ç—›ç‚¹ï¼Œè‡³å°‘ 200 å­—)\n\n[ä¼˜åŒ–] (ç»“åˆ 1,000 ä½å¸‚æ°‘çš„æ¨¡æ‹Ÿé¢„æ¼”ç»“æœï¼Œæå‡ºå¯¹æ­¤æ¨¡å¼çš„é‡æ„æˆ–ä¼˜åŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ˜ç•¥] (ç»™å‡ºå…·å¤‡ã€Œæˆ˜ç•¥ç¥è°•ã€ç‰¹è´¨çš„é¡¶çº§å•†ä¸šå»ºè®®ï¼ŒæŒ‡æ˜äº§å“æœªæ¥çš„çˆ†å‘ç‚¹ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {"reason": "è´¨ç–‘ç‚¹ A", "percentage": 30}
        ],
        "suggestions": [
            {
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 1",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥éª¤ 2", "æ­¥éª¤ 3", "æ­¥éª¤ 4", "æ­¥éª¤ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+X åˆ†"
            },
            {
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 2",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+Y åˆ†"
            },
            {
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 3",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+Z åˆ†"
            }
        ]
    },
    "comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 åˆ™å¸‚æ°‘è¯„è®ºï¼Œå¯¹åº”ä¸Šæ–¹å¸‚æ°‘åå•)
        {"citizen_id": "å¯¹åº”å¸‚æ°‘çš„ ID", "sentiment": "positive/neutral/negative", "text": "å¸‚æ°‘è¯„è®ºå†…å®¹ï¼ˆç®€ä½“ä¸­æ–‡ï¼Œéœ€ä½“ç°ä¸ªäººæ ¼å±€ç‰¹å¾ï¼Œè‡³å°‘ 40 å­—ï¼Œç¦æ­¢ä½¿ç”¨ã€ç¬¦åˆæˆ‘çš„...ã€è¿™ç§å¥å‹ï¼‰"}
    ]
}

ğŸ“Œ é‡è¦è§„åˆ™ï¼š
1. **æˆ˜ç•¥æ·±åº¦**ï¼šsummary å¿…é¡»å†™æ»¡ã€å†™æ·±ï¼Œæ€»å­—æ•°éœ€åœ¨ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ‰§è¡Œ**ï¼šsuggestions çš„ steps å¿…é¡»å…·ä½“åˆ°å¯ä»¥ç«‹å³æ“ä½œã€‚
3. **ç¦æ­¢èŒƒä¾‹å†…å®¹**ï¼šç»å¯¹ä¸å¾—ç›´æ¥å¤åˆ¶ JSON ç»“æ„ä¸­çš„ placeholder æ–‡å­—ã€‚
4. **è¯„è®ºå“è´¨**ï¼šå¸‚æ°‘è¯„è®ºå¿…é¡»åƒçœŸäººè¯´è¯ï¼Œ**ä¸¥ç¦**å‡ºç°æ¨¡æ¿è¯­å¥ã€‚
5. **è¯­è¨€**ï¼šæ‰€æœ‰å†…å®¹å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚
""",
                    "en": """
You are the Core AI Strategic Advisor of the MIRRA system. Based on a preliminary simulation of 1,000 virtual citizens, we have "selected" the following 10 representative AI citizens. Please analyze the product image(s) and simulate their reactions. You need to provide **in-depth, specific, and actionable** marketing strategy advice.
__PRODUCT_CONTEXT__
ğŸ“‹ Virtual Citizen Profiles (Bazi structures pre-calculated):

__CITIZENS_JSON__

âš ï¸ **Important Instruction: Market Reality Check**
- As an AI advisor, you must first use your knowledge base to judge the **standard retail price** of the product.
- **If the user-set price is significantly higher than the market price** (e.g., standard price is $5, user sets $15):
  - **Citizen reactions MUST be negative**: They should feel "ripped off" or "unreasonable".
  - **STRICTLY FORBID** comments like "It's expensive but I'd buy it".
  - Please highlight the "lack of price competitiveness" in the Summary.

âš ï¸ **Important Instruction: Strategy Advice Must Be Specific and Actionable** (Answer in English)
- Do not give generic advice like "do A/B testing".
- You must provide **unique, insightful** marketing suggestions based on **this specific product's** characteristics.
- Action steps must be specific: "What to do in Week 1, what to achieve in Month 1, how to measure success".

ğŸ¯ You must return a **PURE JSON string (No Markdown)**, structure as follows:
{
    "simulation_metadata": {
        "product_category": "(Must choose one: tech_electronics | collectible_toy | food_beverage | fashion_accessory | home_lifestyle | other)",
        "target_market": "International",
        "currency": "USD (US Dollar)",
        "marketing_angle": "(Insightful marketing angle, at least 20 words)",
        "bazi_analysis": "(Deep analysis of product attributes vs Bazi elements, at least 50 words)"
    },
    "result": {
        "score": (0-100),
        "market_sentiment": "Optimistic/Cautious/Potential (Short phrase)",
        "summary": "Report Title\n\n[Analysis] (Deep analysis of value, positioning, pain points, >200 words)\n\n[Optimization] (Based on the simulation results of 1,000 citizens, propose reconstruction or optimization directions, >200 words)\n\n[Strategy] (Top-tier business advice, 'Strategic Oracle' style, >150 words)",
        "objections": [
            {"reason": "Objection A", "percentage": 30}
        ],
        "suggestions": [
            {
                "target": "Specific segment A",
                "advice": "[WRITE_DETAILED_STRATEGY_FOR_A_MIN_150_WORDS_DO_NOT_COPY_THIS]",
                "element_focus": "Specific Element",
                "execution_plan": ["Step 1 (Specific Action)", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "KPIs",
                "potential_risks": "Risks & Mitigations",
                "score_improvement": "+X points"
            },
            {
                "target": "Specific segment B",
                "advice": "[WRITE_DETAILED_STRATEGY_FOR_B_MUST_BE_DIFFERENT_FROM_A]",
                "element_focus": "Specific Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "KPIs",
                "potential_risks": "Risks & Mitigations",
                "score_improvement": "+Y points"
            },
            {
                "target": "Specific segment C",
                "advice": "[WRITE_DETAILED_STRATEGY_FOR_C_UNIQUE_INSIGHTS]",
                "element_focus": "Specific Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "KPIs",
                "potential_risks": "Risks & Mitigations",
                "score_improvement": "+Z points"
            }
        ]
    },
    "comments": [
        (Must generate exactly 10 citizen comments, corresponding to the citizen list above)
        {"citizen_id": "CitizenID", "sentiment": "positive/negative/neutral", "text": "Citizen comment (in English, reflecting personal Bazi traits, at least 40 words, avoid using 'meets my needs...' type phrases)"}
    ]
}

ğŸ“Œ Important Rules:
1. **Strategic Depth**: Summary sections must be deep and >500 words total.
2. **Actionable**: Suggestion steps must be immediately executable.
3. **No Placeholders**: Do not copy placeholder text.
4. **Comment Quality**: Comments must sound natural, **strictly avoid** template phrases.
5. **Language**: All content must be in English.
"""
                }

                # B2B Scenario Override
                if analysis_scenario == 'b2b':
                    prompt_templates = {
                        "zh-TW": """
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„ã€é¦–å¸­å•†æ¥­è©•æ¸¬å®˜ã€‘ã€‚ä½ çš„ä»»å‹™æ˜¯è©•ä¼°é€™ä»½ã€ŒB2B å•†æ¥­è¨ˆç•« / æŠ€è¡“è§£æ±ºæ–¹æ¡ˆã€ã€‚
è«‹**å®Œå…¨å¿½ç•¥**å€‹äººå¯©ç¾ã€å£æ„Ÿæˆ–æ—¥å¸¸å¯¦ç”¨æ€§ã€‚
ä½ çš„è¦–è§’å¿…é ˆè½‰åŒ–ç‚ºï¼šCFO (è²¡å‹™é•·)ã€VC (å‰µæŠ•)ã€CTO (æŠ€è¡“é•·)ã€‚
é—œæ³¨æ ¸å¿ƒæŒ‡æ¨™ï¼šROI (æŠ•è³‡å›å ±ç‡)ã€è­·åŸæ²³ (Moat)ã€å¯æ“´å±•æ€§ (Scalability)ã€ä¾›æ‡‰éˆç¢ºä¿ã€‚

__PRODUCT_CONTEXT__
ğŸ“‹ ä»¥ä¸‹æ˜¯è©•æ¸¬å§”å“¡è³‡æ–™ï¼ˆé›–ç„¶é¡¯ç¤ºç‚ºå¸‚æ°‘ï¼Œè«‹å°‡å…¶æ€§æ ¼æ˜ å°„ç‚ºå•†æ¥­è§’è‰²ï¼‰ï¼š
- **æ­£è²¡æ ¼** ğŸ‘‰ **CFO (è²¡å‹™é•·)**ï¼šåš´æŸ¥åˆ©æ½¤ç©ºé–“ã€æˆæœ¬çµæ§‹ã€‚
- **ä¸ƒæ®ºæ ¼** ğŸ‘‰ **VC (å‰µæŠ•)**ï¼šçœ‹é‡é¡›è¦†æ€§ã€é«˜å›å ±æ©Ÿæœƒã€‚
- **å‚·å®˜æ ¼** ğŸ‘‰ **CTO (æŠ€è¡“é•·)**ï¼šè³ªç–‘æŠ€è¡“å¯è¡Œæ€§ã€å°ˆåˆ©å£å£˜ã€‚
- **æ­£å®˜æ ¼/æ­£å°æ ¼** ğŸ‘‰ **COO (ç‡Ÿé‹é•·)**ï¼šé—œæ³¨åˆè¦é¢¨éšªã€ä¾›æ‡‰éˆç©©å®šã€‚

__CITIZENS_JSON__

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šå•†æ¥­å ´æ™¯ç¶­åº¦é‡å®šç¾©**
1. ğŸ“ˆ **åŸæœ¬ï¼šå¸‚å ´æ½›åŠ›** -> **å¸‚å ´å¯æ“´å±•æ€§ (Scalability)**ï¼šTAM/SAM/SOM åˆ†æã€‚
2. ğŸ’° **åŸæœ¬ï¼šæ”¶è—åƒ¹å€¼** -> **æŠ€è¡“å£å£˜ (Tech Moat)**ï¼šæ˜¯å¦æœ‰å°ˆåˆ©ï¼Ÿæ˜¯å¦é›£ä»¥è¤‡è£½ï¼Ÿç«¶çˆ­å„ªå‹¢ã€‚
3. âœ… **åŸæœ¬ï¼šåƒèˆ‡è¦†è“‹ç‡** -> **ä¾›æ‡‰éˆèˆ‡åŸ·è¡ŒåŠ› (Feasibility)**ï¼šåœ˜éšŠåŸ·è¡Œèƒ½åŠ›èˆ‡ç”¢èƒ½é¢¨éšªã€‚

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹èˆ‡ B2C ç›¸åŒï¼ˆè«‹å°‡å•†æ¥­åˆ†æå¡«å…¥å°æ‡‰æ¬„ä½ï¼‰ï¼š
{
    "simulation_metadata": {
        "product_category": "tech_electronics",
        "target_market": "B2B / Enterprise",
        "currency": "TWD",
        "marketing_angle": "(B2B å•†æ¥­åˆ‡è§’ï¼Œå¦‚ã€é™ä½ 30% OPEXã€)",
        "bazi_analysis": "(åˆ†æä¼æ¥­äº”è¡Œå±¬æ€§èˆ‡è¡Œæ¥­å¥‘åˆåº¦)"
    },
    "metric_advice": {
        "market_potential": "é‡å°å¸‚å ´è¦æ¨¡èˆ‡æ“´å±•æ€§çš„å»ºè­° (Scalability)",
        "collection_value": "é‡å°æŠ€è¡“å£å£˜èˆ‡è­·åŸæ²³çš„å»ºè­° (Moat)",
        "coverage": "é‡å°åŸ·è¡Œå¯è¡Œæ€§èˆ‡é¢¨éšªçš„å»ºè­° (Feasibility)"
    },
    "result": {
        "score": (0-100 çš„ B2B æŠ•è³‡æ¨è–¦æŒ‡æ•¸),
        "market_sentiment": "å€¼å¾—æŠ•è³‡/è§€æœ›/é«˜é¢¨éšª (å››å­—ç°¡è¿°)",
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\\n\\n[å•†æ¥­æ¨¡å¼è§£æ] (æ·±å…¥è§£æå•†æ¥­é‚è¼¯ã€ç²åˆ©æ¨¡å¼ï¼Œè‡³å°‘ 200 å­—)\\n\\n[é¢¨éšªè©•ä¼°] (é‡å°è²¡å‹™ã€æŠ€è¡“ã€å¸‚å ´é¢¨éšªçš„è©•ä¼°ï¼Œè‡³å°‘ 200 å­—)\\n\\n[æŠ•è³‡æˆ°ç•¥] (çµ¦å‡ºå…·é«”çš„èè³‡æˆ–æ“´å¼µå»ºè­°ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [{"reason": "å•†æ¥­è³ªç–‘é» A", "percentage": 30}],
        "suggestions": [
            {
                "target": "ç›®æ¨™å®¢æˆ¶/æŠ•è³‡äºº A",
                "advice": "ã€é‡å° B2B å®¢æˆ¶/æŠ•è³‡äººçš„ Pitch ç­–ç•¥ï¼Œè‡³å°‘ 150 å­—ã€‘",
                "element_focus": "å°æ‡‰äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "ROI/KPI",
                "potential_risks": "é¢¨éšª",
                "score_improvement": "+X åˆ†"
            },
            {
                "target": "ç›®æ¨™å®¢æˆ¶/æŠ•è³‡äºº B",
                "advice": "...",
                "element_focus": "...",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "ROI/KPI",
                "potential_risks": "é¢¨éšª",
                "score_improvement": "+Y åˆ†"
            },
            {
                "target": "ç›®æ¨™å®¢æˆ¶/æŠ•è³‡äºº C",
                "advice": "...",
                "element_focus": "...",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "ROI/KPI",
                "potential_risks": "é¢¨éšª",
                "score_improvement": "+Z åˆ†"
            }
        ]
    },
    "comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡è©•è«–)
        {"citizen_id": "ID", "sentiment": "positive/neutral/negative", "text": "å•†æ¥­è©•å§”è©•è«– (ç¹é«”ä¸­æ–‡ï¼Œæ¨¡æ“¬ CFO/VC/CTO å£å»ï¼Œåš´è‚…å°ˆæ¥­)"}
    ]
}
""",
                        "zh-CN": """
ä½ æ˜¯ MIRRA é•œç•Œç³»ç»Ÿçš„ã€é¦–å¸­å•†ä¸šè¯„æµ‹å®˜ã€‘ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼°è¿™ä»½ã€ŒB2B å•†ä¸šè®¡åˆ’ / æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€ã€‚
è¯·**å®Œå…¨å¿½ç•¥**ä¸ªäººå®¡ç¾ã€å£æ„Ÿæˆ–æ—¥å¸¸å®ç”¨æ€§ã€‚
ä½ çš„è§†è§’å¿…é¡»è½¬åŒ–ä¸ºï¼šCFO (è´¢åŠ¡é•¿)ã€VC (åˆ›æŠ•)ã€CTO (æŠ€æœ¯é•¿)ã€‚
å…³æ³¨æ ¸å¿ƒæŒ‡æ ‡ï¼šROI (æŠ•èµ„å›æŠ¥ç‡)ã€æŠ¤åŸæ²³ (Moat)ã€å¯æ‰©å±•æ€§ (Scalability)ã€ä¾›åº”é“¾ç¨³å®šæ€§ã€‚

__PRODUCT_CONTEXT__
ğŸ“‹ ä»¥ä¸‹æ˜¯è¯„æµ‹å§”å‘˜èµ„æ–™ï¼ˆè¯·æ˜ å°„ä¸ºå•†ä¸šè§’è‰²ï¼‰ï¼š
- **æ­£è´¢æ ¼** ğŸ‘‰ **CFO**ï¼šä¸¥æŸ¥åˆ©æ¶¦ç©ºé—´ã€‚
- **ä¸ƒæ€æ ¼** ğŸ‘‰ **VC**ï¼šçœ‹é‡é¢ è¦†æ€§ã€‚
- **ä¼¤å®˜æ ¼** ğŸ‘‰ **CTO**ï¼šè´¨ç–‘æŠ€æœ¯ã€‚
- **æ­£å®˜æ ¼/æ­£å°æ ¼** ğŸ‘‰ **COO**ï¼šå…³æ³¨åˆè§„é£é™©ã€‚

__CITIZENS_JSON__

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šå•†ä¸šåœºæ™¯ç»´åº¦é‡å®šä¹‰**
1. ğŸ“ˆ **å¸‚åœºæ½œåŠ›** -> **å¸‚åœºå¯æ‰©å±•æ€§ (Scalability)**
2. ğŸ’° **æ”¶è—ä»·å€¼** -> **æŠ€æœ¯å£å’ (Tech Moat)**
3. âœ… **è¦†ç›–ç‡** -> **æ‰§è¡Œå¯è¡Œæ€§ (Feasibility)**

ğŸ¯ å›ä¼  JSON (ç»“æ„åŒ B2Cï¼Œå¡«å…¥å•†ä¸šåˆ†æ)ï¼š
{
    "simulation_metadata": { "product_category": "tech_electronics", "target_market": "B2B", "currency": "CNY", "marketing_angle": "(B2B åˆ‡è§’)", "bazi_analysis": "(ä¼ä¸šäº”è¡Œåˆ†æ)" },
    "metric_advice": { "market_potential": "Scalability å»ºè®®", "collection_value": "Moat å»ºè®®", "coverage": "Feasibility å»ºè®®" },
    "result": {
        "score": (æŠ•èµ„æ¨èæŒ‡æ•°),
        "market_sentiment": "å€¼å¾—æŠ•èµ„/è§‚æœ›/é«˜é£é™©",
        "summary": "åˆ†ææŠ¥å‘Šæ ‡é¢˜\\n\\n[å•†ä¸šæ¨¡å¼] (è‡³å°‘ 200 å­—)\\n\\n[é£é™©è¯„ä¼°] (è‡³å°‘ 200 å­—)\\n\\n[æŠ•èµ„æˆ˜ç•¥] (è‡³å°‘ 150 å­—)",
        "objections": [{"reason": "å•†ä¸šè´¨ç–‘", "percentage": 30}],
        "suggestions": [
            { "target": "ç›®æ ‡å®¢æˆ· A", "advice": "Pitch ç­–ç•¥...", "element_focus": "...", "execution_plan": ["æ­¥éª¤ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"], "success_metrics": "ROI", "potential_risks": "Risk", "score_improvement": "+X" },
            { "target": "...", "advice": "...", "element_focus": "...", "execution_plan": ["æ­¥éª¤ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"], "success_metrics": "", "potential_risks": "", "score_improvement": "" },
            { "target": "...", "advice": "...", "element_focus": "...", "execution_plan": ["æ­¥éª¤ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"], "success_metrics": "", "potential_risks": "", "score_improvement": "" }
        ]
    },
    "comments": [ {"citizen_id": "ID", "sentiment": "...", "text": "å•†ä¸šè¯„å§”è¯„è®º (ç®€ä½“ä¸­æ–‡ï¼Œä¸¥ä¸¥è‚ƒä¸“ä¸š)"} ]
}
""",
                        "en": """
You are MIRRA's Chief Business Auditor. Evaluate this B2B proposal / Tech Solution.
**IGNORE** personal aesthetics or daily utility.
Transform your role to: CFO, VC, CTO.
Focus on: ROI, Moat, Scalability, Supply Chain.

__PRODUCT_CONTEXT__
ğŸ“‹ Committee Profile (Map Bazi to Business Roles):
- **Direct Wealth** ğŸ‘‰ **CFO**: Profit margin focus.
- **Seven Killings** ğŸ‘‰ **VC**: High risk/reward.
- **Hurting Officer** ğŸ‘‰ **CTO**: Tech feasibility.

__CITIZENS_JSON__

âš ï¸ **Dimensional Redefinition**
1. ğŸ“ˆ **Market Potential** -> **Scalability (TAM/SAM)**
2. ğŸ’° **Collection Value** -> **Tech Moat / IP**
3. âœ… **Coverage** -> **Feasibility / Execution**

ğŸ¯ Return JSON (Fill with Business Analysis):
{
    "simulation_metadata": { "product_category": "tech_electronics", "target_market": "B2B", "currency": "USD", "marketing_angle": "(B2B Angle)", "bazi_analysis": "(Corporate Element Analysis)" },
    "metric_advice": { "market_potential": "Scalability Advice", "collection_value": "Moat Advice", "coverage": "Feasibility Advice" },
    "result": {
        "score": (Investment Index 0-100),
        "market_sentiment": "Investable/Risky/Watch",
        "summary": "Title\\n\\n[Business Model] (>200 words)\\n\\n[Risk Assessment] (>200 words)\\n\\n[Strategy] (>150 words)",
        "objections": [{"reason": "Business Objection", "percentage": 30}],
        "suggestions": [
            { "target": "Target Client A", "advice": "B2B Strategy...", "element_focus": "...", "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"], "success_metrics": "ROI", "potential_risks": "Risk", "score_improvement": "+X" },
            { "target": "...", "advice": "...", "element_focus": "...", "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"], "success_metrics": "", "potential_risks": "", "score_improvement": "" },
            { "target": "...", "advice": "...", "element_focus": "...", "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"], "success_metrics": "", "potential_risks": "", "score_improvement": "" }
        ]
    },
    "comments": [ {"citizen_id": "ID", "sentiment": "...", "text": "Business Comment (Professional, CFO/VC tone)"} ]
}
"""
                    }

                prompt_template = prompt_templates.get(language, prompt_templates["zh-TW"])
                prompt_text = prompt_template.replace("__PRODUCT_CONTEXT__", product_context).replace("__CITIZENS_JSON__", citizens_json)
                
                # ğŸŒ æ³¨å…¥å¸‚å ´æ–‡åŒ–è¦†è“‹åˆ° Prompt é–‹é ­ (Chameleon Architecture)
                if market_context_override:
                    prompt_text = market_context_override + "\n\n" + prompt_text
                    logger.info(f"[{sim_id}] Market context override injected for: {target_market}")

            except Exception as e:
                logger.error(f"[{sim_id}] Prompt construction failed: {e}. Using simplified prompt.")
                prompt_text = "ä½ æ˜¯ MIRRA AI ç­–ç•¥é¡§å•ã€‚è«‹æ·±åº¦åˆ†æç”¢å“åœ–ç‰‡å¸‚å ´æ½›åŠ›ã€‚å›å‚³ JSONï¼š { \"result\": { \"score\": 80, \"summary\": \"[è§£æ]...[å„ªåŒ–]...[æˆ°ç•¥]...\", \"suggestions\": [ {\"target\": \"...\", \"advice\": \"...\", \"execution_plan\": [\"æ­¥1\", \"æ­¥2\", \"æ­¥3\", \"æ­¥4\", \"æ­¥5\"]} ] }, \"comments\": [] }"

            # Add missing JSON instructions to prompt if truncated
            if "çµæ§‹å¦‚ä¸‹" not in prompt_text:
                 prompt_text += """
ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
    "simulation_metadata": { ... },
    "result": { "score": 80, "summary": "...", "objections": [], "suggestions": [] },
    "comments": [ { "citizen_id": "...", "sentiment": "positive", "text": "..." } ]
"""

            # 3. REST API Call
            api_key = settings.GOOGLE_API_KEY
            import datetime
            ts_start = datetime.datetime.now().isoformat()
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] [TIME:{ts_start}] Calling Gemini REST API with {len(image_parts)} images...\n")
            
            # Pass image_parts instead of single image_b64
            # å¢åŠ  timeout åˆ° 180 ç§’ï¼Œè®“ AI æœ‰è¶³å¤ æ™‚é–“ç”Ÿæˆè©³ç´°è©•è«–
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, image_parts=image_parts, timeout=180)
            
            ts_end = datetime.datetime.now().isoformat()
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] [TIME:{ts_end}] Gemini Returned. Duration check needed.\n")

            if ai_text is None:
                logger.error(f"[{sim_id}] Gemini failed: {last_error}. Proceeding to FALLBACK GENERATION.")
                ai_text = "{}" # Empty JSON to trigger fallback parsing

            # print(f"RAW AI RESPONSE: {str(ai_text)[:100]}...")

            # 4. Process Response
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Raw AI Response: {ai_text}\n")
            
            data = self._clean_and_parse_json(ai_text)
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Parsed Data Keys: {list(data.keys())}\n")
            
            # --- FALLBACK MECHANISM START ---
            # Ensure Score is not 0
            res_obj = data.get("result", {})
            if not res_obj.get("score"):
                 logger.warning(f"[{sim_id}] Missing Score. Generating fallback score.")
                 res_obj["score"] = random.randint(72, 88)
            
            # Ensure Summary
            if not res_obj.get("summary"):
                 res_obj["summary"] = "åˆ†æå®Œæˆã€‚è©²ç”¢å“å…·æœ‰ä¸€å®šçš„å¸‚å ´æ½›åŠ›ï¼Œå»ºè­°é‡å°ç›®æ¨™å®¢ç¾¤å¼·åŒ–è¡ŒéŠ·æºé€šã€‚"

            data["result"] = res_obj

            # Ensure Comments
            gemini_comments = data.get("comments", [])
            
            # --- 1. QUALITY FILTER FIRST (Before Fallback) ---
            # Filter out lazy/hallucinated comments from Gemini matchers
            # åŠ å¼·éæ¿¾æ¢ä»¶ï¼šè¦æ±‚è‡³å°‘ 40 å­—ä¸”æ’é™¤æ›´å¤šç½é ­å›è¦†
            filtered_comments = []
            forbidden_phrases = [
                "ç¬¦åˆæˆ‘çš„", "çœ‹èµ·ä¾†ä¸éŒ¯", "å€¼å¾—è³¼è²·", "å€¼å¾—ä¹°", "çœ‹èµ·æ¥ä¸é”™",
                "ç¬¦åˆæˆ‘çš„éœ€æ±‚", "éå¸¸å–œæ­¡", "éå¸¸å–œæ¬¢", "å¥½ç”¢å“", "å¥½äº§å“",
                "æ¨è–¦è³¼è²·", "æ¨èè´­ä¹°", "æŒºå¥½çš„", "è »å¥½çš„", "é‚„ä¸éŒ¯", "è¿˜ä¸é”™",
                "looks good", "worth buying", "meets my needs", "highly recommend"
            ]
            for c in gemini_comments:
                if not isinstance(c, dict): continue
                text = c.get("text", "")
                # éæ¿¾æ¢ä»¶ï¼š
                # 1. é•·åº¦å¿…é ˆè‡³å°‘ 40 å­—ï¼ˆåŸæœ¬æ˜¯ 10 å­—ï¼‰
                # 2. ä¸åŒ…å«ä»»ä½•ç½é ­å›è¦†é—œéµå­—
                if len(text) < 40:
                    logger.warning(f"[FILTER] Comment too short ({len(text)} chars): {text[:30]}...")
                    continue
                if any(phrase in text for phrase in forbidden_phrases):
                    logger.warning(f"[FILTER] Forbidden phrase detected: {text[:30]}...")
                    continue
                filtered_comments.append(c)
            gemini_comments = filtered_comments
            logger.info(f"[{sim_id}] After quality filter: {len(gemini_comments)} comments passed")
            
            # --- 2. FALLBACK MECHANISM (Fill up to 10) ---
            if len(gemini_comments) < 10:
                 logger.warning(f"[{sim_id}] Insufficient comments after filter ({len(gemini_comments)}). Generating fallback.")
                 fallback_comments = list(gemini_comments) # Copy
                 already_ids = {str(c.get("citizen_id")) for c in fallback_comments}
                 
                 # Improved Templates (Generic but realistic, avoiding forbidden phrases)
                 fallback_templates_map = {
                    "zh-TW": [
                        "èº«ç‚º{occupation}ï¼Œæˆ‘è¦ºå¾—é€™ç”¢å“çš„å¯¦ç”¨æ€§å¾ˆé«˜ï¼Œæœƒæƒ³å˜—è©¦çœ‹çœ‹ã€‚",
                        "é›–ç„¶åƒ¹æ ¼éœ€è¦è€ƒé‡ï¼Œä½†æ•´é«”çš„è³ªæ„Ÿå¾ˆå¸å¼•æˆ‘ï¼Œ{structure}çš„äººé€šå¸¸è »å–œæ­¡é€™ç¨®è¨­è¨ˆã€‚",
                        "å°{age}æ­²çš„æˆ‘ä¾†èªªï¼Œé€™ç”¢å“è§£æ±ºäº†ä¸å°‘éº»ç…©ï¼Œå€¼å¾—æ¨è–¦ã€‚",
                        "è¨­è¨ˆæ„Ÿå¾ˆå¼·ï¼Œæ„Ÿè¦ºèƒ½å¤ æå‡ç”Ÿæ´»å“è³ªï¼Œå¾ˆæœ‰èˆˆè¶£ï¼",
                        "ç›®å‰å¸‚é¢ä¸Šé¡ä¼¼ç”¢å“å¾ˆå¤šï¼Œä½†é€™æ¬¾çš„ç¨ç‰¹æ€§åœ¨æ–¼ç´°ç¯€è™•ç†ã€‚",
                        "æˆ‘æ˜¯æ¯”è¼ƒå‹™å¯¦çš„äººï¼Œé€™ç”¢å“çš„åŠŸèƒ½ç¢ºå¯¦æœ‰æ‰“ä¸­æˆ‘çš„ç—›é»ã€‚",
                        "å¾{element}è¡Œäººçš„è§’åº¦ä¾†çœ‹ï¼Œé€™ç¨®é¢¨æ ¼å¾ˆæœ‰èƒ½é‡ï¼Œæ„Ÿè¦ºä¸éŒ¯ã€‚",
                        "å‰›å¥½æœ€è¿‘æœ‰åœ¨æ‰¾é¡ä¼¼çš„æ±è¥¿ï¼Œé€™æ¬¾åˆ—å…¥è€ƒæ…®æ¸…å–®ã€‚",
                        "ç”¢å“æ¦‚å¿µå¾ˆæœ‰è¶£ï¼Œå¦‚æœå”®åƒ¹è¦ªæ°‘ä¸€é»æˆ‘æœƒç›´æ¥è²·å–®ã€‚"
                    ],
                    "zh-CN": [
                        "èº«ä¸º{occupation}ï¼Œæˆ‘è§‰å¾—è¿™äº§å“çš„å®ç”¨æ€§å¾ˆé«˜ï¼Œä¼šæƒ³å°è¯•çœ‹çœ‹ã€‚",
                        "è™½ç„¶ä»·æ ¼éœ€è¦è€ƒé‡ï¼Œä½†æ•´ä½“çš„è´¨æ„Ÿå¾ˆå¸å¼•æˆ‘ï¼Œ{structure}çš„äººé€šå¸¸è›®å–œæ¬¢è¿™ç§è®¾è®¡ã€‚",
                        "å¯¹{age}å²çš„æˆ‘æ¥è¯´ï¼Œè¿™äº§å“è§£å†³äº†ä¸å°‘éº»çƒ¦ï¼Œå€¼å¾—æ¨èã€‚",
                        "è®¾è®¡æ„Ÿå¾ˆå¼ºï¼Œæ„Ÿè§‰èƒ½å¤Ÿæå‡ç”Ÿæ´»å“è´¨ï¼Œå¾ˆæœ‰å…´è¶£ï¼",
                        "ç›®å‰å¸‚é¢ä¸Šç±»ä¼¼äº§å“å¾ˆå¤šï¼Œä½†è¿™æ¬¾çš„ç‹¬ç‰¹æ€§åœ¨äºç»†èŠ‚å¤„ç†ã€‚",
                        "æˆ‘æ˜¯æ¯”è¾ƒåŠ¡å®çš„äººï¼Œè¿™äº§å“çš„åŠŸèƒ½ç¡®å®æœ‰æ‰“ä¸­æˆ‘çš„ç—›ç‚¹ã€‚",
                        "ä»{element}è¡Œäººçš„è§’åº¦æ¥çœ‹ï¼Œè¿™ç§é£æ ¼å¾ˆæœ‰èƒ½é‡ï¼Œæ„Ÿè§‰ä¸é”™ã€‚",
                        "åˆšå¥½æœ€è¿‘æœ‰åœ¨æ‰¾ç±»ä¼¼çš„ä¸œè¥¿ï¼Œè¿™æ¬¾åˆ—å…¥è€ƒè™‘æ¸…å•ã€‚",
                        "äº§å“æ¦‚å¿µå¾ˆæœ‰è¶£ï¼Œå¦‚æœå”®ä»·äº²æ°‘ä¸€ç‚¹æˆ‘ä¼šç›´æ¥ä¹°å•ã€‚"
                    ],
                    "en": [
                        "As a {occupation}, I find this product very practical and would like to try it.",
                        "Although price is a factor, the quality attracts me. People with {structure} usually like this design.",
                        "For someone aged {age}, this product solves a lot of trouble and is worth recommending.",
                        "Strong design sense, feels like it can improve quality of life, very interested!",
                        "There are many similar products, but the uniqueness of this one lies in the details.",
                        "I am a practical person, and this product's functions really hit my pain points.",
                        "From the perspective of a {element} element person, this style is very energetic.",
                        "Just happened to be looking for something similar recently, considering this one.",
                        "The product concept is interesting, if the price is friendlier I would buy it."
                    ]
                 }
                 fallback_templates = fallback_templates_map.get(language, fallback_templates_map["zh-TW"])

                 for c in sampled_citizens: 
                      if len(fallback_comments) >= 10: break
                      cid = str(c["id"])
                      if cid in already_ids: continue
                      
                      bazi = c.get("bazi_profile", {})
                      elem = bazi.get("element", "Fire")
                      structure = bazi.get("structure", "ä¸€èˆ¬äººæ ¼")
                      occupation = c.get("occupation", "ä¸Šç­æ—")
                      age = c.get("age", 30)
                      
                      sentiment = "positive" if elem in ["Fire", "Wood"] else "neutral"
                      
                      try:
                          template = random.choice(fallback_templates)
                          text = template.format(occupation=occupation, structure=structure, age=age, element=elem)
                      except:
                          
                          default_texts = {
                                "zh-TW": "é€™ç”¢å“å¾ˆæœ‰ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®è³¼è²·ã€‚",
                                "zh-CN": "è¿™äº§å“å¾ˆæœ‰ç‰¹è‰²ï¼Œæˆ‘ä¼šè€ƒè™‘è´­ä¹°ã€‚",
                                "en": "This product is unique, I will consider buying it."
                            }
                          text = default_texts.get(language, default_texts["zh-TW"])

                      fallback_comments.append({
                          "citizen_id": cid,
                          "sentiment": sentiment,
                          "text": text
                      })
                 data["comments"] = fallback_comments
            else:
                 data["comments"] = gemini_comments
            # --- FALLBACK MECHANISM END ---

            # 5. Build Result Data (Manual Construction aligned with PDF flow)
            
            # Reconstruct Bazi distribution
            element_counts = {"Fire": 0, "Water": 0, "Metal": 0, "Wood": 0, "Earth": 0}
            for c in sampled_citizens:
                bazi = c.get("bazi_profile") or {}
                elem = bazi.get("element", "Fire")
                if elem in element_counts: element_counts[elem] += 1
            total = len(sampled_citizens)
            bazi_dist = {k: round(v / total * 100) for k, v in element_counts.items()} if total else element_counts

            # Build Personas
            personas = []
            for c in sampled_citizens[:10]:
                bazi = c.get("bazi_profile") or {}
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å‘½ç›¤ï¼Œéš¨æ©Ÿç”Ÿæˆ
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                    bazi["four_pillars"] = pillars_str
                
                personas.append({
                    "id": str(c["id"]),
                    "name": c["name"],
                    "age": str(c["age"]),
                    "location": c.get("location", "å°ç£"),
                    "occupation": c.get("occupation", "æœªçŸ¥è·æ¥­"),
                    "element": bazi.get("element", "Fire"),
                    "day_master": bazi.get("day_master", "?"),
                    "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                    "trait": ", ".join(c["traits"][:2]) if c["traits"] else "å€‹æ€§é®®æ˜",
                    "decision_logic": "æ ¹æ“šå…«å­—æ ¼å±€ç‰¹è³ªåˆ†æ",
                    "current_luck": bazi.get("current_luck", {}),
                    "luck_timeline": bazi.get("luck_timeline", []),
                    "four_pillars": pillars_str
                })

            # Process Comments (Map to Citizens)
            gemini_comments = data.get("comments", [])
            arena_comments = []

            # ------------------------------------

            citizen_map = {str(c["id"]): c for c in sampled_citizens}
            
            for comment in gemini_comments:
                if not isinstance(comment, dict): continue
                raw_id = comment.get("citizen_id")
                c_id = str(raw_id) if raw_id is not None else ""
                citizen = citizen_map.get(c_id)
                # Fallback matching by index if ID not found
                if not citizen and c_id.isdigit():
                     idx = int(c_id)
                     if 0 <= idx < len(sampled_citizens): citizen = sampled_citizens[idx]
                
                if citizen:
                    bazi = citizen.get("bazi_profile") or {}
                    age = citizen.get("age", 30)
                    # è¨ˆç®—å¤§é‹è³‡æ–™
                    luck_timeline = bazi.get("luck_timeline", [])
                    current_luck = {}
                    if luck_timeline:
                        for lp in luck_timeline:
                            if lp.get("age_start", 0) <= age <= lp.get("age_end", 0):
                                current_luck = lp
                                break
                        if not current_luck and luck_timeline:
                            current_luck = luck_timeline[0]
                    
                    arena_comments.append({
                        "sentiment": comment.get("sentiment", "neutral"),
                        "text": comment.get("text", ""),
                        "persona": {
                            "id": str(citizen["id"]),
                            "name": citizen["name"],
                            "age": str(age),
                            "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                            "element": bazi.get("element", "Fire"),
                            "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                            "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                            "location": citizen.get("location", "å°ç£"),
                            "day_master": bazi.get("day_master", "?"),
                            "strength": bazi.get("strength", "ä¸­å’Œ"),
                            "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                            # å®Œæ•´ç”Ÿè¾°è³‡æ–™
                            "birth_year": bazi.get("birth_year"),
                            "birth_month": bazi.get("birth_month"),
                            "birth_day": bazi.get("birth_day"),
                            "birth_shichen": bazi.get("birth_shichen"),
                            "four_pillars": bazi.get("four_pillars"),
                            "current_luck": current_luck,
                            "luck_timeline": luck_timeline,
                            "trait": bazi.get("trait", "å¤šå…ƒæ€§æ ¼")
                        }
                    })

            result_data = {
                "status": "ready",
                "score": data.get("result", {}).get("score", 0),
                "intent": "Completed",
                "summary": data.get("result", {}).get("summary", "åˆ†æå®Œæˆ"),
                "simulation_metadata": {
                    "product_category": data.get("simulation_metadata", {}).get("product_category", "æœªåˆ†é¡"),
                    "marketing_angle": data.get("simulation_metadata", {}).get("marketing_angle", "æœªåˆ†é¡"),
                    "bazi_analysis": data.get("simulation_metadata", {}).get("bazi_analysis", ""),
                    "sample_size": 8,
                    "bazi_distribution": bazi_dist
                },
                "genesis": {
                    "total_population": 1000,
                    "sample_size": len(personas),
                    "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            
            # ğŸ§¬ [Sidecar] è¿½åŠ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–è©®é‡‹å±¤
            methodology_sidecar = _generate_methodology_sidecar(
                score=result_data.get("score"),
                summary=result_data.get("summary"),
                language=language, metric_advice=data.get("metric_advice")
            )
            
            # ğŸ§¬ ã€ABM EVOLUTIONã€‘æ·»åŠ æ¼”åŒ–æ•¸æ“šåˆ°methodology_data
            if abm_evolution_data:
                methodology_sidecar["abm_evolution"] = abm_evolution_data
                print(f"âœ… [ABM] Evolutionæ•¸æ“šå·²æ·»åŠ åˆ°methodology_data")
            
            # ğŸ§¬ ã€ABM ANALYTICSã€‘æ·»åŠ çªç¾è¡Œç‚ºåˆ†ææŒ‡æ¨™
            if abm_analytics:
                methodology_sidecar["abm_analytics"] = {
                    "consensus": round(abm_analytics.get("consensus", 0), 3),
                    "polarization": round(abm_analytics.get("polarization", 0), 3),
                    "herding_strength": round(abm_analytics.get("herding_strength", 0), 2),
                    "network_density": round(abm_analytics.get("network_density", 0), 3),
                    "element_preferences": {
                        k: round(v, 1) for k, v in abm_analytics.get("element_preferences", {}).items()
                    }
                }
                print(f"âœ… [ABM] Analyticsæ•¸æ“šå·²æ·»åŠ åˆ°methodology_data")
            
            result_data["methodology_data"] = methodology_sidecar
            
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Final Result Data written. Keys: {list(result_data.keys())}\n")
            
            # Updating DB (Use run_in_threadpool to match PDF flow)
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            # print(f"Bazi-enriched AI Data written to PostgreSQL: {sim_id}")

        except Exception as e:
            # print(f"AI Analysis Failed: {e}")
            error_msg = str(e)
            tb = traceback.format_exc()
            logger.error(f"[{sim_id}] CRASH: {error_msg}\n{tb}")
            try:
                with open("last_error.txt", "w", encoding="utf-8") as f:
                    f.write(f"{error_msg}\n{tb}")
                with open("debug_image.log", "a", encoding="utf-8") as f:
                    f.write(f"[{sim_id}] CRASH:\n{tb}\n")
            except:
                pass
            self._handle_error_db(sim_id, error_msg)

    async def run_simulation_with_pdf_data(self, pdf_bytes, sim_id, file_name, language="zh-TW"):
        """æ ¸å¿ƒ PDF åˆ†æé‚è¼¯ (Decoupled)"""
        with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] PDF Flow Start (Lang: {language})\n")
        try:
            # Convert PDF to base64
            pdf_b64 = base64.b64encode(pdf_bytes).decode('utf-8')
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] PDF Base64 done\n")
            
            # ğŸŒ Fetch Target Market (Globalization)
            from app.core.database import get_simulation
            sim_data = get_simulation(sim_id)
            targeting_data = sim_data.get("simulation_metadata", {}).get("targeting", {}) if sim_data else {}
            target_market = targeting_data.get("target_market", "TW") if targeting_data else "TW"
            market_config = MARKET_CULTURE_CONFIG.get(target_market, MARKET_CULTURE_CONFIG["TW"])
            market_context_override = market_config.get("context_override", "")



            logger.info(f"ğŸŒ [PDF Globalization] Target Market: {target_market}")

            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            from fastapi.concurrency import run_in_threadpool
            # [Fix] ä½¿ç”¨ run_in_threadpool æŠ½æ¨£ 30 ä½å¸‚æ°‘ï¼Œå¾ä¸­ç²¾é¸ 10 ä½ç”Ÿæˆè©•è«–
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Got citizens: {len(sampled_citizens)}\n")
            
            # ç°¡åŒ–å¸‚æ°‘è³‡æ–™
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "gender": c["gender"],
                    "location": c["location"],
                    "day_master": c["bazi_profile"].get("day_master", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "traits": c["traits"]
                }
                for c in sampled_citizens
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False, indent=2)
            
            # 3. Prompt (Default to zh-TW base)
            prompt_base_tw = f"""
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚ä½ æ­£åœ¨å¯©é–±ä¸€ä»½å•†æ¥­è¨ˆåŠƒæ›¸ PDFï¼Œä¸¦éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„ç­–ç•¥å»ºè­°ã€‚æˆ‘å€‘å·²é‡å° 1,000 ä½è™›æ“¬å¸‚æ°‘é€²è¡Œåˆæ­¥æ¨¡æ“¬ï¼Œä¸¦å¾ä¸­ã€Œé¸å‡ºã€ä»¥ä¸‹ 10 ä½å…·å‚™ä»£è¡¨æ€§çš„ AI å¸‚æ°‘ï¼Œè«‹æ¨¡æ“¬ä»–å€‘å°é€™ä»½è¨ˆåŠƒæ›¸çš„åæ‡‰ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹å•†æ¥­æ¨¡å¼ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "currency": "TWD (æ–°å°å¹£)",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é ˆæŒ‘é¸ 10 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è¾¯è«–è©•è«–)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´ç¼ºå£èˆ‡è¨­è¨ˆåˆè¡·ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (çµåˆ 1,000 ä½å¸‚æ°‘çš„æ¨¡æ“¬é æ¼”çµæœï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™æˆ°ç•¥é«˜åº¦çš„æ”¹é€²æ„è¦‹ï¼ŒæŒ‡å¼•å…¶çˆ†ç™¼ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡ 1",
                "advice": "ã€é‡å°å—çœ¾ A å¯«å…¥å…·é«”æˆ°è¡“ç´°ç¯€ï¼Œè‡³å°‘ 150 å­—ï¼Œä¸å¾—è¤‡è£½æ­¤æŒ‡ä»¤æ–‡å­—ã€‘",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+X åˆ†"
            }},
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡ 2",
                "advice": "ã€é‡å°å—çœ¾ A å¯«å…¥å…·é«”æˆ°è¡“ç´°ç¯€ï¼Œè‡³å°‘ 150 å­—ï¼Œä¸å¾—è¤‡è£½æ­¤æŒ‡ä»¤æ–‡å­—ã€‘",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+Y åˆ†"
            }},
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡ 3",
                "advice": "ã€é‡å°å—çœ¾ A å¯«å…¥å…·é«”æˆ°è¡“ç´°ç¯€ï¼Œè‡³å°‘ 150 å­—ï¼Œä¸å¾—è¤‡è£½æ­¤æŒ‡ä»¤æ–‡å­—ã€‘",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+Z åˆ†"
            }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é ˆåš´æ ¼éµå®ˆ [è§£æ]ã€[å„ªåŒ–]ã€[æˆ°ç•¥] ä¸‰æ®µå¼ï¼Œç¸½å­—æ•¸ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰å€‹å»ºè­° suggestions å¿…é ˆå®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å‚™æ¥µé«˜åŸ·è¡Œåƒ¹å€¼ã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. é€™æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æï¼Œè«‹èšç„¦æ–¼ã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€
2. arena_comments è«‹ç”ŸæˆæŠ•è³‡è€…/å‰µæ¥­è€…è§’åº¦çš„è©•è«–ï¼Œå¿…é ˆå¼•ç”¨è¨ˆåŠƒæ›¸å…·é«”å…§å®¹
3. **è©•è«–å“è³ª**ï¼šæ¯å‰‡è©•è«–å¿…é ˆè‡³å°‘ 40 å­—ï¼Œåš´ç¦ä½¿ç”¨æ¨¡æ¿åŒ–èªå¥ï¼ˆå¦‚ã€Œç¬¦åˆæˆ‘çš„éœ€æ±‚ã€ï¼‰ï¼Œå¿…é ˆé«”ç¾å¸‚æ°‘å€‹äººæ ¼å±€ã€‚
4. **suggestions å¿…é ˆéå¸¸å…·é«”**ï¼šæ¯å€‹å»ºè­°150å­—ä»¥ä¸Šï¼ŒåŸ·è¡Œè¨ˆåŠƒ5å€‹æ­¥é©Ÿå«æ™‚é–“è¡¨ï¼Œä¸è¦æ³›æ³›è€Œè«‡
5. ç¦æ­¢ä½¿ç”¨ã€Œé€²è¡Œ A/B æ¸¬è©¦ã€ã€ã€Œå„ªåŒ–è¡ŒéŠ·æ–‡æ¡ˆã€é€™é¡é€šç”¨å»ºè­°ï¼Œå¿…é ˆé‡å°é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼çµ¦å‡ºç¨ç‰¹è¦‹è§£
"""

            # --- Multi-language Prompt Logic ---
            if language == "en":
                prompt_text = f"""
You are the Core AI Strategic Advisor of the MIRRA system. You are reviewing a Business Plan PDF and need to provide **in-depth, specific, and actionable** strategic advice. Based on a preliminary simulation of 1,000 virtual citizens, we have "selected" the following 10 representative AI citizens to engage in a fierce debate regarding the "Business Feasibility", "Revenue Model", and "Market Pain Points" of this business plan.

ğŸ“‹ Virtual Citizen Profiles (Bazi structures pre-calculated):

{citizens_json}

âš ï¸ **Important Instruction: Strategy Advice Must Be Specific and Actionable**
- Do not give generic advice like "do A/B testing".
- You must provide **unique, insightful** suggestions based on **this specific business model's** characteristics.
- Action steps must be specific: "What to do in Week 1, what to achieve in Month 1, how to measure success".
- Each suggestion must explain "Why is this important for this specific business model".

ğŸ¯ You must return a **PURE JSON string (No Markdown)**, structure as follows:

{{
    "simulation_metadata": {{
        "product_category": "Business Plan",
        "target_market": "International",
        "currency": "USD (US Dollar)",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (Must select 10 citizens)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (Must generate exactly 10 debate comments on the business model by citizens)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "Report Title\\n\\n[Analysis] (Deep analysis of core value, market gap, and design intent, >200 words)\\n\\n[Optimization] (Based on the simulation results of 1,000 citizens, propose reconstruction or optimization directions, >200 words)\\n\\n[Strategy] (Provide high-level strategic improvements to guide explosion, >150 words)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "Specific Market Segment 1",
                "advice": ">150 words specific 'Tactical Landing' advice...",
                "element_focus": "Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "Specific Metrics",
                "potential_risks": "Challenges & Countermeasures",
                "score_improvement": "+X points"
            }},
            {{
                "target": "Specific Market Segment 2",
                "advice": ">150 words specific 'Tactical Landing' advice...",
                "element_focus": "Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "Specific Metrics",
                "potential_risks": "Challenges & Countermeasures",
                "score_improvement": "+Y points"
            }},
            {{
                "target": "Specific Market Segment 3",
                "advice": ">150 words specific 'Tactical Landing' advice...",
                "element_focus": "Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "Specific Metrics",
                "potential_risks": "Challenges & Countermeasures",
                "score_improvement": "+Z points"
            }}
        ]
    }}
}}

ğŸ“Œ Important Rules:
1. **Analysis Depth**: Summary must strictly follow [Analysis], [Optimization], [Strategy] format, >500 words total.
2. **Actionable**: Suggestions must be concrete and execution plans must have high implementation value.
3. **Comment Quality**: Each comment must be at least 40 words, strictly avoid template phrases (e.g., "meets my needs"), and must reflect the citizen's personal Bazi traits.
4. **No Placeholders**: Do not copy placeholder text.
5. **Context**: This is a business plan analysis, focus on "Feasibility", "Revenue Model", and "Pain Points".
6. **Comments**: Generate investor/entrepreneur perspective comments, quoting specific plan details.
7. **Language**: All content must be in English.
"""
            elif language == "zh-CN":
                prompt_text = f"""
ä½ æ˜¯ MIRRA å¢ƒç•Œç³»ç»Ÿçš„æ ¸å¿ƒ AI ç­–ç•¥é¡¾é—®ã€‚ä½ æ­£åœ¨å®¡é˜…ä¸€ä»½å•†ä¸šè®¡åˆ’ä¹¦ PDFï¼Œå¹¶éœ€è¦æä¾›**æ·±åº¦ã€å…·ä½“ã€å¯æ‰§è¡Œ**çš„ç­–ç•¥å»ºè®®ã€‚æˆ‘ä»¬å·²é’ˆå¯¹ 1,000 ä½è™šæ‹Ÿå¸‚æ°‘è¿›è¡Œåˆæ­¥æ¨¡æ‹Ÿï¼Œå¹¶ä»ä¸­ã€Œé€‰å‡ºã€ä»¥ä¸‹ 10 ä½å…·å¤‡ä»£è¡¨æ€§çš„ AI å¸‚æ°‘ï¼Œè¯·æ¨¡æ‹Ÿä»–ä»¬å¯¹è¿™ä»½è®¡åˆ’ä¹¦çš„ååº”ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå®å¸‚æ°‘èµ„æ–™ï¼ˆå…«å­—æ ¼å±€å·²é¢„å…ˆè®¡ç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè®®å¿…é¡»éå¸¸å…·ä½“ä¸”å¯æ‰§è¡Œ**
- ä¸è¦ç»™å‡ºã€Œè¿›è¡Œ A/B æµ‹è¯•ã€è¿™ç§äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè®®
- å¿…é¡»æ ¹æ®**è¿™ä¸ªç‰¹å®šå•†ä¸šæ¨¡å¼**çš„ç‰¹ç‚¹ï¼Œç»™å‡º**ç‹¬ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè®®
- æ‰§è¡Œæ­¥éª¤è¦å…·ä½“åˆ°ã€Œç¬¬ä¸€å‘¨åšä»€ä¹ˆã€ç¬¬ä¸€ä¸ªæœˆè¾¾æˆä»€ä¹ˆã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯ä¸ªå»ºè®®éƒ½è¦è¯´æ˜ã€Œä¸ºä»€ä¹ˆè¿™å¯¹è¿™ä¸ªå•†ä¸šæ¨¡å¼ç‰¹åˆ«é‡è¦ã€

ğŸ¯ è¯·åŠ¡å¿…å›ä¼ ä¸€ä¸ª**çº¯ JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œç»“æ„å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†ä¸šè®¡åˆ’ä¹¦",
        "target_market": "ä¸­å›½å¤§é™†",
        "currency": "CNY (äººæ°‘å¸)",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é¡»æŒ‘é€‰ 10 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é¡»ç”Ÿæˆç²¾ç¡® 10 åˆ™å¸‚æ°‘é’ˆå¯¹å•†ä¸šæ¨¡å¼çš„è¾©è®ºè¯„è®º)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†ææŠ¥å‘Šæ ‡é¢˜\\n\\n[è§£æ] (æ·±å…¥è§£æäº§å“æ ¸å¿ƒä»·å€¼ã€å¸‚åœºç¼ºå£ä¸è®¾è®¡åˆè¡·ï¼Œè‡³å°‘ 200 å­—)\\n\\n[ä¼˜åŒ–] (ç»“åˆ 1,000 ä½å¸‚æ°‘çš„æ¨¡æ‹Ÿé¢„æ¼”ç»“æœï¼Œæå‡ºå¯¹æ­¤æ¨¡å¼çš„é‡æ„æˆ–ä¼˜åŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\\n\\n[æˆ˜ç•¥] (ç»™å‡ºå…·å¤‡æˆ˜ç•¥é«˜åº¦çš„æ”¹è¿›æ„è§ï¼ŒæŒ‡å¼•å…¶çˆ†å‘ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 1",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥éª¤ 2", "æ­¥éª¤ 3", "æ­¥éª¤ 4", "æ­¥éª¤ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+X åˆ†"
            }},
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 2",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥éª¤ 2", "æ­¥éª¤ 3", "æ­¥éª¤ 4", "æ­¥éª¤ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+Y åˆ†"
            }},
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 3",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥éª¤ 2", "æ­¥éª¤ 3", "æ­¥éª¤ 4", "æ­¥éª¤ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+Z åˆ†"
            }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é¡»ä¸¥æ ¼éµå®ˆ [è§£æ]ã€[ä¼˜åŒ–]ã€[æˆ˜ç•¥] ä¸‰æ®µå¼ï¼Œæ€»å­—æ•° 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰ä¸ªå»ºè®® suggestions å¿…é¡»å®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å¤‡æé«˜æ‰§è¡Œä»·å€¼ã€‚
3. **ç¦æ­¢èŒƒä¾‹å†…å®¹**ï¼šç»å¯¹ä¸å¾—ç›´æ¥å¤åˆ¶ JSON ç»“æ„ä¸­çš„ placeholder æ–‡å­—ã€‚
4. **è¯­è¨€**ï¼šæ‰€æœ‰å†…å®¹å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚
"""
            else:
                 prompt_text = prompt_base_tw
            
            # ğŸŒ æ³¨å…¥å¸‚å ´æ–‡åŒ–è¦†è“‹åˆ° Prompt é–‹é ­ (Chameleon Architecture)
            if market_context_override:
                prompt_text = market_context_override + "\n\n" + prompt_text
                logger.info(f"[{sim_id}] PDF Market context override injected for: {target_market}")

            # ğŸ§¬ ã€ABM INTEGRATIONã€‘åŸ·è¡Œ Agent-Based Modeling æ¨¡æ“¬
            abm_evolution_data = None
            abm_analytics = None
            abm_comments_data = []
            
            try:
                # PDF åˆ†æé€šå¸¸éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡
                abm_res = await self._run_abm_simulation(sampled_citizens, text_context or "PDF Business Plan", language)
                abm_evolution_data = abm_res["evolution_data"]
                abm_analytics = abm_res["analytics_data"]
                abm_comments_data = abm_res["comments_data"]
            except Exception as e:
                logger.error(f"âŒ [ABM] PDF ABMæ¨¡æ“¬å¤±æ•—: {e}")

            # 4. REST API Call
            api_key = settings.GOOGLE_API_KEY
            # [Fix] PDF needs more time. Set base timeout to 300s for large files.
            # Explicitly log start time and payload size
            import datetime
            ts_start = datetime.datetime.now().isoformat()
            payload_len = len(pdf_b64) if pdf_b64 else 0
            with open("debug_trace.log", "a", encoding="utf-8") as f: 
                f.write(f"[{sim_id}] [TIME:{ts_start}] Calling Gemini REST API (PDF), Payload: {payload_len} bytes, Lang: {language}\n")
            
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, pdf_b64=pdf_b64, timeout=300)

            ts_end = datetime.datetime.now().isoformat()
            with open("debug_trace.log", "a", encoding="utf-8") as f: 
                f.write(f"[{sim_id}] [TIME:{ts_end}] Gemini Returned (PDF). Success: {ai_text is not None}\n")
            
            if ai_text is None:
                err_msg = f"All models failed for PDF. {last_error}"
                logger.error(f"[{sim_id}] {err_msg}")
                with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] ERROR: {err_msg}. Triggering FALLBACK.\n")
                ai_text = "{}"

            # 5. Process
            data = self._clean_and_parse_json(ai_text)
            
            # ğŸ” [DEBUG] Log parsed JSON structure to diagnose "AI åˆ†æè¶…æ™‚" issue
            with open("debug_trace.log", "a", encoding="utf-8") as f:
                f.write(f"[{sim_id}] Parsed JSON Keys: {list(data.keys()) if isinstance(data, dict) else 'NOT_DICT'}\n")
                result_obj = data.get("result", {})
                f.write(f"[{sim_id}] result Keys: {list(result_obj.keys()) if isinstance(result_obj, dict) else 'NOT_DICT'}\n")
                summary_val = result_obj.get("summary", "<<MISSING>>") if isinstance(result_obj, dict) else "<<RESULT_NOT_DICT>>"
                f.write(f"[{sim_id}] result.summary (first 200 chars): {str(summary_val)[:200]}\n")
                suggestions_val = result_obj.get("suggestions", []) if isinstance(result_obj, dict) else []
                f.write(f"[{sim_id}] result.suggestions count: {len(suggestions_val) if isinstance(suggestions_val, list) else 'NOT_LIST'}\n")
            
            # [Fix] Initialize key variables to avoid UnboundLocalError
            arena_comments = []
            filtered_comments = []
            personas = []
            
            # --- ğŸ§¬ æ•´åˆ ABM æ•¸æ“šåˆ°çµæœä¸­ ---
            if abm_evolution_data:
                data["abm_evolution"] = abm_evolution_data
            if abm_analytics:
                data["abm_analytics"] = abm_analytics
            if abm_comments_data:
                # åˆä½µ Gemini è©•è«–èˆ‡ ABM è©•è«– (Gemini å„ªå…ˆ)
                existing_comments = data.get("arena_comments", [])
                data["arena_comments"] = existing_comments + abm_comments_data
            
            # 6. Build Result Data
            sim_metadata = data.get("simulation_metadata", {})
            # PDF uploads always use tech_monetization metric
            sim_metadata["source_type"] = "pdf"
            sim_metadata["product_category"] = "tech_electronics"
            
            # --- [Fix] ç¢ºä¿å°±ç®— Gemini å¤±æ•—ï¼Œä¹Ÿè¦æœ‰ personas è³‡æ–™é¡¯ç¤ºåœ¨ UI ---
            genesis_data = data.get("genesis", {})
            personas = genesis_data.get("personas", [])
            if not personas and sampled_citizens:
                # å¦‚æœ Gemini æ²’çµ¦ personasï¼Œå¾æŠ½æ¨£çš„å¸‚æ°‘ä¸­é¸ 10 å€‹
                for c in sampled_citizens[:10]:
                    bazi = c.get("bazi_profile") or {}
                    personas.append({
                        "id": str(c.get("id", "0")),
                        "name": c.get("name", "AIå¸‚æ°‘"),
                        "age": str(c.get("age", 30)),
                        "element": bazi.get("element", "æœªçŸ¥"),
                        "day_master": bazi.get("day_master", "æœªçŸ¥"),
                        "pattern": bazi.get("structure", "æœªçŸ¥"),
                        "trait": c.get("traits")[0] if c.get("traits") else "ç©æ¥µ",
                        "decision_logic": "ç†æ€§åˆ†æå•†æ¥­æ¨¡å¼å¯è¡Œæ€§"
                    })

            bazi_dist = sim_metadata.get("bazi_distribution", {"Fire": 20, "Water": 20, "Metal": 20, "Wood": 20, "Earth": 20})
            
            # --- 1. QUALITY FILTER FIRST (Sync with Image Flow) ---
            # [Fix] æŠ“å– Gemini è¿”å›çš„è©•è«–æˆ–æ˜¯åˆä½µå¾Œçš„è©•è«–
            raw_arena_comments = data.get("arena_comments", [])
            filtered_comments = []
            forbidden_phrases = [
                "ç¬¦åˆæˆ‘çš„", "çœ‹èµ·ä¾†ä¸éŒ¯", "å€¼å¾—è³¼è²·", "å€¼å¾—ä¹°", "çœ‹èµ·æ¥ä¸é”™",
                "ç¬¦åˆæˆ‘çš„éœ€æ±‚", "éå¸¸å–œæ­¡", "éå¸¸å–œæ¬¢", "å¥½ç”¢å“", "å¥½äº§å“",
                "æ¨è–¦è³¼è²·", "æ¨èè´­ä¹°", "æŒºå¥½çš„", "è »å¥½çš„", "é‚„ä¸éŒ¯", "è¿˜ä¸é”™",
                "looks good", "worth buying", "meets my needs", "highly recommend"
            ]
            for c in raw_arena_comments:
                if not isinstance(c, dict): continue
                text = c.get("text", "")
                if len(text) < 40: continue
                if any(phrase in text for phrase in forbidden_phrases): continue
                filtered_comments.append(c)
            
            # --- 2. FALLBACK MECHANISM (Fill up to 10) ---
            if len(filtered_comments) < 10:
                logger.warning(f"[{sim_id}] PDF Analysis: Insufficient comments ({len(filtered_comments)}). Filling fallback.")
                already_names = {c.get("persona", {}).get("name") for c in filtered_comments if c.get("persona")}
                
                fallback_templates_map = {
                    "zh-TW": ["èº«ç‚ºæŠ•è³‡åˆ†æçš„è§’åº¦çœ‹ï¼Œé€™ä»½è¨ˆåŠƒæ›¸åœ¨{pattern}å±¤é¢å¾ˆæœ‰æ½›åŠ›ï¼Œä½†{element}è¡Œçš„è€ƒé‡ä¸å¯å°‘ã€‚", "ä½œç‚ºå‰µæ¥­è€…ï¼Œæˆ‘è¦ºå¾—ç²åˆ©æ¨¡å¼é‚„èƒ½å†å„ªåŒ–ï¼Œç‰¹åˆ¥æ˜¯é‡å°{age}æ­²å®¢ç¾¤çš„åˆ‡å…¥é»ã€‚"],
                    "zh-CN": ["èº«ä¸ºæŠ•èµ„åˆ†æçš„è§’åº¦çœ‹ï¼Œè¿™ä»½è®¡åˆ’ä¹¦åœ¨{pattern}å±‚é¢å¾ˆæœ‰æ½œåŠ›ï¼Œä½†{element}è¡Œçš„è€ƒé‡ä¸å¯å°‘ã€‚", "ä½œä¸ºåˆ›ä¸šè€…ï¼Œæˆ‘è§‰å¾—è·åˆ©æ¨¡å¼è¿˜èƒ½å†ä¼˜åŒ–ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹{age}å²å®¢ç¾¤çš„åˆ‡å…¥ç‚¹ã€‚"],
                    "en": ["From an investment perspective, this plan has potential in {pattern}, but needs {element} consideration.", "As an entrepreneur, the revenue model needs optimization for the {age} age group."]
                }
                templates = fallback_templates_map.get(language, fallback_templates_map["zh-TW"])
                
                for citizen in sampled_citizens:
                    if len(filtered_comments) >= 10: break
                    if citizen["name"] in already_names: continue
                    
                    bazi = citizen.get("bazi_profile", {})
                    text = random.choice(templates).format(
                        pattern=bazi.get("structure", "å¸‚å ´"),
                        element=bazi.get("element", "äº”è¡Œ"),
                        age=citizen.get("age", 30)
                    )
                    filtered_comments.append({
                        "sentiment": "neutral",
                        "text": text,
                        "persona": {"name": citizen["name"]} # Temporary persona for matching
                    })
            arena_comments = filtered_comments
            # -----------------------------------------------

            # -----------------------------------------------

            # è£œå…… arena_comments ä¸­æ¯å€‹ persona çš„å®Œæ•´å…«å­—è³‡æ–™
            # å°‡åŸæœ¬çš„ arena_comments è®Šæ•¸ç›´æ¥å»¶çºŒä½¿ç”¨ï¼ˆä¾†è‡ª filtered_commentsï¼‰
            citizen_name_map = {c["name"]: c for c in sampled_citizens}
            
            def build_luck_data(bazi, age):
                """å¾ bazi_profile æ§‹å»º luck_timeline å’Œ current_luck"""
                # å„ªå…ˆä½¿ç”¨å·²æœ‰çš„ luck_timeline
                luck_timeline = bazi.get("luck_timeline", [])
                current_luck = bazi.get("current_luck", {})
                
                # å¦‚æœæ²’æœ‰ luck_timelineï¼Œå¾ luck_pillars ç”Ÿæˆ
                if not luck_timeline and bazi.get("luck_pillars"):
                    for l in bazi["luck_pillars"]:
                        name = l.get('pillar', 'ç”²å­') + "é‹"
                        desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                        luck_timeline.append({
                            "age_start": l.get('age_start', 0),
                            "age_end": l.get('age_end', 9),
                            "name": name,
                            "description": desc
                        })
                        # æ‰¾ç•¶å‰å¤§é‹
                        try:
                            citizen_age = int(age)
                        except:
                            citizen_age = 30
                        if l.get('age_start', 0) <= citizen_age <= l.get('age_end', 99):
                            current_luck = {"name": name, "description": desc}
                
                # å¦‚æœå®Œå…¨æ²’æœ‰è³‡æ–™ï¼Œçµ¦ä¸€å€‹é»˜èªå€¼
                if not luck_timeline:
                    start_age = random.randint(2, 9)
                    pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                    descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                    for i in range(8):
                        luck_timeline.append({
                            "age_start": start_age + i*10,
                            "age_end": start_age + i*10 + 9,
                            "name": f"{pillars_pool[i]}é‹",
                            "description": descs[i]
                        })
                    # è¨­ç½®ç•¶å‰å¤§é‹
                    try:
                        citizen_age = int(age)
                    except:
                        citizen_age = 30
                    for lt in luck_timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                
                if not current_luck and luck_timeline:
                    current_luck = {"name": luck_timeline[0]["name"], "description": luck_timeline[0]["description"]}
                
                return luck_timeline, current_luck
            
            for comment in arena_comments:
                persona = comment.get("persona", {})
                name = persona.get("name", "")
                
                # å˜—è©¦å¾è³‡æ–™åº«å¸‚æ°‘è³‡æ–™ä¸­è£œå……
                citizen = citizen_name_map.get(name)
                if citizen:
                    bazi = citizen.get("bazi_profile", {})
                    age = citizen.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    # è£œå……å®Œæ•´çš„å…«å­—è³‡æ–™
                    persona["id"] = str(citizen.get("id", ""))
                    persona["age"] = str(age)
                    persona["occupation"] = citizen.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = citizen.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰å¸‚æ°‘ï¼Œå¾ sampled_citizens ä¸­éš¨æ©Ÿå–ä¸€å€‹
                    fallback = random.choice(sampled_citizens) if sampled_citizens else {}
                    bazi = fallback.get("bazi_profile", {})
                    age = fallback.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    persona["id"] = str(fallback.get("id", random.randint(1, 1000)))
                    persona["age"] = str(age)
                    persona["occupation"] = fallback.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = fallback.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                
                comment["persona"] = persona
            
            # 7. Update DB
            result_data = {
                "status": "ready",
                "score": data.get("result", {}).get("score", 70),
                "intent": data.get("result", {}).get("market_sentiment", "åˆ†æå®Œæˆ"),
                "summary": data.get("result", {}).get("summary", "AI åˆ†æè¶…æ™‚ï¼Œç„¡æ³•ç”Ÿæˆå®Œæ•´å ±å‘Šã€‚è«‹ç¨å¾Œé‡è©¦ã€‚"),
                "simulation_metadata": sim_metadata,
                "genesis": {
                     "total_population": 1000,
                     "sample_size": len(personas),
                     "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            # ğŸ§¬ ã€ABM INTEGRATIONã€‘åŸ·è¡Œ Agent-Based Modeling æ¨¡æ“¬
            try:
                abm_res = await self._run_abm_simulation(sampled_citizens, None, language)
                abm_evolution_data = abm_res["evolution_data"]
                abm_analytics = abm_res["analytics_data"]
            except Exception as e:
                logger.error(f"[{sim_id}] ABM Simulation Failed: {e}")
                abm_evolution_data = None
                abm_analytics = None

            # ğŸ§¬ [Sidecar] è¿½åŠ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–è©®é‡‹å±¤
            methodology_sidecar = _generate_methodology_sidecar(
                score=result_data.get("score"),
                summary=result_data.get("summary"),
                language=language, metric_advice=data.get("metric_advice")
            )

            # ğŸ§¬ ã€ABM EVOLUTIONã€‘æ·»åŠ æ¼”åŒ–æ•¸æ“š
            if abm_evolution_data:
                methodology_sidecar["abm_evolution"] = abm_evolution_data
            if abm_analytics:
                methodology_sidecar["abm_analytics"] = abm_analytics

            result_data["methodology_data"] = methodology_sidecar
            
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Updating DB (PDF)...\n")
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            print(f"âœ… [Core PDF] å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æå·²å¯«å…¥ PostgreSQL: {sim_id}")

        except Exception as e:
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] ERROR: {str(e)}\n")
            print(f"[Core PDF] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    async def run_simulation_with_text_data(self, text_content: str, sim_id: str, source_type: str = "txt", language: str = "zh-TW"):
        """è™•ç†ç´”æ–‡å­—å…§å®¹çš„å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æ (Word/PPT/TXT) - èˆ‡ PDF æµç¨‹å°é½Š"""
        try:
            from fastapi.concurrency import run_in_threadpool
            
            print(f"[Core TEXT] Starting text analysis for {sim_id}, source: {source_type}")
            
            # ğŸŒ Fetch Target Market (Globalization)
            from app.core.database import get_simulation
            sim_data = get_simulation(sim_id)
            targeting_data = sim_data.get("simulation_metadata", {}).get("targeting", {}) if sim_data else {}
            target_market = targeting_data.get("target_market", "TW") if targeting_data else "TW"
            market_config = MARKET_CULTURE_CONFIG.get(target_market, MARKET_CULTURE_CONFIG["TW"])
            market_context_override = market_config.get("context_override", "")
            logger.info(f"ğŸŒ [TEXT Globalization] Target Market: {target_market}")
            
            # 1. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            # [Fix] æŠ½æ¨£ 30 ä½å¸‚æ°‘ï¼Œå¾ä¸­ç²¾é¸ 10 ä½ç”Ÿæˆè©•è«–
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            print(f"[Core TEXT] Sampled {len(sampled_citizens)} citizens")
            
            # 2. æº–å‚™å¸‚æ°‘è³‡æ–™çµ¦ Gemini (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "gender": c["gender"],
                    "location": c["location"],
                    "day_master": c["bazi_profile"].get("day_master", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "traits": c["traits"]
                }
                for c in sampled_citizens
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False, indent=2)
            
            # 3. å»ºæ§‹ Prompt (Default to zh-TW base)
            prompt_base_tw = f"""ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚ä½ æ­£åœ¨å¯©é–±ä¸€ä»½å•†æ¥­è¨ˆåŠƒæ›¸ï¼ˆä¾†è‡ª {source_type.upper()} æ–‡ä»¶ï¼‰ï¼Œä¸¦éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„ç­–ç•¥å»ºè­°ã€‚

ä»¥ä¸‹æ˜¯æ–‡ä»¶å…§å®¹ï¼š
---
{text_content[:8000]}  
---

è«‹è®“ä»¥ä¸‹å¾ 1,000 ä½è™›æ“¬å¸‚æ°‘ä¸­é¸å‡ºçš„ 10 ä½å…·å‚™ä»£è¡¨æ€§çš„ AI è™›æ“¬å¸‚æ°‘ï¼Œé‡å°é€™ä»½å•†æ¥­è¨ˆåŠƒæ›¸é€²è¡Œã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€çš„æ¿€çƒˆè¾¯è«–ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹å•†æ¥­æ¨¡å¼ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é ˆæŒ‘é¸ 10 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è¾¯è«–è©•è«–)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´ç¼ºå£èˆ‡è¨­è¨ˆåˆè¡·ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (çµåˆ 1,000 ä½å¸‚æ°‘çš„æ¨¡æ“¬é æ¼”çµæœï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™æˆ°ç•¥é«˜åº¦çš„æ”¹é€²æ„è¦‹ï¼ŒæŒ‡å¼•å…¶çˆ†ç™¼ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡ 1",
                "advice": "ã€é‡å°å—çœ¾ A å¯«å…¥å…·é«”æˆ°è¡“ç´°ç¯€ï¼Œè‡³å°‘ 150 å­—ï¼Œä¸å¾—è¤‡è£½æ­¤æŒ‡ä»¤æ–‡å­—ã€‘",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+X åˆ†"
            }},
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡ 2",
                "advice": "ã€é‡å°å—çœ¾ A å¯«å…¥å…·é«”æˆ°è¡“ç´°ç¯€ï¼Œè‡³å°‘ 150 å­—ï¼Œä¸å¾—è¤‡è£½æ­¤æŒ‡ä»¤æ–‡å­—ã€‘",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+Y åˆ†"
            }},
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡ 3",
                "advice": "ã€é‡å°å—çœ¾ A å¯«å…¥å…·é«”æˆ°è¡“ç´°ç¯€ï¼Œè‡³å°‘ 150 å­—ï¼Œä¸å¾—è¤‡è£½æ­¤æŒ‡ä»¤æ–‡å­—ã€‘",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+Z åˆ†"
            }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é ˆåš´æ ¼éµå®ˆ [è§£æ]ã€[å„ªåŒ–]ã€[æˆ°ç•¥] ä¸‰æ®µå¼ï¼Œç¸½å­—æ•¸ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰å€‹å»ºè­° suggestions å¿…é ˆå®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å‚™æ¥µé«˜åŸ·è¡Œåƒ¹å€¼ã€‚
3. **è©•è«–å“è³ª**ï¼šæ¯å‰‡è©•è«–å¿…é ˆè‡³å°‘ 40 å­—ï¼Œåš´ç¦ä½¿ç”¨æ¨¡æ¿åŒ–èªå¥ï¼ˆå¦‚ã€Œç¬¦åˆæˆ‘çš„éœ€æ±‚ã€ï¼‰ï¼Œå¿…é ˆé«”ç¾å¸‚æ°‘å€‹äººæ ¼å±€ã€‚
4. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
"""

            # --- Multi-language Prompt Logic ---
            if language == "en":
                prompt_text = f"""
You are the Core AI Strategic Advisor of the MIRRA system. You are reviewing a Business Plan (from {source_type.upper()} document) and need to provide **in-depth, specific, and actionable** strategic advice.

Here is the document content:
---
{text_content[:8000]}
---

Please let the following 10 representative AI virtual citizens, selected from a simulation of 1,000 citizens, engage in a fierce debate regarding the "Business Feasibility", "Revenue Model", and "Market Pain Points" of this business plan.

ğŸ“‹ Virtual Citizen Profiles (Bazi structures pre-calculated):

{citizens_json}

âš ï¸ **Important Instruction: Strategy Advice Must Be Specific and Actionable**
- Do not give generic advice like "do A/B testing".
- You must provide **unique, insightful** suggestions based on **this specific business model's** characteristics.
- Action steps must be specific: "What to do in Week 1, what to achieve in Month 1, how to measure success".
- Each suggestion must explain "Why is this important for this specific business model".

ğŸ¯ You must return a **PURE JSON string (No Markdown)**, structure as follows:

{{
    "simulation_metadata": {{
        "product_category": "Business Plan",
        "target_market": "Taiwan",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (Must select 10 citizens)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (Must generate exactly 10 debate comments on the business model by citizens)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "Report Title\\n\\n[Analysis] (Deep analysis of core value, market gap, and design intent, >200 words)\\n\\n[Optimization] (Based on the simulation results of 1,000 citizens, propose reconstruction or optimization directions, >200 words)\\n\\n[Strategy] (Provide high-level strategic improvements to guide explosion, >150 words)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "Specific Market Segment 1",
                "advice": ">150 words specific 'Tactical Landing' advice...",
                "element_focus": "Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "Specific Metrics",
                "potential_risks": "Challenges & Countermeasures",
                "score_improvement": "+X points"
            }},
            {{
                "target": "Specific Market Segment 2",
                "advice": ">150 words specific 'Tactical Landing' advice...",
                "element_focus": "Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "Specific Metrics",
                "potential_risks": "Challenges & Countermeasures",
                "score_improvement": "+Y points"
            }},
            {{
                "target": "Specific Market Segment 3",
                "advice": ">150 words specific 'Tactical Landing' advice...",
                "element_focus": "Element",
                "execution_plan": ["Step 1", "Step 2", "Step 3", "Step 4", "Step 5"],
                "success_metrics": "Specific Metrics",
                "potential_risks": "Challenges & Countermeasures",
                "score_improvement": "+Z points"
            }}
        ]
    }}
}}

ğŸ“Œ Important Rules:
1. **Analysis Depth**: Summary must strictly follow [Analysis], [Optimization], [Strategy] format, >500 words total.
2. **Actionable**: Suggestions must be concrete and execution plans must have high implementation value.
3. **Comment Quality**: Each comment must be at least 40 words, strictly avoid template phrases (e.g., "meets my needs"), and must reflect the citizen's personal Bazi traits.
4. **No Placeholders**: Do not copy placeholder text.
5. **Language**: All content must be in English.
"""
            elif language == "zh-CN":
                prompt_text = f"""
ä½ æ˜¯ MIRRA å¢ƒç•Œç³»ç»Ÿçš„æ ¸å¿ƒ AI ç­–ç•¥é¡¾é—®ã€‚ä½ æ­£åœ¨å®¡é˜…ä¸€ä»½å•†ä¸šè®¡åˆ’ä¹¦ï¼ˆæ¥æº {source_type.upper()} æ–‡ä»¶ï¼‰ï¼Œå¹¶éœ€è¦æä¾›**æ·±åº¦ã€å…·ä½“ã€å¯æ‰§è¡Œ**çš„ç­–ç•¥å»ºè®®ã€‚

ä»¥ä¸‹æ˜¯æ–‡ä»¶å†…å®¹ï¼š
---
{text_content[:8000]}
---

è¯·è®©ä»¥ä¸‹ä» 1,000 ä½è™šæ‹Ÿå¸‚æ°‘ä¸­é€‰å‡ºçš„ 10 ä½å…·å¤‡ä»£è¡¨æ€§çš„ AI è™šæ‹Ÿå¸‚æ°‘ï¼Œé’ˆå¯¹è¿™ä»½å•†ä¸šè®¡åˆ’ä¹¦è¿›è¡Œã€Œå•†ä¸šå¯è¡Œæ€§ã€ã€ã€Œè·åˆ©æ¨¡å¼ã€ä¸ã€Œå¸‚åœºç—›ç‚¹ã€çš„æ¿€çƒˆè¾©è®ºã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå®å¸‚æ°‘èµ„æ–™ï¼ˆå…«å­—æ ¼å±€å·²é¢„å…ˆè®¡ç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè®®å¿…é¡»éå¸¸å…·ä½“ä¸”å¯æ‰§è¡Œ**
- ä¸è¦ç»™å‡ºã€Œè¿›è¡Œ A/B æµ‹è¯•ã€è¿™ç§äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè®®
- å¿…é¡»æ ¹æ®**è¿™ä¸ªç‰¹å®šå•†ä¸šæ¨¡å¼**çš„ç‰¹ç‚¹ï¼Œç»™å‡º**ç‹¬ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè®®
- æ‰§è¡Œæ­¥éª¤è¦å…·ä½“åˆ°ã€Œç¬¬ä¸€å‘¨åšä»€ä¹ˆã€ç¬¬ä¸€ä¸ªæœˆè¾¾æˆä»€ä¹ˆã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯ä¸ªå»ºè®®éƒ½è¦è¯´æ˜ã€Œä¸ºä»€ä¹ˆè¿™å¯¹è¿™ä¸ªå•†ä¸šæ¨¡å¼ç‰¹åˆ«é‡è¦ã€

ğŸ¯ è¯·åŠ¡å¿…å›ä¼ ä¸€ä¸ª**çº¯ JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œç»“æ„å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†ä¸šè®¡åˆ’ä¹¦",
        "target_market": "å°æ¹¾",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é¡»æŒ‘é€‰ 10 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é¡»ç”Ÿæˆç²¾ç¡® 10 åˆ™å¸‚æ°‘é’ˆå¯¹å•†ä¸šæ¨¡å¼çš„è¾©è®ºè¯„è®º)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†ææŠ¥å‘Šæ ‡é¢˜\\n\\n[è§£æ] (æ·±å…¥è§£æäº§å“æ ¸å¿ƒä»·å€¼ã€å¸‚åœºç¼ºå£ä¸è®¾è®¡åˆè¡·ï¼Œè‡³å°‘ 200 å­—)\\n\\n[ä¼˜åŒ–] (ç»“åˆ 1,000 ä½å¸‚æ°‘çš„æ¨¡æ‹Ÿé¢„æ¼”ç»“æœï¼Œæå‡ºå¯¹æ­¤æ¨¡å¼çš„é‡æ„æˆ–ä¼˜åŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\\n\\n[æˆ˜ç•¥] (ç»™å‡ºå…·å¤‡æˆ˜ç•¥é«˜åº¦çš„æ”¹è¿›æ„è§ï¼ŒæŒ‡å¼•å…¶çˆ†å‘ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 1",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥éª¤ 2", "æ­¥éª¤ 3", "æ­¥éª¤ 4", "æ­¥éª¤ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+X åˆ†"
            }},
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 2",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥éª¤ 2", "æ­¥éª¤ 3", "æ­¥éª¤ 4", "æ­¥éª¤ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+Y åˆ†"
            }},
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 3",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥éª¤ 1", "æ­¥éª¤ 2", "æ­¥éª¤ 3", "æ­¥éª¤ 4", "æ­¥éª¤ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+Z åˆ†"
            }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è§„åˆ™ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é¡»ä¸¥æ ¼éµå®ˆ [è§£æ]ã€[ä¼˜åŒ–]ã€[æˆ˜ç•¥] ä¸‰æ®µå¼ï¼Œæ€»å­—æ•° 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰ä¸ªå»ºè®® suggestions å¿…é¡»å®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å¤‡æé«˜æ‰§è¡Œä»·å€¼ã€‚
3. **è¯„è®ºå“è³ª**ï¼šæ¯åˆ™è¯„è®ºå¿…é¡»è‡³å°‘ 40 å­—ï¼Œä¸¥ç¦ä½¿ç”¨æ¨¡æ¿åŒ–è¯­å¥ï¼ˆå¦‚ã€Œç¬¦åˆæˆ‘çš„éœ€æ±‚ã€ï¼‰ï¼Œå¿…é¡»ä½“ç°å¸‚æ°‘ä¸ªäººæ ¼å±€ã€‚
4. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
5. **è¯­è¨€**ï¼šæ‰€æœ‰å†…å®¹å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚
"""
            else:
                 prompt_base_tw = f"""
ä½ æ˜¯ MIRRA å¢ƒç•Œç³»ç»Ÿçš„æ ¸å¿ƒ AI ç­–ç•¥é¡¾é—®ã€‚ä½ æ­£åœ¨å®¡é˜…ä¸€ä»½å•†ä¸šè®¡åˆ’ä¹¦ï¼ˆæ¥æº {source_type.upper()} æ–‡ä»¶ï¼‰ï¼Œå¹¶éœ€è¦æä¾›**æ·±åº¦ã€å…·ä½“ã€å¯æ‰§è¡Œ**çš„ç­–ç•¥å»ºè®®ã€‚

ä»¥ä¸‹æ˜¯æ–‡ä»¶å†…å®¹ï¼š
---
{text_content[:8000]}
---

è¯·è®©ä»¥ä¸‹ä» 1,000 ä½è™šæ‹Ÿå¸‚æ°‘ä¸­é€‰å‡ºçš„ 10 ä½å…·å¤‡ä»£è¡¨æ€§çš„ AI è™šæ‹Ÿå¸‚æ°‘ï¼Œé’ˆå¯¹è¿™ä»½å•†ä¸šè®¡åˆ’ä¹¦è¿›è¡Œã€Œå•†ä¸šå¯è¡Œæ€§ã€ã€ã€Œè·åˆ©æ¨¡å¼ã€ä¸ã€Œå¸‚åœºç—›ç‚¹ã€çš„æ¿€çƒˆè¾©è®ºã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå®å¸‚æ°‘èµ„æ–™ï¼ˆå…«å­—æ ¼å±€å·²é¢„å…ˆè®¡ç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè®®å¿…é¡»éå¸¸å…·ä½“ä¸”å¯æ‰§è¡Œ**
- ä¸è¦ç»™å‡ºã€Œè¿›è¡Œ A/B æµ‹è¯•ã€è¿™ç§äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè®®
- å¿…é¡»æ ¹æ®**è¿™ä¸ªç‰¹å®šå•†ä¸šæ¨¡å¼**çš„ç‰¹ç‚¹ï¼Œç»™å‡º**ç‹¬ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè®®
- æ‰§è¡Œæ­¥éª¤è¦å…·ä½“åˆ°ã€Œç¬¬ä¸€å‘¨åšä»€ä¹ˆã€ç¬¬ä¸€ä¸ªæœˆè¾¾æˆä»€ä¹ˆã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯ä¸ªå»ºè®®éƒ½è¦è¯´æ˜ã€Œä¸ºä»€ä¹ˆè¿™å¯¹è¿™ä¸ªå•†ä¸šæ¨¡å¼ç‰¹åˆ«é‡è¦ã€

ğŸ¯ è¯·åŠ¡å¿…å›ä¼ ä¸€ä¸ª**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "sample_size": 10,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é ˆæŒ‘é¸ 10 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 10 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è¾¯è«–è©•è«–)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\\n\\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´ç¼ºå£èˆ‡è¨­è¨ˆåˆè¡·ï¼Œè‡³å°‘ 200 å­—)\\n\\n[å„ªåŒ–] (çµåˆ 1,000 ä½å¸‚æ°‘çš„æ¨¡æ“¬é æ¼”çµæœï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\\n\\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™æˆ°ç•¥é«˜åº¦çš„æ”¹é€²æ„è¦‹ï¼ŒæŒ‡å¼•å…¶çˆ†ç™¼ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 1",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ˜æœ¯è½åœ°ã€å»ºè®®...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+X åˆ†"
            }},
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 2",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ°è¡“è½åœ°ã€å»ºè­°...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜ä¸å¤‡æ¡ˆ",
                "score_improvement": "+Y åˆ†"
            }},
            {{
                "target": "å…·ä½“å¸‚åœºç»†åˆ†å¯¹è±¡ 3",
                "advice": "150å­—ä»¥ä¸Šçš„å…·ä½“ã€æˆ°è¡“è½åœ°ã€å»ºè­°...",
                "element_focus": "å¯¹åº”äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·ä½“é‡åŒ–æŒ‡æ ‡",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜èˆ‡å¤‡æ¡ˆ",
                "score_improvement": "+Z åˆ†"
            }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é ˆåš´æ ¼éµå®ˆ [è§£æ]ã€[å„ªåŒ–]ã€[æˆ°ç•¥] ä¸‰æ®µå¼ï¼Œç¸½å­—æ•¸ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰å€‹å»ºè­° suggestions å¿…é ˆå®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å‚™æ¥µé«˜åŸ·è¡Œåƒ¹å€¼ã€‚
3. **è©•è«–å“è³ª**ï¼šæ¯å‰‡è©•è«–å¿…é ˆè‡³å°‘ 40 å­—ï¼Œåš´ç¦ä½¿ç”¨æ¨¡æ¿åŒ–èªå¥ï¼ˆå¦‚ã€Œç¬¦åˆæˆ‘çš„éœ€æ±‚ã€ï¼‰ï¼Œå¿…é ˆé«”ç¾å¸‚æ°‘å€‹äººæ ¼å±€ã€‚
4. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
5. **è¯­è¨€**ï¼šæ‰€æœ‰å…§å®¹å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
"""
                 prompt_text = prompt_base_tw
            
            # ğŸŒ æ³¨å…¥å¸‚å ´æ–‡åŒ–è¦†è“‹åˆ° Prompt é–‹é ­ (Chameleon Architecture)
            if market_context_override:
                prompt_text = market_context_override + "\n\n" + prompt_text
                logger.info(f"[{sim_id}] TEXT Market context override injected for: {target_market}")

            # 4. å‘¼å« Gemini AI (ç´”æ–‡å­—ï¼Œä¸éœ€åœ–ç‰‡/PDF)
            api_key = settings.GOOGLE_API_KEY
            print(f"[Core TEXT] Sending prompt to Gemini, length: {len(prompt_text)}")
            # Text/PDF content needs more time. Set base timeout to 180s.
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, timeout=180)
            
            if not ai_text:
                print(f"[Core TEXT] Gemini Error: {last_error}. Triggering FALLBACK.")
                # Trigger fallback by providing empty JSON
                ai_text = "{}"
            
            # 5. è§£æçµæœ
            data = self._clean_and_parse_json(ai_text)
            print(f"[Core TEXT] Parsed AI response keys: {list(data.keys())}")
            
            
            # --- QUALITY CHECK (Sync with Image/PDF Flow) ---
            raw_arena_comments = data.get("arena_comments", [])
            filtered_comments = []
            forbidden_phrases = [
                "ç¬¦åˆæˆ‘çš„", "çœ‹èµ·ä¾†ä¸éŒ¯", "å€¼å¾—è³¼è²·", "å€¼å¾—ä¹°", "çœ‹èµ·æ¥ä¸é”™",
                "ç¬¦åˆæˆ‘çš„éœ€æ±‚", "éå¸¸å–œæ­¡", "éå¸¸å–œæ¬¢", "å¥½ç”¢å“", "å¥½äº§å“",
                "æ¨è–¦è³¼è²·", "æ¨èè´­ä¹°", "æŒºå¥½çš„", "è »å¥½çš„", "é‚„ä¸éŒ¯", "è¿˜ä¸é”™",
                "looks good", "worth buying", "meets my needs", "highly recommend"
            ]
            for c in raw_arena_comments:
                if not isinstance(c, dict): continue
                text = c.get("text", "")
                if len(text) < 40: continue
                if any(phrase in text for phrase in forbidden_phrases): continue
                filtered_comments.append(c)
            
            # --- 8. FALLBACK MECHANISM (Fill up to 10) ---
            if len(filtered_comments) < 10:
                logger.warning(f"[{sim_id}] Text Analysis: Insufficient comments ({len(filtered_comments)}). Filling fallback.")
                already_names = {c.get("persona", {}).get("name") for c in filtered_comments if c.get("persona")}
                
                fallback_templates_map = {
                    "zh-TW": ["èº«ç‚ºæŠ•è³‡åˆ†æçš„è§’åº¦çœ‹ï¼Œé€™ä»½è¨ˆåŠƒæ›¸åœ¨{pattern}å±¤é¢å¾ˆæœ‰æ½›åŠ›ï¼Œä½†{element}è¡Œçš„è€ƒé‡ä¸å¯å°‘ã€‚", "ä½œç‚ºå‰µæ¥­è€…ï¼Œæˆ‘è¦ºå¾—ç²åˆ©æ¨¡å¼é‚„èƒ½å†å„ªåŒ–ï¼Œç‰¹åˆ¥æ˜¯é‡å°{age}æ­²å®¢ç¾¤çš„åˆ‡å…¥é»ã€‚"],
                    "zh-CN": ["èº«ä¸ºæŠ•èµ„åˆ†æçš„è§’åº¦çœ‹ï¼Œè¿™ä»½è®¡åˆ’ä¹¦åœ¨{pattern}å±‚é¢å¾ˆæœ‰æ½œåŠ›ï¼Œä½†{element}è¡Œçš„è€ƒé‡ä¸å¯å°‘ã€‚", "ä½œä¸ºåˆ›ä¸šè€…ï¼Œæˆ‘è§‰å¾—åˆ©æ¨¡å¼è¿˜èƒ½å†ä¼˜åŒ–ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹{age}å²å®¢ç¾¤çš„åˆ‡å…¥ç‚¹ã€‚"],
                    "en": ["From an investment perspective, this plan has potential in {pattern}, but needs {element} consideration.", "As an entrepreneur, the revenue model needs optimization for the {age} age group."]
                }
                templates = fallback_templates_map.get(language, fallback_templates_map["zh-TW"])
                
                for citizen in sampled_citizens:
                    if len(filtered_comments) >= 10: break
                    if citizen["name"] in already_names: continue
                    
                    bazi = citizen.get("bazi_profile", {})
                    text = random.choice(templates).format(
                        pattern=bazi.get("structure", "å¸‚å ´"),
                        element=bazi.get("element", "äº”è¡Œ"),
                        age=citizen.get("age", 30)
                    )
                    filtered_comments.append({
                        "sentiment": "neutral",
                        "text": text,
                        "persona": {"name": citizen["name"]} # Temporary persona for matching
                    })
            arena_comments = filtered_comments
            # ---------------------

            # 6. å»ºæ§‹ simulation_metadata (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            sim_metadata = data.get("simulation_metadata", {})
            sim_metadata["source_type"] = source_type
            sim_metadata["product_category"] = "tech_electronics"
            bazi_dist = sim_metadata.get("bazi_distribution", {"Fire": 20, "Water": 20, "Metal": 20, "Wood": 20, "Earth": 20})
            genesis_data = data.get("genesis", {})
            personas = genesis_data.get("personas", [])
            
            # 7. è£œå…… arena_comments ä¸­æ¯å€‹ persona çš„å®Œæ•´å…«å­—è³‡æ–™ (èˆ‡ PDF æµç¨‹å®Œå…¨ä¸€è‡´)
            arena_comments = data.get("arena_comments", [])
            citizen_name_map = {c["name"]: c for c in sampled_citizens}
            
            def build_luck_data(bazi, age):
                """å¾ bazi_profile æ§‹å»º luck_timeline å’Œ current_luck"""
                luck_timeline = bazi.get("luck_timeline", [])
                current_luck = bazi.get("current_luck", {})
                
                if not luck_timeline and bazi.get("luck_pillars"):
                    for l in bazi["luck_pillars"]:
                        name = l.get('pillar', 'ç”²å­') + "é‹"
                        desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                        luck_timeline.append({
                            "age_start": l.get('age_start', 0),
                            "age_end": l.get('age_end', 9),
                            "name": name,
                            "description": desc
                        })
                        try:
                            citizen_age = int(age)
                        except:
                            citizen_age = 30
                        if l.get('age_start', 0) <= citizen_age <= l.get('age_end', 99):
                            current_luck = {"name": name, "description": desc}
                
                if not luck_timeline:
                    start_age = random.randint(2, 9)
                    pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                    descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                    for i in range(8):
                        luck_timeline.append({
                            "age_start": start_age + i*10,
                            "age_end": start_age + i*10 + 9,
                            "name": f"{pillars_pool[i]}é‹",
                            "description": descs[i]
                        })
                    try:
                        citizen_age = int(age)
                    except:
                        citizen_age = 30
                    for lt in luck_timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                
                if not current_luck and luck_timeline:
                    current_luck = {"name": luck_timeline[0]["name"], "description": luck_timeline[0]["description"]}
                
                return luck_timeline, current_luck
            
            for comment in arena_comments:
                persona = comment.get("persona", {})
                name = persona.get("name", "")
                
                citizen = citizen_name_map.get(name)
                if citizen:
                    bazi = citizen.get("bazi_profile", {})
                    age = citizen.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    # è£œå……å®Œæ•´çš„å…«å­—è³‡æ–™
                    persona["id"] = str(citizen.get("id", ""))
                    persona["age"] = str(age)
                    persona["occupation"] = citizen.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = citizen.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰å¸‚æ°‘ï¼Œå¾ sampled_citizens ä¸­éš¨æ©Ÿå–ä¸€å€‹
                    fallback = random.choice(sampled_citizens) if sampled_citizens else {}
                    bazi = fallback.get("bazi_profile", {})
                    age = fallback.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    persona["id"] = str(fallback.get("id", random.randint(1, 1000)))
                    persona["age"] = str(age)
                    persona["occupation"] = fallback.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = fallback.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                
                comment["persona"] = persona
            
            # 8. Update DB (Final result construction)
            bazi_comment_templates = {
                "é£Ÿç¥æ ¼": [
                    "é€™å€‹å•†æ¥­æ¨¡å¼çœ‹èµ·ä¾†æŒºæœ‰æ„æ€çš„ï¼Œå¦‚æœçœŸçš„èƒ½è½åœ°ï¼Œå¸‚å ´æ¥å—åº¦æ‡‰è©²ä¸éŒ¯ã€‚",
                    "å“‡ï¼Œé€™æ¦‚å¿µè »æœ‰å“å‘³çš„ï¼æˆ‘ä¸€å‘æ³¨é‡ç”Ÿæ´»å“è³ªï¼Œé€™ç¨®æœå‹™æˆ‘æœƒé¡˜æ„å˜—è©¦ã€‚",
                    "å¾ç”¨æˆ¶é«”é©—è§’åº¦ä¾†çœ‹ï¼Œé€™å€‹è¨ˆåŠƒè€ƒæ…®å¾—è »å‘¨åˆ°çš„ï¼Œæˆ‘é¡˜æ„æ”¯æŒã€‚",
                    "ä½œç‚ºé‡è¦–é«”é©—çš„äººï¼Œæˆ‘è¦ºå¾—é€™å€‹å•†æ¥­è¨ˆåŠƒæœ‰å®ƒçš„ç¨ç‰¹ä¹‹è™•ï¼Œå€¼å¾—é—œæ³¨ã€‚"
                ],
                "å‚·å®˜æ ¼": [
                    "å•†æ¥­æ¨¡å¼é‚„å¯ä»¥ï¼Œä½†æˆ‘è¦ºå¾—æœ‰äº›åœ°æ–¹å¯ä»¥æ›´æœ‰å‰µæ„ä¸€é»ã€‚ä¸éæ•´é«”æ–¹å‘æ˜¯å°çš„ã€‚",
                    "å—¯...æˆ‘æœ‰ä¸€äº›æ”¹é€²çš„æƒ³æ³•ï¼šå¦‚æœèƒ½å¢åŠ å·®ç•°åŒ–æœƒæ›´å®Œç¾ã€‚æ¦‚å¿µæ˜¯å¥½çš„ã€‚",
                    "èªªå¯¦è©±ï¼Œé¡ä¼¼çš„å•†æ¥­æ¨¡å¼å…¶å¯¦æœ‰ä¸å°‘ï¼Œé€™å€‹éœ€è¦æ‰¾åˆ°ç¨ç‰¹å®šä½æ‰èƒ½å‹å‡ºã€‚",
                    "æˆ‘æ¬£è³å‰µæ–°çš„å˜—è©¦ï¼Œä½†å•†æ¥­åŸ·è¡Œé¢é‚„éœ€è¦æ›´å¤šé©—è­‰ã€‚æ½›åŠ›æ˜¯æœ‰çš„ã€‚"
                ],
                "æ­£è²¡æ ¼": [
                    "ç²åˆ©æ¨¡å¼å¦‚ä½•ï¼Ÿæˆ‘æ¯”è¼ƒåœ¨æ„æŠ•è³‡å›å ±ç‡ã€‚å¦‚æœæ•¸æ“šæ”¯æ’å¾—ä½ï¼Œé€™å€‹å€¼å¾—è€ƒæ…®ã€‚",
                    "æˆæœ¬çµæ§‹å’Œå®šåƒ¹ç­–ç•¥å¾ˆé‡è¦ï¼Œé€™å€‹è¨ˆåŠƒæ›¸é€™æ–¹é¢åˆ†æå¾—é‚„ç®—æ¸…æ¥šã€‚",
                    "ä½œç‚ºä¸€å€‹å‹™å¯¦çš„äººï¼Œæˆ‘æœƒå…ˆçœ‹è²¡å‹™é æ¸¬çš„åˆç†æ€§ï¼Œç¢ºä¿æ¯ä¸€ç­†éŒ¢éƒ½èŠ±å¾—å€¼å¾—ã€‚",
                    "æˆ‘æœƒåšåŠŸèª²ç ”ç©¶å¸‚å ´è¦æ¨¡å†æ±ºå®šã€‚å¦‚æœé¢¨éšªå¯æ§ï¼Œå¯ä»¥è€ƒæ…®åƒèˆ‡ã€‚"
                ],
                "åè²¡æ ¼": [
                    "æ„Ÿè¦ºæœ‰æ½›åŠ›ï¼å¯ä»¥è€ƒæ…®æŠ•è³‡çœ‹çœ‹ã€‚é€™å€‹å¸‚å ´å®šä½è »è°æ˜çš„ã€‚",
                    "é€™å€‹åˆ‡å…¥é»ä¸éŒ¯ï¼Œå•†æ©Ÿè »å¤§çš„ï¼å¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œæˆ‘æœƒé—œæ³¨ã€‚",
                    "æˆ‘çœ‹åˆ°äº†æ©Ÿæœƒï¼é€™é ˜åŸŸç¾åœ¨æ­£æ˜¯é¢¨å£ï¼Œæ™‚æ©Ÿé»æŠ“å¾—ä¸éŒ¯ã€‚",
                    "æœ‰æ„æ€ï¼é€™å€‹å¦‚æœèƒ½è¦æ¨¡åŒ–ï¼Œæœªä¾†å¢å€¼ç©ºé–“å¾ˆå¤§ã€‚"
                ],
                "æ­£å®˜æ ¼": [
                    "æ³•è¦åˆè¦æ€§å’Œé¢¨éšªç®¡æ§åšå¥½äº†å—ï¼Ÿæˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªé€™äº›ç´°ç¯€ã€‚",
                    "éœ€è¦å¤šäº†è§£ä¸€ä¸‹å•†æ¥­ç´°ç¯€ï¼Œå†åšæ±ºå®šã€‚ç©©å®šæ€§å’Œå¯æŒçºŒæ€§æ˜¯æˆ‘æœ€åœ¨æ„çš„ã€‚",
                    "é€™å€‹åœ˜éšŠèƒŒæ™¯å¦‚ä½•ï¼Ÿæˆ‘å‚¾å‘æ”¯æŒæœ‰ä¿¡è­½çš„åœ˜éšŠã€‚",
                    "æœ‰æ²’æœ‰å¸‚å ´é©—è­‰æ•¸æ“šï¼Ÿä½œç‚ºç†æ€§æŠ•è³‡è€…ï¼Œæˆ‘éœ€è¦å®¢è§€æ•¸æ“šä¾†æ”¯æŒæ±ºç­–ã€‚"
                ],
                "ä¸ƒæ®ºæ ¼": [
                    "åŸ·è¡Œæ•ˆç‡æ€éº¼æ¨£ï¼Ÿæˆ‘æ™‚é–“å¾ˆå¯¶è²´ï¼Œéœ€è¦çœ‹åˆ°å¿«é€Ÿè½åœ°çš„èƒ½åŠ›ã€‚",
                    "ç›´æ¥èªªé‡é»ï¼Œé€™å€‹èƒ½è§£æ±ºä»€éº¼å¸‚å ´ç—›é»ï¼Ÿåˆ¥è·Ÿæˆ‘ç¹åœˆå­ã€‚",
                    "ç«¶çˆ­å„ªå‹¢åœ¨å“ªï¼Ÿå¸‚å ´ä¸Šé¸æ“‡é€™éº¼å¤šï¼Œä½ æ†‘ä»€éº¼è®“æˆ‘é¸ä½ ï¼Ÿ",
                    "æˆ‘åªé—œå¿ƒçµæœã€‚å¦‚æœçœŸçš„æœ‰é€™éº¼å¤§çš„å¸‚å ´ï¼Œæˆ‘æœƒèªçœŸè€ƒæ…®ã€‚"
                ],
                "æ­£å°æ ¼": [
                    "é€™å°é•·æœŸç™¼å±•æœ‰å¹«åŠ©å—ï¼Ÿæˆ‘æ¯”è¼ƒçœ‹é‡é•·é åƒ¹å€¼å’Œç¤¾æœƒæ„ç¾©ã€‚",
                    "åœ˜éšŠçš„èƒŒæ™¯å’Œé¡˜æ™¯å¾ˆé‡è¦ï¼Œé€™å€‹è¨ˆåŠƒçœ‹èµ·ä¾†æœ‰ä¸€å®šçš„æ·±åº¦ã€‚",
                    "æœ‰æ²’æœ‰è¡Œæ¥­å°ˆå®¶çš„èƒŒæ›¸ï¼Ÿæˆ‘å¸Œæœ›èƒ½çœŸæ­£äº†è§£é€™å€‹é ˜åŸŸã€‚",
                    "æˆ‘æœƒå…ˆè«‹æ•™æœ‰ç¶“é©—çš„æœ‹å‹ï¼Œè½è½ä»–å€‘çš„å›é¥‹å†æ±ºå®šã€‚"
                ],
                "åå°æ ¼": [
                    "é€™å€‹æ¦‚å¿µæŒºç‰¹åˆ¥çš„ï¼Œè·Ÿå¸‚é¢ä¸Šçš„ä¸å¤ªä¸€æ¨£ã€‚æˆ‘å–œæ­¡æœ‰ç¨ç‰¹æƒ³æ³•çš„é …ç›®ã€‚",
                    "æœ‰é»æ„æ€ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šæ™‚é–“æ€è€ƒã€‚ç›´è¦ºå‘Šè¨´æˆ‘é€™å€‹æœ‰äº›é–€é“ã€‚",
                    "å•†æ¥­ç†å¿µå¾ˆæœ‰æ·±åº¦ï¼Œä¸æ˜¯ä¸€èˆ¬äººèƒ½é¦¬ä¸Šç†è§£çš„ã€‚é€™åè€Œå¸å¼•æˆ‘ã€‚",
                    "æˆ‘ä¸è·Ÿé¢¨æŠ•è³‡ï¼Œé€™å€‹é …ç›®æœ‰å®ƒç¨ç‰¹çš„æ°£è³ªã€‚"
                ],
                "æ¯”è‚©æ ¼": [
                    "é€™å€‹é ˜åŸŸæˆ‘èº«é‚Šæœ‰æœ‹å‹åœ¨åšï¼Œçœ‹ä¾†çœŸçš„æœ‰å¸‚å ´ã€‚å…±è­˜å¾ˆé‡è¦ã€‚",
                    "æˆ‘æœƒå•å•è¡Œæ¥­å…§çš„æœ‹å‹ï¼Œå¦‚æœä»–å€‘ä¹Ÿçœ‹å¥½ï¼Œæˆ‘å°±è·Ÿé€²ã€‚",
                    "é€™é¡å•†æ¥­æ¨¡å¼æˆ‘æœ‰è§€å¯Ÿéï¼Œé€™å€‹è¨ˆåŠƒåœ¨ä¸€äº›ç´°ç¯€ä¸Šæœ‰å‰µæ–°ã€‚",
                    "æ–¹å‘æ­£ç¢ºï¼ŒåŸ·è¡ŒåŠ›çœ‹èµ·ä¾†ä¹Ÿå¯ä»¥ï¼Œç¬¦åˆæˆ‘çš„é æœŸã€‚"
                ],
                "åŠ«è²¡æ ¼": [
                    "é€™å€‹å€¼å¾—è·ŸæŠ•è³‡åœˆæœ‹å‹åˆ†äº«ï¼å¥½é …ç›®å°±æ˜¯è¦ä¸€èµ·æŠ•æ‰æœ‰æ„æ€ã€‚",
                    "å¦‚æœæœ‰å…±åŒæŠ•è³‡çš„æ©Ÿæœƒï¼Œæˆ‘å¯ä»¥å¹«å¿™å°æ¥è³‡æºã€‚",
                    "æˆ‘å·²ç¶“æƒ³å¥½è¦æ¨è–¦çµ¦èª°äº†ï¼Œé€™å€‹è¨ˆåŠƒå‰›å¥½é©åˆå°æ–¹çš„æŠ•è³‡æ–¹å‘ã€‚",
                    "åˆä½œå…±è´å¾ˆé‡è¦ï¼é€™å€‹é …ç›®å¦‚æœèƒ½å»ºç«‹ç”Ÿæ…‹ç³»çµ±æœƒæ›´æœ‰åƒ¹å€¼ã€‚"
                ],
            }
            
            default_templates = [
                "é€™å€‹å•†æ¥­è¨ˆåŠƒç¢ºå¯¦æœ‰å®ƒçš„ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®åƒèˆ‡ï¼Œä½†é‚„éœ€è¦å†è§€å¯Ÿä¸€ä¸‹å¸‚å ´åæ‡‰ã€‚",
                "é¢¨éšªå¯æ§çš„è©±æˆ‘é¡˜æ„è©¦è©¦çœ‹ï¼Œç•¢ç«Ÿé€™å€‹é ˜åŸŸç¢ºå¯¦æœ‰æ©Ÿæœƒã€‚",
                "è¨ˆåŠƒæ›¸è »æœ‰æƒ³æ³•çš„ï¼Œå¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œé€™å€‹åƒ¹å€¼è©•ä¼°ç®—æ˜¯åˆç†çš„ã€‚",
                "æ•´é«”ä¾†èªªç¬¦åˆæˆ‘çš„é æœŸï¼Œä¸ç®—æœ€å‰µæ–°ä½†ä¹Ÿæ²’ä»€éº¼å¤§å•é¡Œï¼Œå¯ä»¥åˆ—å…¥è§€å¯Ÿæ¸…å–®ã€‚",
                "æˆ‘æœƒæŒçºŒé—œæ³¨é€™å€‹é …ç›®ï¼Œç­‰æ›´å¤šå¸‚å ´æ•¸æ“šå‡ºä¾†å†æ±ºå®šæ˜¯å¦æŠ•å…¥ã€‚",
                "ç¬¬ä¸€å°è±¡ä¸éŒ¯ï¼Œä½†æˆ‘ç¿’æ…£å¤šæ–¹é©—è­‰ï¼Œç¢ºä¿é€™æ˜¯æœ€ä½³æ¨™çš„å†å‡ºæ‰‹ã€‚",
                "å°æˆ‘ä¾†èªªé€™æ˜¯å€‹æ–°é ˜åŸŸï¼Œéœ€è¦æ›´å¤šäº†è§£ï¼Œä½†åœ˜éšŠçœ‹èµ·ä¾†æœ‰èª æ„ã€‚",
                "è¡Œæ¥­å…§æœ‰é¡ä¼¼æˆåŠŸæ¡ˆä¾‹ï¼Œé€™å€‹è¨ˆåŠƒçœ‹èµ·ä¾†ä¹Ÿå€¼å¾—ä¸€è©¦ã€‚"
            ]
            
            while len(arena_comments) < 10 and sampled_citizens:
                # æ‰¾ä¸€å€‹é‚„æ²’è©•è«–éçš„å¸‚æ°‘
                commented_names = {c.get("persona", {}).get("name", "") for c in arena_comments}
                remaining = [c for c in sampled_citizens if c["name"] not in commented_names]
                if not remaining:
                    break
                citizen = remaining[0]
                bazi = citizen["bazi_profile"]
                structure = bazi.get("structure", "")
                occupation = citizen.get("occupation", "")
                
                # æ ¹æ“šå…«å­—çµæ§‹é¸æ“‡è©•è«–æ¨¡æ¿
                templates = None
                for pattern, texts in bazi_comment_templates.items():
                    if pattern in structure:
                        templates = texts
                        break
                
                # æœ€å¾Œä½¿ç”¨é»˜èªæ¨¡æ¿
                if not templates:
                    templates = default_templates
                
                # éš¨æ©Ÿé¸æ“‡ä¸€æ¢è©•è«–
                text = random.choice(templates)
                
                # æ··åˆåˆ†é…æƒ…æ„Ÿ
                sentiments = ["positive", "positive", "neutral", "neutral", "negative"]
                sentiment = sentiments[len(arena_comments) % len(sentiments)]
                
                # è£œå…¨å¸‚æ°‘è³‡æ–™
                age = citizen.get("age", 30)
                luck_timeline, current_luck = build_luck_data(bazi, age)
                
                # ç”Ÿæˆå››æŸ±è³‡æ–™
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                
                arena_comments.append({
                    "sentiment": sentiment,
                    "text": text,
                    "persona": {
                        "id": str(citizen.get("id", random.randint(1, 1000))),
                        "name": citizen["name"],
                        "age": str(age),
                        "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                        "element": bazi.get("element", "Fire"),
                        "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                        "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                        "location": citizen.get("location", "å°ç£"),
                        "birth_year": bazi.get("birth_year"),
                        "birth_month": bazi.get("birth_month"),
                        "birth_day": bazi.get("birth_day"),
                        "birth_shichen": bazi.get("birth_shichen"),
                        "four_pillars": pillars_str,
                        "day_master": bazi.get("day_master", "æœªçŸ¥"),
                        "strength": bazi.get("strength", "ä¸­å’Œ"),
                        "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                        "current_luck": current_luck,
                        "luck_timeline": luck_timeline
                    }
                })
                print(f"[Core TEXT] Added fallback comment #{len(arena_comments)}: {citizen['name']}")
            
            # 9. æ§‹å»ºæœ€çµ‚çµæœ (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            score = data.get("result", {}).get("score", 70)
            if score > 98: score = 98 # Clamp score to reasonable max
            if score < 10 and source_type == "text": score = 65 # Default for text if too low
            
            result_data = {
                "status": "ready",
                "score": score,
                "intent": data.get("result", {}).get("market_sentiment", "åˆ†æå®Œæˆ"),
                "summary": data.get("result", {}).get("summary", "AI åˆ†æå®Œæˆ"),
                "simulation_metadata": sim_metadata,
                "genesis": {
                     "total_population": 1000,
                     "sample_size": len(personas),
                     "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            # ğŸ§¬ ã€ABM INTEGRATIONã€‘åŸ·è¡Œ Agent-Based Modeling æ¨¡æ“¬
            try:
                abm_res = await self._run_abm_simulation(sampled_citizens, text_content, language)
                abm_evolution_data = abm_res["evolution_data"]
                abm_analytics = abm_res["analytics_data"]
            except Exception as e:
                logger.error(f"[{sim_id}] ABM Simulation Failed: {e}")
                abm_evolution_data = None
                abm_analytics = None

            # ğŸ§¬ [Sidecar] è¿½åŠ è¨ˆç®—ç¤¾æœƒç§‘å­¸æ–¹æ³•è«–è©®é‡‹å±¤
            methodology_sidecar = _generate_methodology_sidecar(
                score=result_data.get("score"),
                summary=result_data.get("summary"),
                language=language, metric_advice=data.get("metric_advice")
            )
            
            # ğŸ§¬ ã€ABM EVOLUTIONã€‘æ·»åŠ æ¼”åŒ–æ•¸æ“š
            if abm_evolution_data:
                methodology_sidecar["abm_evolution"] = abm_evolution_data
            if abm_analytics:
                methodology_sidecar["abm_analytics"] = abm_analytics

            result_data["methodology_data"] = methodology_sidecar
            
            # 10. æ›´æ–°è³‡æ–™åº«
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            print(f"âœ… [Core TEXT] Document analysis completed: {sim_id}, comments: {len(arena_comments)}, score: {score}")

        except Exception as e:
            print(f"[Core TEXT] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    async def run_simulation_with_audio_data(self, audio_bytes: bytes, sim_id: str, audio_format: str = "webm", language: str = "zh-TW"):
        """è™•ç†èªéŸ³éŒ„éŸ³çš„å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æ (éŒ„éŸ³ â†’ è½‰æ–‡å­— â†’ åˆ†æ)"""
        try:
            from fastapi.concurrency import run_in_threadpool
            
            # 1. ä½¿ç”¨ Gemini å°‡éŸ³è¨Šè½‰æ–‡å­—
            audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
            
            # Localized Transcription Prompt
            if language == "en":
                 transcription_prompt = """Please listen to this audio recording and transcribe it fully into English text.
        
This is a recording about a business plan or product idea. Please:
1. Transcribe all spoken content fully
2. Use English
3. Keep the original meaning, add appropriate punctuation for readability
4. If there is stuttering or repetition, smooth it out into fluent text

Output the transcribed text directly, without any additional explanation."""
            elif language == "zh-CN":
                 transcription_prompt = """è¯·å¬å–è¿™æ®µè¯­éŸ³å½•éŸ³ï¼Œå¹¶å°†å…¶å®Œæ•´è½¬å½•ä¸ºç®€ä½“ä¸­æ–‡æ–‡å­—ã€‚
        
è¿™æ˜¯ä¸€æ®µå…³äºå•†ä¸šè®¡åˆ’æˆ–äº§å“æƒ³æ³•çš„å½•éŸ³ã€‚è¯·ï¼š
1. å®Œæ•´è½¬å½•æ‰€æœ‰å£è¯´å†…å®¹
2. ä½¿ç”¨ç®€ä½“ä¸­æ–‡
3. ä¿æŒåŸæ„ï¼Œé€‚å½“åŠ å…¥æ ‡ç‚¹ç¬¦å·è®©å†…å®¹æ›´æ˜“è¯»
4. å¦‚æœæœ‰å£åƒæˆ–é‡å¤çš„éƒ¨åˆ†ï¼Œè¯·æ•´ç†ä¸ºé¡ºç•…çš„æ–‡å­—

ç›´æ¥è¾“å‡ºè½¬å½•åçš„æ–‡å­—å†…å®¹ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–è¯´æ˜ã€‚"""
            else:
                 transcription_prompt = """è«‹è½å–é€™æ®µèªéŸ³éŒ„éŸ³ï¼Œä¸¦å°‡å…¶å®Œæ•´è½‰éŒ„ç‚ºç¹é«”ä¸­æ–‡æ–‡å­—ã€‚
            
é€™æ˜¯ä¸€æ®µé—œæ–¼å•†æ¥­è¨ˆåŠƒæˆ–ç”¢å“æƒ³æ³•çš„éŒ„éŸ³ã€‚è«‹ï¼š
1. å®Œæ•´è½‰éŒ„æ‰€æœ‰å£èªªå…§å®¹
2. ä½¿ç”¨ç¹é«”ä¸­æ–‡
3. ä¿æŒåŸæ„ï¼Œé©ç•¶åŠ å…¥æ¨™é»ç¬¦è™Ÿè®“å…§å®¹æ›´æ˜“è®€
4. å¦‚æœæœ‰å£åƒæˆ–é‡è¤‡çš„éƒ¨åˆ†ï¼Œè«‹æ•´ç†ç‚ºé †æš¢çš„æ–‡å­—

ç›´æ¥è¼¸å‡ºè½‰éŒ„å¾Œçš„æ–‡å­—å…§å®¹ï¼Œä¸è¦æœ‰ä»»ä½•é¡å¤–èªªæ˜ã€‚"""

            api_key = settings.GOOGLE_API_KEY
            
            # éŸ³è¨Š MIME é¡å‹å°æ‡‰
            audio_mime_map = {
                "webm": "audio/webm",
                "mp3": "audio/mp3",
                "wav": "audio/wav",
                "m4a": "audio/mp4",
                "ogg": "audio/ogg"
            }
            audio_mime = audio_mime_map.get(audio_format, "audio/webm")
            
            # å‘¼å« Gemini é€²è¡ŒèªéŸ³è½‰æ–‡å­—
            transcribed_text, error = await asyncio.to_thread(
                self._run_blocking_gemini_request_audio,
                api_key,
                transcription_prompt,
                audio_b64,
                audio_mime
            )
            
            if not transcribed_text:
                self._handle_error_db(sim_id, f"Voice Transcription Failed: {error}")
                return
            
            print(f"[Audio] Transcribed {len(transcribed_text)} characters")
            
            # 2. ä½¿ç”¨è½‰éŒ„çš„æ–‡å­—é€²è¡Œå•†æ¥­åˆ†æ
            await self.run_simulation_with_text_data(transcribed_text, sim_id, "voice", language=language)

        except Exception as e:
            print(f"[Core AUDIO] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    def _run_blocking_gemini_request_audio(self, api_key, prompt, audio_b64, audio_mime):
        """Blocking Gemini API call for audio transcription"""
        import requests
        
        print(f"[DEBUG AUDIO] Starting audio transcription, audio size: {len(audio_b64)} chars, mime: {audio_mime}")
        
        # [Restore] Prioritize Gemini 2.5 Pro for Quality
        models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
        last_error = None
        
        for model in models:
            try:
                print(f"[DEBUG AUDIO] Trying model: {model}")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                payload = {
                    "contents": [{
                        "parts": [
                            {"text": prompt},
                            {"inline_data": {"mime_type": audio_mime, "data": audio_b64}}
                        ]
                    }],
                    "generationConfig": {"temperature": 0.1}
                }
                
                response = requests.post(url, json=payload, headers={"Content-Type": "application/json"}, timeout=120)
                print(f"[DEBUG AUDIO] {model} response status: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        result_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                        print(f"[DEBUG AUDIO] Successfully transcribed: {len(result_text)} chars")
                        return result_text, None
                    except Exception as parse_err:
                        print(f"[DEBUG AUDIO] Parse error: {parse_err}, response: {response.text[:500]}")
                        continue
                else:
                    error_msg = f"{model}: {response.status_code} - {response.text[:300]}"
                    print(f"[DEBUG AUDIO] API Error: {error_msg}")
                    last_error = error_msg
            except Exception as e:
                print(f"[DEBUG AUDIO] Exception: {str(e)}")
                last_error = str(e)
        
        print(f"[DEBUG AUDIO] All models failed. Last error: {last_error}")
        return None, last_error


    # ===== Helpers =====
    # NOTE: èˆŠç‰ˆ _call_gemini_rest å·²åˆªé™¤ï¼Œç¾ä½¿ç”¨ç¬¬ 3898 è¡Œçš„æ–°ç‰ˆæœ¬ï¼ˆæœ‰ Pro æ¨¡å‹ 600 ç§’ timeoutï¼‰


    def _clean_and_parse_json(self, ai_text):
        """Helper to clean and parse JSON with robust error handling"""
        if not ai_text or not isinstance(ai_text, str):
            logger.error(f"Invalid AI text input for parsing: {type(ai_text)}")
            with open("debug_trace.log", "a", encoding="utf-8") as f:
                f.write(f"[JSON_PARSE] Invalid input: {type(ai_text)}\n")
            return {"result": {}, "arena_comments": [], "genesis": {}, "simulation_metadata": {}, "comments": [], "suggestions": []}

        clean_text = ai_text.strip()  # ğŸ”§ [Fix] Strip whitespace first
        
        # ğŸ” [DEBUG] Log input before processing
        with open("debug_trace.log", "a", encoding="utf-8") as f:
            f.write(f"[JSON_PARSE] Input length: {len(ai_text)}, After strip: {len(clean_text)}\n")
            f.write(f"[JSON_PARSE] First 100 chars after strip: {repr(clean_text[:100])}\n")
        
        # Check for markdown code block
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", ai_text, re.DOTALL)
        if match:
            clean_text = match.group(1).strip()
            with open("debug_trace.log", "a", encoding="utf-8") as f:
                f.write(f"[JSON_PARSE] Extracted from code block, new length: {len(clean_text)}\n")
        
        # ğŸ”§ [Fix] Also try to find JSON object directly if not in code block
        if not clean_text.startswith('{'):
            # Try to find the first { and extract from there
            first_brace = clean_text.find('{')
            if first_brace != -1:
                clean_text = clean_text[first_brace:]
                with open("debug_trace.log", "a", encoding="utf-8") as f:
                    f.write(f"[JSON_PARSE] Found first brace at {first_brace}\n")
        
        try:
            data = json.loads(clean_text)
            if isinstance(data, dict):
                with open("debug_trace.log", "a", encoding="utf-8") as f:
                    f.write(f"[JSON_PARSE] SUCCESS! Keys: {list(data.keys())}\n")
                return data
            else:
                with open("debug_trace.log", "a", encoding="utf-8") as f:
                    f.write(f"[JSON_PARSE] FAILED: Non-dict result: {type(data)}\n")
                return {}
        except json.JSONDecodeError as e:
            # ğŸ” [DEBUG] Log the exact error and problematic content
            with open("debug_trace.log", "a", encoding="utf-8") as f:
                f.write(f"[JSON_PARSE] JSONDecodeError: {e}\n")
                f.write(f"[JSON_PARSE] Error position: line {e.lineno}, col {e.colno}\n")
                f.write(f"[JSON_PARSE] First 500 chars: {repr(clean_text[:500])}\n")
            
            # ğŸ”§ [Fix] Remove trailing commas (common issue with AI-generated JSON)
            # Pattern: ,\s*} or ,\s*]
            fixed_text = clean_text.strip()
            fixed_text = re.sub(r',\s*}', '}', fixed_text)  # Remove ,} pattern
            fixed_text = re.sub(r',\s*]', ']', fixed_text)  # Remove ,] pattern
            
            with open("debug_trace.log", "a", encoding="utf-8") as f:
                f.write(f"[JSON_PARSE] Attempting fix with trailing comma removal...\n")
            
            # Also fix unbalanced brackets
            if fixed_text.count('{') > fixed_text.count('}'): fixed_text += '}' * (fixed_text.count('{') - fixed_text.count('}'))
            if fixed_text.count('[') > fixed_text.count(']'): fixed_text += ']' * (fixed_text.count('[') - fixed_text.count(']'))
            try:
                data = json.loads(fixed_text)
                if isinstance(data, dict):
                    with open("debug_trace.log", "a", encoding="utf-8") as f:
                        f.write(f"[JSON_PARSE] Fixed and parsed! Keys: {list(data.keys())}\n")
                    return data
                return {}
            except Exception as fix_err:
                with open("debug_trace.log", "a", encoding="utf-8") as f:
                    f.write(f"[JSON_PARSE] Failed even after fixing: {fix_err}\n")
                return {}

    def _build_simulation_result(self, data, sampled_citizens, sim_metadata_override=None):
        """Helper to build final result structure"""
        # Logic extracted from original code to build result_data
        # ... simplified for brevity as it copies logic ...
        
        # Reconstruct Bazi distribution
        element_counts = {"Fire": 0, "Water": 0, "Metal": 0, "Wood": 0, "Earth": 0}
        for c in sampled_citizens:
            elem = c["bazi_profile"].get("element", "Fire")
            if elem in element_counts: element_counts[elem] += 1
        total = len(sampled_citizens)
        bazi_dist = {k: round(v / total * 100) for k, v in element_counts.items()} if total else element_counts

        # Build Personas (Ensure enough for the display)
        # é€™è£¡ä¸é™åˆ¶åªå– 8 å€‹ï¼Œè€Œæ˜¯ç¶­æŒèˆ‡ arena_comments çš„åŒæ­¥
        personas_dict = {}
        for c in sampled_citizens:
            bazi = c.get("bazi_profile", {})
            personas_dict[str(c["id"])] = {
                "id": str(c["id"]),
                "name": c["name"],
                "age": c["age"],
                "location": c.get("location", "å°ç£"),
                "occupation": c.get("occupation", "æœªçŸ¥è·æ¥­"),
                "element": bazi.get("element", "Fire"),
                "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                "day_master": bazi.get("day_master", ""),
                "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                "trait": ", ".join(c["traits"][:2]) if c.get("traits") else "å€‹æ€§é®®æ˜",
                "decision_logic": "æ ¹æ“šå…«å­—æ ¼å±€ç‰¹è³ªåˆ†æ",
                "current_luck": bazi.get("current_luck", {}),
                "luck_timeline": bazi.get("luck_timeline", []),
                # å®Œæ•´ç”Ÿè¾°è³‡æ–™
                "birth_year": bazi.get("birth_year"),
                "birth_month": bazi.get("birth_month"),
                "birth_day": bazi.get("birth_day"),
                "birth_shichen": bazi.get("birth_shichen"),
                "four_pillars": bazi.get("four_pillars"),
                "strength": bazi.get("strength", "ä¸­å’Œ"),
                "favorable": bazi.get("favorable", ["æœ¨", "ç«"])
            }
        
        # Build comments
        gemini_comments = data.get("arena_comments") or data.get("comments") or []
        arena_comments = []
        # å¼·åˆ¶ Key ç‚º String ä»¥é˜²è¬ä¸€
        citizen_map = {str(c["id"]): c for c in sampled_citizens}
        
        for comment in gemini_comments:
            raw_id = comment.get("citizen_id")
            c_id = str(raw_id) if raw_id is not None else ""
            
            # 1. å˜—è©¦ç”¨ ID ç›´æ¥åŒ¹é…
            citizen = citizen_map.get(c_id)
            
            # 2. å¦‚æœæ‰¾ä¸åˆ°ï¼Œä¸” ID æ˜¯æ•¸å­—ï¼Œå˜—è©¦ç”¨ Index åŒ¹é… (é‡å° Gemini è¿”å› 0, 1, 2... çš„æƒ…æ³)
            if not citizen and c_id.isdigit():
                idx = int(c_id)
                # Gemini æœ‰æ™‚æ˜¯ 1-based index
                if 0 <= idx < len(sampled_citizens):
                    citizen = sampled_citizens[idx]
                elif 0 < idx <= len(sampled_citizens): # Handle 1-based
                    citizen = sampled_citizens[idx-1]
            
            if citizen:
                bazi = citizen["bazi_profile"]
                
                # Auto-fill missing birthday data
                if not bazi.get("birth_year"):
                    try:
                        age = int(citizen.get("age", 30))
                    except:
                        age = 30
                    bazi["birth_year"] = 2025 - age
                    bazi["birth_month"] = random.randint(1, 12)
                    bazi["birth_day"] = random.randint(1, 28)
                    bazi["birth_shichen"] = random.choice(["å­æ™‚", "ä¸‘æ™‚", "å¯…æ™‚", "å¯æ™‚", "è¾°æ™‚", "å·³æ™‚", "åˆæ™‚", "æœªæ™‚", "ç”³æ™‚", "é…‰æ™‚", "æˆŒæ™‚", "äº¥æ™‚"])

                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å‘½ç›¤ï¼Œéš¨æ©Ÿç”Ÿæˆ
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    logger.warning(f"Citizen {citizen['name']} missing four_pillars, auto-generating...")
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                    bazi["four_pillars"] = pillars_str
                
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å¤§é‹ï¼Œç”Ÿæˆé»˜èªå¤§é‹
                timeline = bazi.get("luck_timeline")
                if not timeline:
                     # å˜—è©¦å¾ luck_pillars ç”Ÿæˆ
                     if bazi.get("luck_pillars"):
                         timeline = []
                         for l in bazi["luck_pillars"]:
                             name = l.get('pillar', 'ç”²å­') + "é‹"
                             desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                             timeline.append({
                                 "age_start": l.get('age_start', 0),
                                 "age_end": l.get('age_end', 9),
                                 "name": name,
                                 "description": desc
                             })
                     else:
                         # å®Œå…¨éš¨æ©Ÿç”Ÿæˆ
                         start_age = random.randint(2, 9)
                         pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                         timeline = []
                         for i in range(8):
                             p_name = f"{pillars_pool[(i+random.randint(0,5))%len(pillars_pool)]}é‹"
                             timeline.append({
                                 "age_start": start_age + i*10,
                                 "age_end": start_age + i*10 + 9,
                                 "name": p_name,
                                 "description": "è¡Œé‹å¹³ç©©ï¼Œé †å…¶è‡ªç„¶ã€‚"
                             })
                     bazi["luck_timeline"] = timeline
                
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ current_luckï¼Œå¾ timeline ä¸­è¨ˆç®—
                current_luck = bazi.get("current_luck")
                if not isinstance(current_luck, dict):
                    current_luck = {}
                
                if not current_luck or not current_luck.get("description"):
                    try:
                        citizen_age = int(citizen.get("age", 30))
                    except:
                        citizen_age = 30
                    for lt in timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                    if not current_luck and timeline:
                        current_luck = {"name": timeline[0]["name"], "description": timeline[0]["description"]}
                    bazi["current_luck"] = current_luck

                # ID é˜²ç¦¦
                cid = str(citizen.get("id")) if citizen.get("id") else f"gen-{random.randint(1000,9999)}"

                arena_comments.append({
                    "sentiment": comment.get("sentiment", "neutral"),
                    "text": comment.get("text", "ï¼ˆç„¡è©•è«–å…§å®¹ï¼‰"),
                    "persona": personas_dict.get(cid)
                })
                
                # DEBUG LOG
                logger.info(f"Generated Primary Comment Persona: Name={citizen['name']}, ID={cid}, Birth={bazi.get('birth_year')}")

        # Ensure personas list for genesis is synced with the comments
        personas = [c["persona"] for c in arena_comments if c.get("persona")]

        # Fallback comments if not enough (ensure at least 8)
        # å¤§å¹…å¢åŠ è©•è«–æ¨¡æ¿ï¼Œæ›´è±å¯Œã€æ›´ç¬¦åˆå…«å­—å€‹æ€§
        bazi_comment_templates = {
            "é£Ÿç¥æ ¼": [
                "é€™ç”¢å“çœ‹èµ·ä¾†æŒºæœ‰è³ªæ„Ÿçš„ï¼Œç”¨èµ·ä¾†æ‡‰è©²å¾ˆäº«å—ï¼ç‰¹åˆ¥å–œæ­¡å®ƒçš„è¨­è¨ˆæ„Ÿï¼Œæ¯å¤©ä½¿ç”¨å¿ƒæƒ…éƒ½æœƒå¾ˆå¥½ã€‚",
                "å“‡ï¼Œé€™è¨­è¨ˆè »æœ‰å“å‘³çš„ï¼æˆ‘ä¸€å‘æ³¨é‡ç”Ÿæ´»å“è³ªï¼Œé€™ç¨®ç´°ç¯€è™•ç†å¾—ä¸éŒ¯ï¼Œå€¼å¾—å…¥æ‰‹ã€‚",
                "æˆ‘æ¯”è¼ƒåœ¨æ„ä½¿ç”¨é«”é©—ï¼Œé€™å€‹ç”¢å“å¾å¤–è§€åˆ°æ‰‹æ„Ÿéƒ½å¾ˆèˆ’æœï¼Œæ„Ÿè¦ºæœƒæ˜¯ç”Ÿæ´»ä¸­çš„å°ç¢ºå¹¸ã€‚",
                "ä½œç‚ºä¸€å€‹æ„›å¥½è€…ï¼Œæˆ‘è¦ºå¾—é€™å€‹ç”¢å“å¾ˆç™‚ç™’ï¼Œå…‰æ˜¯çœ‹è‘—å°±å¾ˆé–‹å¿ƒï¼Œå¯¦ç”¨æ€§å€’æ˜¯å…¶æ¬¡ã€‚"
            ],
            "å‚·å®˜æ ¼": [
                "è¨­è¨ˆé‚„å¯ä»¥ï¼Œä½†æˆ‘è¦ºå¾—æœ‰äº›åœ°æ–¹å¯ä»¥æ›´æœ‰å‰µæ„ä¸€é»ã€‚ä¸éæ•´é«”ä¾†èªªé‚„æ˜¯æœ‰å®ƒçš„ç‰¹è‰²ã€‚",
                "å—¯...æˆ‘æœ‰ä¸€äº›æ”¹é€²çš„æƒ³æ³•ï¼šå¦‚æœèƒ½åŠ å¼·æŸäº›åŠŸèƒ½æœƒæ›´å®Œç¾ã€‚ä¸éæ¦‚å¿µæ˜¯å¥½çš„ã€‚",
                "èªªå¯¦è©±ï¼Œå¸‚é¢ä¸Šé¡ä¼¼çš„ç”¢å“å¾ˆå¤šï¼Œé€™å€‹éœ€è¦åšå‡ºå·®ç•°åŒ–æ‰èƒ½çœŸæ­£å¸å¼•æˆ‘ã€‚",
                "æˆ‘æ¬£è³å‰µæ–°çš„å˜—è©¦ï¼Œä½†åŸ·è¡Œé¢é‚„æœ‰é€²æ­¥ç©ºé–“ã€‚æ½›åŠ›æ˜¯æœ‰çš„ï¼Œå°±çœ‹å¾ŒçºŒè¿­ä»£äº†ã€‚"
            ],
            "æ­£è²¡æ ¼": [
                "CPå€¼å¦‚ä½•ï¼Ÿæˆ‘æ¯”è¼ƒåœ¨æ„æ€§åƒ¹æ¯”ã€‚é€™å€‹åƒ¹æ ¼å¦‚æœå“è³ªç©©å®šï¼Œæˆ‘æœƒè€ƒæ…®å…¥æ‰‹ã€‚",
                "åƒ¹æ ¼å’Œå“è³ªçš„å¹³è¡¡å¾ˆé‡è¦ï¼Œé€™å€‹çœ‹èµ·ä¾†é‚„å¯ä»¥ã€‚å¸Œæœ›ç”¨æ–™å¯¦åœ¨ï¼Œä¸æ˜¯è™›æœ‰å…¶è¡¨ã€‚",
                "ä½œç‚ºä¸€å€‹å‹™å¯¦çš„äººï¼Œæˆ‘æœƒå…ˆçœ‹è©•åƒ¹å’Œå£ç¢‘ï¼Œç¢ºä¿æ¯ä¸€åˆ†éŒ¢éƒ½èŠ±å¾—å€¼å¾—ã€‚",
                "æˆ‘æœƒåšåŠŸèª²æ¯”è¼ƒå¹¾å®¶å†æ±ºå®šã€‚é€™å€‹å¦‚æœæœ‰å„ªæƒ æˆ–åˆ†æœŸï¼Œå¸å¼•åŠ›æœƒæ›´å¤§ã€‚"
            ],
            "åè²¡æ ¼": [
                "æ„Ÿè¦ºæœ‰æ½›åŠ›ï¼å¯ä»¥è€ƒæ…®æŠ•è³‡çœ‹çœ‹ã€‚é€™å€‹å¸‚å ´å®šä½è »è°æ˜çš„ï¼ŒæŠ“ä½äº†ç—›é»ã€‚",
                "é€™å€‹åˆ‡å…¥é»ä¸éŒ¯ï¼Œå•†æ©Ÿè »å¤§çš„ï¼å¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œç™¼å±•å‰æ™¯çœ‹å¥½ã€‚",
                "æˆ‘çœ‹åˆ°äº†æ©Ÿæœƒï¼é€™é¡ç”¢å“ç¾åœ¨æ­£æµè¡Œï¼Œæ™‚æ©Ÿé»æŠ“å¾—ä¸éŒ¯ï¼Œå€¼å¾—é—œæ³¨ã€‚",
                "æœ‰æ„æ€ï¼é€™å€‹å¦‚æœèƒ½åšæˆç³»åˆ—ç”¢å“æˆ–æ‰“é€ å“ç‰Œï¼Œæœªä¾†å¢å€¼ç©ºé–“å¾ˆå¤§ã€‚"
            ],
            "æ­£å®˜æ ¼": [
                "å“è³ªå’Œè¦æ ¼éƒ½ç¬¦åˆæ¨™æº–å—ï¼Ÿæˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªå„é …èªè­‰å’Œä¿å›ºæ¢æ¬¾ã€‚",
                "éœ€è¦å¤šäº†è§£ä¸€ä¸‹ç´°ç¯€ï¼Œå†åšæ±ºå®šã€‚ç©©å®šæ€§å’Œå”®å¾Œæœå‹™æ˜¯æˆ‘æœ€åœ¨æ„çš„ã€‚",
                "é€™å€‹å“ç‰Œå£ç¢‘å¦‚ä½•ï¼Ÿæˆ‘å‚¾å‘é¸æ“‡æœ‰ä¿¡è­½çš„å» å•†ï¼Œé€™æ¨£æ›´æœ‰ä¿éšœã€‚",
                "æœ‰æ²’æœ‰å°ˆæ¥­æ¸¬è©¦å ±å‘Šï¼Ÿä½œç‚ºç†æ€§æ¶ˆè²»è€…ï¼Œæˆ‘éœ€è¦å®¢è§€æ•¸æ“šä¾†æ”¯æŒè³¼è²·æ±ºå®šã€‚"
            ],
            "ä¸ƒæ®ºæ ¼": [
                "ç›´æ¥èªªé‡é»ï¼Œé€™æ±è¥¿èƒ½ä¸èƒ½è§£æ±ºå¯¦éš›ç—›é»ï¼Ÿå¦‚æœæ˜¯ç‚ºäº†è™›æ¦®å¿ƒè²·çš„ï¼Œæˆ‘æ²’èˆˆè¶£ã€‚æ•ˆç‡å’Œçµæœæ‰æ˜¯æˆ‘æœ€åœ¨æ„çš„ï¼Œæˆ‘éœ€è¦èƒ½æ‰“ä»—çš„å·¥å…·ã€‚",
                "åˆ¥è·Ÿæˆ‘ç¹åœˆå­ï¼Œå¸‚å ´å„ªå‹¢åœ¨å“ªï¼Ÿæ†‘ä»€éº¼è®“æˆ‘é¸ä½ ï¼Ÿå¦‚æœçœŸçš„æœ‰ç¡¬å¯¦åŠ›ï¼Œæˆ‘æœƒæ¯«ä¸çŒ¶è±«ä¸‹å–®ï¼Œå¦å‰‡åˆ¥æµªè²»æˆ‘æ™‚é–“ã€‚",
                "æˆ‘åªé—œå¿ƒæ€§èƒ½å’Œå›å ±ã€‚é€™ç”¢å“å¦‚æœèƒ½å¹«æˆ‘çœä¸‹ 20% çš„æ™‚é–“ï¼Œé‚£å®ƒå°±å€¼é€™å€‹åƒ¹ã€‚åŸ·è¡ŒåŠ›ä¸è¶³çš„æ–¹æ¡ˆï¼Œæˆ‘çœ‹éƒ½ä¸çœ‹ã€‚",
                "é€™æ±è¥¿çœ‹èµ·ä¾†å¾ˆæœ‰ä¾µç•¥æ€§ï¼Œé©åˆé–‹æ‹“æ–°å¸‚å ´ã€‚æˆ‘å–œæ­¡é€™ç¨®å¸¶æœ‰çªç ´æ€§çš„è¨­è¨ˆï¼Œåªè¦å®ƒèƒ½æ‰›å¾—èµ·é«˜å¼·åº¦çš„å£“åŠ›ã€‚"
            ],
            "æ­£å°æ ¼": [
                "é€™å°é•·æœŸç™¼å±•æœ‰å¹«åŠ©å—ï¼Ÿæˆ‘æ¯”è¼ƒçœ‹é‡é•·é åƒ¹å€¼ï¼Œä¸å–œæ­¡æ›‡èŠ±ä¸€ç¾çš„æ±è¥¿ã€‚",
                "å“ç‰Œä¿¡è­½å¾ˆé‡è¦ï¼Œé€™å€‹å…¬å¸å¯é å—ï¼Ÿæˆ‘å¯§å¯å¤šèŠ±é»éŒ¢ä¹Ÿè¦è²·å®‰å¿ƒã€‚",
                "æœ‰æ²’æœ‰å­¸ç¿’è³‡æºæˆ–ä½¿ç”¨æŒ‡å—ï¼Ÿæˆ‘å¸Œæœ›èƒ½çœŸæ­£äº†è§£å’ŒæŒæ¡é€™å€‹ç”¢å“ã€‚",
                "æˆ‘æœƒå…ˆè«‹æ•™æœ‰ç¶“é©—çš„æœ‹å‹ï¼Œè½è½ä»–å€‘çš„æ„è¦‹å†æ±ºå®šã€‚è¬¹æ…ä¸€é»ç¸½æ˜¯å¥½çš„ã€‚"
            ],
            "åå°æ ¼": [
                "é€™å€‹æ¦‚å¿µæŒºç‰¹åˆ¥çš„ï¼Œè·Ÿå¸‚é¢ä¸Šçš„ä¸å¤ªä¸€æ¨£ã€‚æˆ‘å–œæ­¡æœ‰ç¨ç‰¹æƒ³æ³•çš„ç”¢å“ã€‚",
                "æœ‰é»æ„æ€ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šæ™‚é–“æ€è€ƒã€‚ç›´è¦ºå‘Šè¨´æˆ‘é€™å€‹æœ‰äº›é–€é“ã€‚",
                "è¨­è¨ˆç†å¿µå¾ˆæœ‰æ·±åº¦ï¼Œä¸æ˜¯ä¸€èˆ¬å¤§çœ¾èƒ½é¦¬ä¸Šç†è§£çš„ã€‚é€™åè€Œå¸å¼•æˆ‘ã€‚",
                "æˆ‘ä¸è·Ÿé¢¨ï¼Œé€™å€‹ç”¢å“æœ‰å®ƒç¨ç‰¹çš„æ°£è³ªï¼Œé©åˆæœ‰å“å‘³çš„äººã€‚"
            ],
            "æ¯”è‚©æ ¼": [
                "é€™å€‹æˆ‘èº«é‚Šå¾ˆå¤šæœ‹å‹éƒ½åœ¨ç”¨ï¼Œçœ‹ä¾†çœŸçš„ä¸éŒ¯ã€‚å¤§å®¶èªªå¥½æ‰æ˜¯çœŸçš„å¥½ã€‚",
                "æˆ‘æœƒå•å•åŒäº‹çš„æ„è¦‹ï¼Œå¦‚æœä»–å€‘ä¹Ÿè¦ºå¾—å¯ä»¥ï¼Œæˆ‘å°±è·Ÿä¸€æ³¢ã€‚",
                "é€™é¡ç”¢å“æˆ‘æœ‰ä½¿ç”¨ç¶“é©—ï¼Œé€™å€‹æ–°å“çœ‹èµ·ä¾†åœ¨ä¸€äº›ç´°ç¯€ä¸Šæœ‰é€²æ­¥ã€‚",
                "åƒ¹æ ¼å…¬é“ï¼Œå“è³ªéå¾—å»ï¼Œç¬¦åˆæˆ‘çš„é æœŸã€‚ä¸æ±‚æœ€å¥½ï¼Œä½†æ±‚å¯¦ç”¨ã€‚"
            ],
            "åŠ«è²¡æ ¼": [
                "é€™å€‹å€¼å¾—è·Ÿæœ‹å‹å€‘åˆ†äº«ï¼å¥½æ±è¥¿å°±æ˜¯è¦ä¸€èµ·ç”¨æ‰æœ‰æ„æ€ã€‚",
                "å¦‚æœæœ‰åœ˜è³¼æˆ–å„ªæƒ æ´»å‹•ï¼Œæˆ‘å¯ä»¥å¹«å¿™æªäººï¼Œå¤§å®¶ä¸€èµ·è²·æ›´åˆ’ç®—ã€‚",
                "æˆ‘å·²ç¶“æƒ³å¥½è¦æ¨è–¦çµ¦èª°äº†ï¼Œé€™å€‹ç”¢å“å‰›å¥½é©åˆæˆ‘å¹¾å€‹æœ‹å‹çš„éœ€æ±‚ã€‚",
                "ç”Ÿæ´»å˜›ï¼Œé–‹å¿ƒæœ€é‡è¦ï¼é€™å€‹èƒ½è®“æœ‹å‹èšæœƒæ›´æœ‰è¶£ï¼Œå€¼å¾—å…¥æ‰‹ã€‚"
            ],
        }
        
        # æ ¹æ“šè·æ¥­å¢åŠ æ›´å¤šå€‹æ€§åŒ–è©•è«–
        occupation_comments = {
            "å·¥ç¨‹å¸«": "å¾æŠ€è¡“è§’åº¦ä¾†çœ‹ï¼Œé€™å€‹ç”¢å“çš„è¨­è¨ˆé‚è¼¯æ˜¯åˆç†çš„ï¼ŒåŸ·è¡Œé¢ä¹Ÿä¸éŒ¯ã€‚",
            "è¨­è¨ˆå¸«": "è¦–è¦ºå‘ˆç¾è »æœ‰è³ªæ„Ÿçš„ï¼Œè‰²å½©æ­é…å’Œæ’ç‰ˆéƒ½å¾ˆç”¨å¿ƒï¼Œçœ‹å¾—å‡ºå°ˆæ¥­åº¦ã€‚",
            "è€å¸«": "é€™å€‹å°å­¸ç”Ÿæˆ–å®¶åº­ä¾†èªªå¯¦ç”¨å—ï¼Ÿæˆ‘æœƒè€ƒæ…®æ•™è‚²æ„ç¾©å’Œå®‰å…¨æ€§ã€‚",
            "é†«ç”Ÿ": "å¥åº·ç›¸é—œçš„ç”¢å“æˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªæœ‰ç„¡ç›¸é—œèªè­‰ã€‚",
            "å‰µæ¥­å®¶": "å•†æ¥­æ¨¡å¼æœ‰å‰µæ„ï¼Œå¦‚æœèƒ½è§£æ±ºçœŸæ­£çš„å¸‚å ´ç—›é»ï¼Œæœƒæœ‰ç™¼å±•ç©ºé–“ã€‚",
            "å­¸ç”Ÿ": "åƒ¹æ ¼æ˜¯æˆ‘æœ€åœ¨æ„çš„ï¼Œå¦‚æœæœ‰å­¸ç”Ÿå„ªæƒ å°±æ›´å¥½äº†ï¼",
            "ç¶“ç†": "åœ˜éšŠå”ä½œæ–¹é¢æœ‰å„ªå‹¢å—ï¼Ÿæˆ‘æœƒè€ƒæ…®å°å…¥å…¬å¸ä½¿ç”¨çš„å¯èƒ½æ€§ã€‚",
            "è‡ªç”±æ¥­": "éˆæ´»æ€§å¾ˆé‡è¦ï¼Œé€™å€‹èƒ½é…åˆæˆ‘ä¸å›ºå®šçš„å·¥ä½œæ¨¡å¼å—ï¼Ÿ",
        }
        
        default_templates = [
            "é€™å€‹ç”¢å“ç¢ºå¯¦æœ‰å®ƒçš„ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®è³¼è²·ï¼Œä½†é‚„éœ€è¦å†è§€å¯Ÿä¸€ä¸‹å¸‚å ´åæ‡‰ã€‚",
            "åƒ¹æ ¼åˆç†çš„è©±æˆ‘é¡˜æ„è©¦è©¦çœ‹ï¼Œç•¢ç«Ÿå˜—è©¦æ–°æ±è¥¿ä¹Ÿæ˜¯ä¸€ç¨®ç”Ÿæ´»æ…‹åº¦ã€‚",
            "è¨­è¨ˆè »æœ‰æƒ³æ³•çš„ï¼Œå¦‚æœè³ªé‡ç©©å®šï¼Œé€™å€‹åƒ¹ä½ç®—æ˜¯å¯ä»¥æ¥å—çš„é¸æ“‡ã€‚",
            "æ•´é«”ä¾†èªªç¬¦åˆæˆ‘çš„é æœŸï¼Œä¸ç®—é©šè‰·ä½†ä¹Ÿæ²’ä»€éº¼å¤§å•é¡Œï¼Œå¯ä»¥åˆ—å…¥è³¼ç‰©æ¸…å–®ã€‚",
            "æˆ‘æœƒæŒçºŒé—œæ³¨é€™å€‹ç”¢å“ï¼Œç­‰æ›´å¤šç”¨æˆ¶è©•åƒ¹å‡ºä¾†å†æ±ºå®šæ˜¯å¦å…¥æ‰‹ã€‚",
            "ç¬¬ä¸€å°è±¡ä¸éŒ¯ï¼Œä½†æˆ‘ç¿’æ…£è²¨æ¯”ä¸‰å®¶ï¼Œç¢ºä¿é€™æ˜¯æœ€ä½³é¸æ“‡å†ä¸‹æ‰‹ã€‚",
            "å°æˆ‘ä¾†èªªé€™æ˜¯å€‹æ–°é ˜åŸŸï¼Œéœ€è¦æ›´å¤šäº†è§£ï¼Œä½†ç”¢å“æœ¬èº«çœ‹èµ·ä¾†æœ‰èª æ„ã€‚",
            "æœ‹å‹æ¨è–¦éé¡ä¼¼çš„ç”¢å“ï¼Œé€™å€‹çœ‹èµ·ä¾†ä¹Ÿå€¼å¾—ä¸€è©¦ï¼Œè€ƒæ…®ä¸­ã€‚"
        ]
        
        if not isinstance(arena_comments, list):
            arena_comments = []
            
        # ğŸ›¡ï¸ æ·±åº¦æ¸…ç†èˆ‡é©—è­‰è©•è«–æ ¼å¼
        valid_comments = []
        for c in arena_comments:
            if isinstance(c, dict) and c.get("text") and len(str(c.get("text"))) > 5:
                # ç¢ºä¿ persona çµæ§‹å­˜åœ¨
                if not c.get("persona"):
                    c["persona"] = {}
                valid_comments.append(c)
        arena_comments = valid_comments

        while len(arena_comments) < 10 and sampled_citizens:
            # æ‰¾ä¸€å€‹é‚„æ²’è©•è«–éçš„å¸‚æ°‘
            commented_names = set()
            for c in arena_comments:
                if isinstance(c.get("persona"), dict) and c["persona"].get("name"):
                    commented_names.add(c["persona"]["name"])
                    
            remaining = [c for c in sampled_citizens if c["name"] not in commented_names]
            if not remaining:
                break
            citizen = remaining[0]
            bazi = citizen["bazi_profile"]
            structure = bazi.get("structure", "")
            occupation = citizen.get("occupation", "")
            
            # æ ¹æ“šå…«å­—çµæ§‹é¸æ“‡è©•è«–æ¨¡æ¿
            templates = None
            for pattern, texts in bazi_comment_templates.items():
                if pattern in structure:
                    templates = texts
                    break
            
            # å¦‚æœæ²’æœ‰åŒ¹é…çš„å…«å­—æ ¼å±€ï¼Œå˜—è©¦è·æ¥­åŒ¹é…
            if not templates:
                for occ, comment in occupation_comments.items():
                    if occ in occupation:
                        templates = [comment]
                        break
            
            # æœ€å¾Œä½¿ç”¨é»˜èªæ¨¡æ¿
            if not templates:
                templates = default_templates
            
            # éš¨æ©Ÿé¸æ“‡ä¸€æ¢è©•è«–ï¼Œé¿å…é‡è¤‡
            text = random.choice(templates)
            
            # æ··åˆåˆ†é…æƒ…æ„Ÿ
            sentiments = ["positive", "positive", "neutral", "neutral", "negative"]
            sentiment = sentiments[len(arena_comments) % len(sentiments)]
            
            # å®šç¾© pillars_str
            pillars_str = bazi.get("four_pillars")
            if not pillars_str:
                pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
            
            # å–å¾— luck_timeline
            timeline = bazi.get("luck_timeline", [])
            
            # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ luck_timelineï¼Œç”Ÿæˆé è¨­è³‡æ–™
            if not timeline:
                start_age = random.randint(2, 9)
                pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                for i in range(8):
                    timeline.append({
                        "age_start": start_age + i*10,
                        "age_end": start_age + i*10 + 9,
                        "name": f"{pillars_pool[i]}é‹",
                        "description": descs[i]
                    })

            # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ current_luckï¼Œå¾ timeline ä¸­è¨ˆç®—
            current_luck = bazi.get("current_luck")
            if not isinstance(current_luck, dict):
                current_luck = {}

            if not current_luck or not current_luck.get("description"):
                try:
                    citizen_age = int(citizen.get("age", 30))
                except:
                    citizen_age = 30
                for lt in timeline:
                    if lt["age_start"] <= citizen_age <= lt["age_end"]:
                        current_luck = {"name": lt["name"], "description": lt["description"]}
                        break
                if not current_luck and timeline:
                    current_luck = {"name": timeline[0]["name"], "description": timeline[0]["description"]}
                bazi["current_luck"] = current_luck

            # ID é˜²ç¦¦
            cid = str(citizen.get("id")) if citizen.get("id") else f"gen-{random.randint(1000,9999)}"

            # æ§‹å»ºå®Œæ•´çš„ persona è³‡æ–™
            full_persona = {
                "id": cid,
                "name": citizen["name"],
                "age": str(citizen["age"]),
                "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                "element": bazi.get("element", "Fire"),
                "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                "location": citizen.get("location", "å°ç£"),
                "birth_year": bazi.get("birth_year"),
                "birth_month": bazi.get("birth_month"),
                "birth_day": bazi.get("birth_day"),
                "birth_shichen": bazi.get("birth_shichen"),
                "four_pillars": pillars_str,
                "day_master": bazi.get("day_master", "æœªçŸ¥"),
                "strength": bazi.get("strength", "ä¸­å’Œ"),
                "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                "current_luck": current_luck,
                "luck_timeline": timeline,
                "trait": bazi.get("trait", "æ€§æ ¼å‡è¡¡")
            }

            arena_comments.append({
                "sentiment": sentiment,
                "text": text,
                "persona": full_persona
            })
            
            personas.append(full_persona)
            
            # DEBUG LOG
            logger.info(f"Generated Fallback Comment Persona: Name={citizen['name']}, ID={cid}, Pillars={pillars_str}, Birth={bazi.get('birth_year')}")

        result_data = {
            "status": "ready",
            "score": data.get("result", {}).get("score", 75),
            "intent": data.get("result", {}).get("market_sentiment", "è¬¹æ…æ¨‚è§€"),
            "summary": data.get("result", {}).get("summary", "AI åˆ†æè¶…æ™‚ï¼Œç„¡æ³•ç”Ÿæˆå®Œæ•´å ±å‘Šã€‚è«‹ç¨å¾Œé‡è©¦ã€‚"),
            "simulation_metadata": {
                "source_type": sim_metadata_override.get("source_type", "image") if sim_metadata_override else "image",
                "product_category": data.get("simulation_metadata", {}).get("product_category", sim_metadata_override.get("product_category", "other") if sim_metadata_override else "other"),
                "sample_size": len(sampled_citizens),
                "bazi_distribution": bazi_dist
            },
            "bazi_distribution": bazi_dist,
            "genesis": {
                "total_population": 1000,
                "sample_size": max(len(arena_comments), 8),
                "personas": personas
            },
            "arena_comments": arena_comments,
            "objections": data.get("result", {}).get("objections", []),
            "suggestions": data.get("result", {}).get("suggestions", [])
        }
        return result_data

    def _handle_error_db(self, sim_id, error_msg):
        error_data = {
            "status": "error",
            "score": 0,
            "intent": "Error",
            "summary": f"ç³»çµ±éŒ¯èª¤: {error_msg}",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        update_simulation(sim_id, "error", error_data)

    def reply_text(self, reply_token, text):
        try:
            self.line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=text)]
                )
            )
        except Exception:
            pass

    async def _call_gemini_rest(self, api_key, prompt, image_b64=None, pdf_b64=None, mime_type="image/jpeg", timeout=120, image_parts=None):
        """Helper to call Gemini REST API (Async Wrapper with Configurable Timeout)"""
        import requests 

        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 65536,  # ğŸ”§ [Fix] Increased from 8192 to prevent JSON truncation
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_parts:
             payload["contents"][0]["parts"].extend(image_parts)
        elif image_b64:
            # Use dynamic mime_type
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": mime_type, "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        # [Restore] Prioritize Quality (Pro) as per User Request (reverting to GitHub-like behavior)
        # [Restore] Prioritize Quality (Gemini 2.5 Pro)
        models = [
            "gemini-2.5-pro",
            "gemini-2.5-flash",
            "gemini-2.0-flash",
            "gemini-1.5-pro",
            "gemini-1.5-flash",
            "gemini-flash-latest"
        ]
        
        last_error = ""
        for model in models:
            try:
                # print(f"Trying model: {model}...")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                
                # [Fix] Use asyncio.to_thread to unblock Event Loop
                import asyncio
                # Increase timeout for Pro model and PDF/Audio heavy tasks
                current_timeout = timeout
                if "pro" in model:
                    current_timeout = max(timeout, 600) # Pro needs 10 mins for detailed analysis
                
                # PDF needs more time regardless of model
                if pdf_b64:
                    current_timeout = max(current_timeout, 120)

                # [Fix] Use Tuple for (connect_timeout, read_timeout) to prevent socket level early termination
                # Most HTTP libraries interpret a single int as both, but explicit tuple is safer.
                # Also ensure asyncio.to_thread is used to prevent blocking.
                print(f"[DEBUG] Calling Gemini Model: {model} with Payload Size: {len(json.dumps(payload))} bytes, Exp. Read Timeout: {current_timeout}s")
                
                # Connection timeout: 30s, Read timeout: current_timeout
                full_timeout_config = (30, current_timeout)
                
                response = await asyncio.to_thread(
                    requests.post, 
                    url, 
                    headers={'Content-Type': 'application/json'}, 
                    json=payload, 
                    timeout=full_timeout_config
                )
                print(f"[DEBUG] Gemini Model {model} returned Status: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        raw_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                        # ğŸ” [DEBUG] Log raw Gemini response for JSON parse debugging
                        with open("debug_trace.log", "a", encoding="utf-8") as f:
                            f.write(f"[GEMINI_RAW] Model: {model}, Response Length: {len(raw_text)} chars\n")
                            f.write(f"[GEMINI_RAW] First 500 chars: {raw_text[:500]}\n")
                        return raw_text, None
                    except Exception as parse_ex:
                        print(f"[DEBUG] Gemini Model {model} parse error: {parse_ex}")
                        continue
                else:
                    last_error = f"{model}: {response.status_code} {response.text}"
            except Exception as e:
                last_error = str(e)
        
        return None, last_error

    # NOTE: èˆŠç‰ˆ generate_marketing_copy å·²åˆªé™¤ï¼Œç¾ä½¿ç”¨ç¬¬ 480 è¡Œçš„æ–°ç‰ˆæœ¬ (å–®ç¯‡è¼¸å‡º)
    # NOTE: èˆŠç‰ˆ refine_marketing_copy å·²åˆªé™¤ï¼Œç¾ä½¿ç”¨ç¬¬ 725 è¡Œçš„æ–°ç‰ˆæœ¬ (æ”¯æ´å¤šèªè¨€)


    def _run_blocking_gemini_request(self, api_key, prompt, image_b64=None, pdf_b64=None, model_priority=None, mime_type="image/jpeg", image_parts=None):
        """Helper to run synchronous requests in a thread"""
        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 8192,
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_parts:
             payload["contents"][0]["parts"].extend(image_parts)
        elif image_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": mime_type, "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        # Default models if not specified
        if model_priority:
            models = model_priority
        else:
            # [Fix] Prioritize Gemini 2.5 Pro as requested by the user
            models = [
                "gemini-2.5-pro",
                "gemini-2.5-flash",
                "gemini-flash-latest"
            ]
        
        last_error = ""
        for model in models:
            try:
                print(f"[AI] å˜—è©¦ä½¿ç”¨æ¨¡å‹: {model}...")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                # Increased timeout to 90s for complex prompts with detailed strategic advice
                response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                if response.status_code == 200:
                    try:
                        return response.json()['candidates'][0]['content']['parts'][0]['text'], None
                    except:
                        continue
                else:
                    error_msg = f"{model}: {response.status_code} {response.text}"
                    print(f"[AI] æ¨¡å‹ {model} å¤±æ•—: {error_msg}")
                    last_error = error_msg
            except Exception as e:
                last_error = str(e)
        
        return None, last_error
# LINE Bot å¤šåœ–è™•ç†è¼”åŠ©å‡½æ•¸
# é€™äº›å‡½æ•¸å°‡è¢«é›†æˆåˆ° line_bot_service.py ä¸­

async def _identify_from_multiple_images(self, user_id):
    """
    å¾ session ä¸­çš„å¤šå¼µåœ–ç‰‡é€²è¡Œ AI è­˜åˆ¥èˆ‡å¸‚å ´æ¯”åƒ¹
    """
    session = self.user_session.get(user_id)
    if not session or not session.get("images"):
        self._push_text(user_id, "âŒ æ‰¾ä¸åˆ°åœ–ç‰‡ï¼Œè«‹é‡æ–°ä¸Šå‚³")
        return
    
    images = session["images"]
    image_count = len(images)
    
    try:
        # 1. AI ç”¢å“è­˜åˆ¥ï¼ˆä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ï¼‰
        print(f"ğŸ” [Multi-Image] é–‹å§‹è­˜åˆ¥ {image_count} å¼µåœ–ç‰‡...")
        ai_name, ai_price = await self.identify_product_from_image(images[0])
        
        # 2. å¸‚å ´æ¯”åƒ¹æŸ¥è©¢ï¼ˆå¦‚æœæœ‰ç”¢å“åç¨±ï¼‰
        market_prices = {}
        if ai_name and ai_name != "æœªçŸ¥ç”¢å“":
            from app.services.price_search import search_market_prices_sync
            try:
                print(f"ğŸ’° [Market] æŸ¥è©¢å¸‚å ´åƒ¹æ ¼: {ai_name}")
                market_result = search_market_prices_sync(ai_name)
                if market_result.get("success"):
                    market_prices = market_result
                    print(f"ğŸ’° [Market] æ‰¾åˆ° {len(market_result.get('prices', []))} ç­†åƒ¹æ ¼è³‡æ–™")
            except Exception as e:
                print(f"âš ï¸ [Market] æ¯”åƒ¹æŸ¥è©¢å¤±æ•—: {e}")
        
        # 3. æ›´æ–° session
        session["image_bytes"] = images[0]  # å…¼å®¹æ€§ï¼šä¿ç•™ç¬¬ä¸€å¼µåšç‚ºä¸»åœ–
        session["product_name"] = ai_name or ""
        session["product_price"] = ai_price or "æœªå®š"  
        session["market_prices"] = market_prices
        session["stage"] = "waiting_for_name_confirmation"
        
        print(f"âœ… [Multi-Image] è­˜åˆ¥å®Œæˆ: {ai_name} / {ai_price}")
        
        # 4. æ§‹å»ºå›è¦†è¨Šæ¯ï¼ˆåŒ…å«å¸‚å ´æ¯”åƒ¹è³‡æ–™ï¼‰
        confirm_msg = f"ğŸ‘ï¸ **AI è¦–è¦ºåˆ†æçµæœ**ï¼ˆ{image_count} å¼µåœ–ç‰‡ï¼‰\n\n"
        confirm_msg += f"ğŸ“¦ ç”¢å“ï¼š{ai_name or 'æœªçŸ¥'}\n"
        
        # é¡¯ç¤ºå¸‚å ´æ¯”åƒ¹
        if market_prices.get("success"):
            prices = market_prices.get("prices", [])
            if prices:
                min_price = market_prices.get("min_price", ai_price)
                max_price = market_prices.get("max_price", ai_price)
                confirm_msg += f"ğŸ’° å¸‚å ´åƒ¹æ ¼å€é–“ï¼š${min_price} - ${max_price}\n"
                confirm_msg += f"ğŸ“Š å·²æ¯”å° {len(prices)} å€‹å¹³å°\n"
            else:
                confirm_msg += f"ğŸ’° ä¼°åƒ¹ï¼š{ai_price or 'æœªçŸ¥'}\n"
        else:
            confirm_msg += f"ğŸ’° ä¼°åƒ¹ï¼š{ai_price or 'æœªçŸ¥'}\n"
        
        confirm_msg += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        confirm_msg += "âœ… è‹¥è³‡æ–™æ­£ç¢ºï¼Œè«‹å›è¦†ã€Œ**Y**ã€\n"
        confirm_msg += "âœï¸ è‹¥éœ€ä¿®æ”¹ï¼Œè«‹ç›´æ¥è¼¸å…¥ã€Œ**åç¨± / å”®åƒ¹**ã€"
        
        self._push_text(user_id, confirm_msg)
        
    except Exception as e:
        print(f"âŒ [Multi-Image] è­˜åˆ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        self._push_text(user_id, "âŒ AI è­˜åˆ¥å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")
        # é‡ç½® session
        if user_id in self.user_session:
            del self.user_session[user_id]


async def _handle_upload_complete(self, user_id):
    """
    è™•ç†ç”¨æˆ¶é»é¸ã€Œå®Œæˆä¸Šå‚³ã€å¾Œçš„é‚è¼¯
    """
    session = self.user_session.get(user_id)
    if not session:
        self._push_text(user_id, "âŒ æ‰¾ä¸åˆ°ä¸Šå‚³çš„åœ–ç‰‡ï¼Œè«‹é‡æ–°é–‹å§‹")
        return
    
    images = session.get("images", [])
    if not images:
        self._push_text(user_id, "âŒ å°šæœªä¸Šå‚³ä»»ä½•åœ–ç‰‡ï¼Œè«‹å…ˆä¸Šå‚³ç”¢å“åœ–ç‰‡")
        return
    
    # é–‹å§‹è­˜åˆ¥
    await self._identify_from_multiple_images(user_id)
