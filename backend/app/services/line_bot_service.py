import asyncio
import io
import json
import random
import uuid
import re
import base64
import requests
import logging

# Create logger for this module
logger = logging.getLogger(__name__)
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    MessagingApiBlob,
    ReplyMessageRequest,
    TextMessage,
    PushMessageRequest
)
from app.core.config import settings
from app.core.database import create_simulation, update_simulation, get_simulation, get_random_citizens

# Alias for compatibility with main.py
get_simulation_data = get_simulation


class LineBotService:
    # In-memory session storage for user states
    user_session = {}
    
    def __init__(self):
        configuration = Configuration(access_token=settings.LINE_CHANNEL_ACCESS_TOKEN)
        self.api_client = ApiClient(configuration)
        self.line_bot_api = MessagingApi(self.api_client)
        self.line_bot_blob = MessagingApiBlob(self.api_client)

    async def handle_event(self, event):
        """
        é›™è»Œè¼¸å…¥æ©Ÿåˆ¶ (Dual-Track Input)
        - æƒ…å¢ƒ A: åœ–ç‰‡ (ImageMessage) â†’ æš«å­˜ä¸¦ç­‰å¾…è£œå……èªªæ˜
        - æƒ…å¢ƒ B: æ–‡å­— (TextMessage) â†’ æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        - æƒ…å¢ƒ C: æª”æ¡ˆ (FileMessage) â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸
        """
        user_id = event.source.user_id
        reply_token = event.reply_token
        message_type = event.message.type
        
        print(f"[EVENT] user_id={user_id}, type={message_type}")
        
        # ===== æƒ…å¢ƒ A: åœ–ç‰‡è¨Šæ¯ =====
        if message_type == "image":
            await self._handle_image_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ B: æ–‡å­—è¨Šæ¯ =====
        elif message_type == "text":
            await self._handle_text_message(event, user_id, reply_token)
        
        # ===== æƒ…å¢ƒ C: æª”æ¡ˆè¨Šæ¯ (PDF) =====
        elif message_type == "file":
            await self._handle_file_message(event, user_id, reply_token)
            
        # ===== æƒ…å¢ƒ D: å½±ç‰‡è¨Šæ¯ (ä¸æ”¯æ´) =====
        elif message_type == "video":
            self.reply_text(reply_token, "âš ï¸ æŠ±æ­‰ï¼Œç›®å‰ç³»çµ±åƒ…æ”¯æ´ã€Œåœ–ç‰‡ã€é æ¼”ã€‚\n\nè«‹å°‡å½±ç‰‡ç•«é¢ **æˆªåœ–** å¾Œä¸Šå‚³ï¼Œå³å¯å•Ÿå‹•åˆ†æï¼ğŸ“¸")
        
        else:
            # ä¸æ”¯æ´çš„è¨Šæ¯é¡å‹
            self.reply_text(reply_token, "âš ï¸ æŠ±æ­‰ï¼Œæˆ‘ä¸æ”¯æ´æ­¤æ ¼å¼ã€‚\nè«‹ä¸Šå‚³åœ–ç‰‡ ğŸ“¸ æˆ– PDF å•†æ¥­è¨ˆåŠƒæ›¸ ğŸ“„")

    async def _handle_image_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ A: æ”¶åˆ°åœ–ç‰‡ â†’ æš«å­˜ä¸¦ç­‰å¾…ç”¢å“åç¨±å’Œå”®åƒ¹"""
        message_id = event.message.id
        
        # ä¸‹è¼‰åœ–ç‰‡ä¸¦æš«å­˜
        try:
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            
            # æš«å­˜åˆ° sessionï¼ˆæ–°æµç¨‹ï¼šå…ˆå•åç¨±/å”®åƒ¹ï¼‰
            self.user_session[user_id] = {
                "image_bytes": image_bytes,
                "message_id": message_id,
                "stage": "waiting_for_name_price",  # æ–°ç‹€æ…‹ï¼šç­‰å¾…åç¨±å’Œå”®åƒ¹
                "product_name": None,
                "product_price": None,
                "product_description": None,
                "generated_descriptions": None  # AI ç”Ÿæˆçš„å…©æ®µæè¿°
            }
            
            print(f"ğŸ“¸ [SESSION] å·²æš«å­˜åœ–ç‰‡: user_id={user_id}, size={len(image_bytes)} bytes")
            
            # å›è¦†å¼•å°è¨Šæ¯ï¼ˆæ–°æµç¨‹ï¼šå…ˆå•åç¨±å’Œå”®åƒ¹ï¼‰
            guide_msg = (
                "ğŸ”® **MIRRA ç³»çµ±å·²æ¥æ”¶ç”¢å“å½±åƒã€‚**\n\n"
                "è«‹æä¾›ä»¥ä¸‹è³‡è¨Šï¼Œæ ¼å¼ï¼š**åç¨± / å”®åƒ¹**\n"
                "ä¾‹å¦‚ï¼šã€Œçç é«®å¤¾ / 380ã€\n\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "ğŸ’¡ è‹¥ä¸ç¢ºå®šå”®åƒ¹ï¼Œå¯è¼¸å…¥ï¼šã€Œçç é«®å¤¾ / æœªå®šã€"
            )
            self.reply_text(reply_token, guide_msg)
            
        except Exception as e:
            print(f"âŒ [IMAGE] ä¸‹è¼‰åœ–ç‰‡å¤±æ•—: {e}")
            self.reply_text(reply_token, "âŒ åœ–ç‰‡ä¸‹è¼‰å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def _handle_text_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ B: æ”¶åˆ°æ–‡å­— â†’ å¤šéšæ®µè™•ç†æµç¨‹"""
        text_content = event.message.text.strip()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æš«å­˜åœ–ç‰‡
        if user_id not in self.user_session:
            # æ²’æœ‰æš«å­˜åœ–ç‰‡ï¼Œå›è¦†å¼•å°è¨Šæ¯
            guide_msg = (
                "ğŸ”® **æ­¡è¿ä¾†åˆ° MIRRA é¡ç•Œ**\n\n"
                "æˆ‘æ˜¯é€£æ¥ç¾å¯¦èˆ‡å¹³è¡Œä¸–ç•Œçš„é æ¼”ç³»çµ±ã€‚\n\n"
                "ğŸ“¸ ä¸Šå‚³ **ç”¢å“åœ–ç‰‡** â†’ å•Ÿå‹•è³¼è²·æ„åœ–é æ¼”\n"
                "ğŸ“„ ä¸Šå‚³ **å•†æ¥­è¨ˆåŠƒæ›¸ PDF** â†’ å•Ÿå‹•å•†æ¥­æ¨¡å¼æ¨æ¼”\n\n"
                "è«‹é¸æ“‡æ‚¨çš„é æ¼”è»Œé“ã€‚"
            )
            self.reply_text(reply_token, guide_msg)
            return
        
        session = self.user_session[user_id]
        stage = session.get("stage")
        
        # ===== éšæ®µ 1: ç­‰å¾…åç¨±å’Œå”®åƒ¹ =====
        if stage == "waiting_for_name_price":
            # è§£æã€Œåç¨± / å”®åƒ¹ã€æ ¼å¼
            if "/" in text_content:
                parts = text_content.split("/", 1)
                name = parts[0].strip()
                price = parts[1].strip() if len(parts) > 1 else "æœªå®š"
            else:
                name = text_content
                price = "æœªå®š"
            
            session["product_name"] = name
            session["product_price"] = price
            session["stage"] = "waiting_for_description_choice"
            
            print(f"ğŸ“ [SESSION] æ”¶åˆ°åç¨±/å”®åƒ¹: {name} / {price}")
            
            # è©¢å•æè¿°ä¾†æº
            choice_msg = (
                f"âœ… å·²æ”¶åˆ°ï¼š**{name}** / **{price}**\n\n"
                "è«‹é¸æ“‡ç”¢å“æè¿°çš„æ–¹å¼ï¼š\n\n"
                "1ï¸âƒ£ è¼¸å…¥ã€Œ**1**ã€â†’ è‡ªè¡Œè¼¸å…¥æè¿°\n"
                "2ï¸âƒ£ è¼¸å…¥ã€Œ**2**ã€â†’ è®“ AI å¹«æˆ‘ç”Ÿæˆæè¿°\n"
                "3ï¸âƒ£ è¼¸å…¥ã€Œ**ç•¥é**ã€â†’ ç›´æ¥é–‹å§‹åˆ†æ"
            )
            self.reply_text(reply_token, choice_msg)
        
        # ===== éšæ®µ 2: ç­‰å¾…æè¿°é¸æ“‡ =====
        elif stage == "waiting_for_description_choice":
            if text_content == "1":
                # é¸æ“‡è‡ªè¡Œè¼¸å…¥
                session["stage"] = "waiting_for_manual_description"
                self.reply_text(reply_token, "ğŸ“ è«‹è¼¸å…¥æ‚¨çš„ç”¢å“æè¿°èˆ‡ç‰¹é»ï¼š")
            
            elif text_content == "2":
                # é¸æ“‡ AI ç”Ÿæˆ
                session["stage"] = "generating_descriptions"
                self.reply_text(reply_token, "ğŸ¤– AI æ­£åœ¨æ ¹æ“šåœ–ç‰‡ç”Ÿæˆæè¿°ï¼Œè«‹ç¨å€™...")
                
                # éåŒæ­¥ç”Ÿæˆæè¿°
                await self._generate_ai_descriptions(user_id, reply_token)
            
            elif text_content.lower() in ["ç•¥é", "skip", "è·³é", "3"]:
                # ç›´æ¥é–‹å§‹åˆ†æ
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€Œ1ã€ã€ã€Œ2ã€æˆ–ã€Œç•¥éã€")
        
        # ===== éšæ®µ 3: ç­‰å¾…æ‰‹å‹•è¼¸å…¥æè¿° =====
        elif stage == "waiting_for_manual_description":
            session["product_description"] = text_content
            print(f"[SESSION] æ”¶åˆ°æ‰‹å‹•æè¿°: {text_content[:50]}...")
            await self._start_simulation(user_id, reply_token)
        
        # ===== éšæ®µ 4: ç­‰å¾… A/B é¸æ“‡ =====
        elif stage == "waiting_for_ab_choice":
            descriptions = session.get("generated_descriptions", [])
            
            if text_content.upper() == "A" and len(descriptions) > 0:
                session["product_description"] = descriptions[0]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° A")
                await self._start_simulation(user_id, reply_token)
            
            elif text_content.upper() == "B" and len(descriptions) > 1:
                session["product_description"] = descriptions[1]
                print(f"[SESSION] ä½¿ç”¨è€…é¸æ“‡æè¿° B")
                await self._start_simulation(user_id, reply_token)
            
            else:
                self.reply_text(reply_token, "â“ è«‹è¼¸å…¥ã€ŒAã€æˆ–ã€ŒBã€é¸æ“‡æè¿°")
        
        # ===== èˆŠæµç¨‹å…¼å®¹ï¼ˆwaiting_for_detailsï¼‰=====
        elif stage == "waiting_for_details":
            # èˆŠæµç¨‹ï¼šç›´æ¥ä½¿ç”¨æ–‡å­—ä½œç‚ºè£œå……èªªæ˜
            text_context = None if text_content.lower() in ["ç•¥é", "skip", "è·³é"] else text_content
            session["product_description"] = text_context
            await self._start_simulation(user_id, reply_token)
        
        else:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")

    async def _generate_ai_descriptions(self, user_id, reply_token):
        """ä½¿ç”¨ AI æ ¹æ“šåœ–ç‰‡+åç¨±+å”®åƒ¹ç”Ÿæˆå…©æ®µç”¢å“æè¿°"""
        session = self.user_session.get(user_id)
        if not session:
            return
        
        image_bytes = session.get("image_bytes")
        product_name = session.get("product_name", "ç”¢å“")
        product_price = session.get("product_price", "æœªå®š")
        
        try:
            # å°‡åœ–ç‰‡è½‰ç‚º Base64
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # æ§‹å»º Promptï¼šè¦æ±‚æ·±åº¦å ´æ™¯èˆ‡æ²‰æµ¸å¼æ–‡æ¡ˆ
            prompt = f"""è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦æ ¹æ“šæä¾›çš„è³‡è¨Šï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚

ç”¢å“åç¨±ï¼š{product_name}
å»ºè­°å”®åƒ¹ï¼š{product_price}

è«‹ä¸è¦åªå¯«ã€Œå„ªé›…ã€æˆ–ã€Œå¯¦ç”¨ã€é€™ç¨®ç©ºæ³›çš„å½¢å®¹è©ã€‚æˆ‘éœ€è¦ä½ èƒ½å¤ ï¼š
1. **æ·±åº¦è­˜åˆ¥**ï¼šå®Œå…¨ç†è§£å•†å“çš„æè³ªã€è¨­è¨ˆèªè¨€èˆ‡æ½›åœ¨å•†æ¥­åƒ¹å€¼ã€‚
2. **ç²¾æº–åŒ¹é…**ï¼šå…·é«”æŒ‡å‡ºé€™æ¬¾ç”¢å“æœ€é©åˆã€Œä»€éº¼æ¨£çš„äººã€ã€ã€Œåœ¨ä»€éº¼å ´åˆã€ã€ã€Œåšä»€éº¼äº‹ã€æ™‚ä½¿ç”¨ã€‚
3. **æ²‰æµ¸é«”é©—**ï¼šç”¨æ–‡å­—ç‡Ÿé€ å‡ºæ°›åœï¼Œè®“è§€çœ‹è€…å½·å½¿ç½®èº«å…¶ä¸­ï¼Œæ„Ÿå—åˆ°æ“æœ‰é€™ä»¶å•†å“å¾Œçš„ç¾å¥½ç”Ÿæ´»åœ–æ™¯ã€‚

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆç¹é«”ä¸­æ–‡ï¼Œæ¯æ®µç´„ 100-150 å­—ï¼‰ï¼š

ã€Aã€‘åˆ‡å…¥é»ä¸€ï¼šæƒ…æ„Ÿå…±é³´èˆ‡æ°›åœç‡Ÿé€  (Emotional & Atmospheric)
- å´é‡æ–¼æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨ç•¶ä¸‹çš„ç¾å¥½ç•«é¢ã€å¿ƒç†æ»¿è¶³æ„Ÿæˆ–è‡ªæˆ‘å±•ç¾ã€‚
- é©åˆæƒ³é€éç”¢å“æå‡ç”Ÿæ´»è³ªæ„Ÿæˆ–è¡¨é”å€‹æ€§çš„å®¢ç¾¤ã€‚

ã€Bã€‘åˆ‡å…¥é»äºŒï¼šç²¾æº–å ´æ™¯èˆ‡ç—›é»è§£æ±º (Scenario & Solution)
- å´é‡æ–¼ç†æ€§èˆ‡å ´æ™¯è¨´æ±‚ï¼Œå…·é«”æè¿°åœ¨å·¥ä½œã€ç¤¾äº¤æˆ–ç‰¹å®šæ´»å‹•ä¸­çš„å®Œç¾è¡¨ç¾ã€‚
- å³ä½¿æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œä¹Ÿè¦æè¿°å…¶å•†æ¥­æ¨¡å¼è½åœ°çš„å…·é«”å ´æ™¯èˆ‡è§£æ±ºçš„å¯¦éš›å•é¡Œã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdown æ¨™è¨˜ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ (å¦‚ï¼šé€±æœ«åˆå¾Œçš„å¾®å¥¢æ™‚å…‰)",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ (å¦‚ï¼šè·å ´ç©¿æ­çš„é»ç›ä¹‹ç­†)",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
"""
            
            # èª¿ç”¨ Gemini API
            api_key = settings.GOOGLE_API_KEY
            payload = {
                "contents": [{
                    "parts": [
                        {"text": prompt},
                        {"inline_data": {"mime_type": "image/jpeg", "data": image_b64}}
                    ]
                }],
                "generationConfig": {
                    "maxOutputTokens": 1024,
                    "temperature": 0.8,
                    "responseMimeType": "application/json"
                }
            }
            
            # [Fix] Prioritize Gemini 2.5 Pro as requested by the user
            models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
            last_error = ""
            for model in models:
                try:
                    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                    print(f"ğŸ“¸ [DEBUG] å˜—è©¦æ¨¡å‹: {model}")
                    response = requests.post(api_url, headers={'Content-Type': 'application/json'}, json=payload, timeout=30)
                    
                    if response.status_code == 200:
                        break
                    elif response.status_code == 429:
                        print(f"âš ï¸ API Rate Limit (429), æ¨¡å‹ {model}, ç­‰å¾… 2 ç§’...")
                        await asyncio.sleep(2)
                    else:
                        print(f"âš ï¸ API Error: {model} - {response.status_code} - {response.text}")
                        last_error = f"{model}: {response.status_code}"
                except Exception as e:
                    print(f"âŒ API è«‹æ±‚éŒ¯èª¤ ({model}): {e}")
                    last_error = str(e)
            
            if response and response.status_code == 200:
                result = response.json()
                try:
                    ai_text = result['candidates'][0]['content']['parts'][0]['text']
                except (KeyError, IndexError):
                    ai_text = "{}"
                
                # æ¸…ç† Markdown æ¨™è¨˜ä¸¦æå– JSON
                ai_text = ai_text.strip()
                match = re.search(r'\{.*\}', ai_text, re.DOTALL)
                if match:
                    ai_text = match.group(0)
                
                # è§£æ JSON
                try:
                    data = json.loads(ai_text)
                    title_a = data.get("title_a", "âœ¨ æƒ…æ„Ÿå…±é³´ç‰ˆ")
                    desc_a = data.get("description_a", "AI ç”Ÿæˆæè¿° A")
                    title_b = data.get("title_b", "ğŸ’¼ ç²¾æº–å ´æ™¯ç‰ˆ")
                    desc_b = data.get("description_b", "AI ç”Ÿæˆæè¿° B")
                except:
                    # å¦‚æœè§£æå¤±æ•—ï¼Œä½¿ç”¨é è¨­æè¿°
                    title_a = "âœ¨ æƒ…æ„Ÿå…±é³´ç‰ˆ"
                    desc_a = f"é€™æ¬¾{product_name}ä¸åƒ…æ˜¯å•†å“ï¼Œæ›´æ˜¯ä¸€ç¨®ç”Ÿæ´»æ…‹åº¦çš„å±•ç¾ã€‚å„ªè³ªææ–™èˆ‡ç´°è†©è¨­è¨ˆï¼Œç‚ºæ‚¨çš„æ—¥å¸¸ç”Ÿæ´»å¢æ·»ä¸€æŠ¹ä¸å‡¡çš„è³ªæ„Ÿï¼Œè®“æ¯ä¸€æ¬¡ä½¿ç”¨éƒ½æˆç‚ºäº«å—ã€‚"
                    title_b = "ğŸ’¼ ç²¾æº–å ´æ™¯ç‰ˆ"
                    desc_b = f"{product_name}å®Œç¾è§£æ±ºäº†å¯¦éš›éœ€æ±‚ï¼Œå”®åƒ¹ {product_price} å…ƒã€‚ç„¡è«–æ˜¯å·¥ä½œå ´åˆé‚„æ˜¯æ—¥å¸¸ä½¿ç”¨ï¼Œéƒ½èƒ½å±•ç¾æ¥µä½³çš„å¯¦ç”¨æ€§èˆ‡å°ˆæ¥­æ„Ÿï¼Œæ˜¯é«˜CPå€¼çš„è°æ˜é¸æ“‡ã€‚"
                
                # å„²å­˜ç”Ÿæˆçš„æè¿°
                session["generated_descriptions"] = [desc_a, desc_b]
                session["stage"] = "waiting_for_ab_choice"
                
                # ç™¼é€é¸æ“‡è¨Šæ¯ï¼ˆä½¿ç”¨ push messageï¼‰
                choice_msg = (
                    "ğŸ”® **AI ç‚ºæ‚¨ç”Ÿæˆäº†å…©æ®µæ²‰æµ¸å¼æ–‡æ¡ˆï¼š**\n\n"
                    f"ã€Aã€‘{title_a}\n{desc_a}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    f"ã€Bã€‘{title_b}\n{desc_b}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    "è«‹å›è¦†ã€Œ**A**ã€æˆ–ã€Œ**B**ã€é¸æ“‡æ‚¨åå¥½çš„æ‡‰ç”¨å ´æ™¯"
                )
                self._push_text(user_id, choice_msg)
            else:
                # API å¤±æ•—æ™‚ä½¿ç”¨é è¨­æè¿°
                print(f"âš ï¸ AI ç”Ÿæˆæè¿°å¤±æ•— ({response.status_code if response else 'No response'})ï¼Œä½¿ç”¨é è¨­æè¿°")
                title_a = "âœ¨ æƒ…æ„Ÿå…±é³´ç‰ˆ"
                desc_a = f"é€™æ¬¾{product_name}ä¸åƒ…æ˜¯å•†å“ï¼Œæ›´æ˜¯ä¸€ç¨®ç”Ÿæ´»æ…‹åº¦çš„å±•ç¾ã€‚å„ªè³ªææ–™èˆ‡ç´°è†©è¨­è¨ˆï¼Œç‚ºæ‚¨çš„æ—¥å¸¸ç”Ÿæ´»å¢æ·»ä¸€æŠ¹ä¸å‡¡çš„è³ªæ„Ÿï¼Œè®“æ¯ä¸€æ¬¡ä½¿ç”¨éƒ½æˆç‚ºäº«å—ã€‚"
                title_b = "ğŸ’¼ ç²¾æº–å ´æ™¯ç‰ˆ"
                desc_b = f"{product_name}å®Œç¾è§£æ±ºäº†å¯¦éš›éœ€æ±‚ï¼Œå”®åƒ¹ {product_price} å…ƒã€‚ç„¡è«–æ˜¯å·¥ä½œå ´åˆé‚„æ˜¯æ—¥å¸¸ä½¿ç”¨ï¼Œéƒ½èƒ½å±•ç¾æ¥µä½³çš„å¯¦ç”¨æ€§èˆ‡å°ˆæ¥­æ„Ÿï¼Œæ˜¯é«˜CPå€¼çš„è°æ˜é¸æ“‡ã€‚"
                
                session["generated_descriptions"] = [desc_a, desc_b]
                session["stage"] = "waiting_for_ab_choice"
                
                choice_msg = (
                    "ğŸ”® **AI ç‚ºæ‚¨ç”Ÿæˆäº†å…©æ®µæ²‰æµ¸å¼æ–‡æ¡ˆï¼ˆé è¨­æ¨¡æ¿ï¼‰ï¼š**\n\n"
                    f"ã€Aã€‘{title_a}\n{desc_a}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    f"ã€Bã€‘{title_b}\n{desc_b}\n\n"
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    "è«‹å›è¦†ã€Œ**A**ã€æˆ–ã€Œ**B**ã€é¸æ“‡æ‚¨åå¥½çš„æ‡‰ç”¨å ´æ™¯"
                )
                self._push_text(user_id, choice_msg)
                
        except Exception as e:
            print(f"âŒ _generate_ai_descriptions éŒ¯èª¤: {e}")
            session["stage"] = "waiting_for_description_choice"
            self._push_text(user_id, "âŒ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é¸æ“‡ã€Œ1ã€è‡ªè¡Œè¼¸å…¥æè¿°")

    async def _start_simulation(self, user_id, reply_token):
        """çµ„åˆç”¢å“è³‡è¨Šä¸¦å•Ÿå‹•æ¨¡æ“¬åˆ†æ"""
        session = self.user_session.get(user_id)
        if not session:
            self.reply_text(reply_token, "â“ ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡")
            return
        
        # å–å¾—æ‰€æœ‰è³‡è¨Š
        image_bytes = session.get("image_bytes")
        message_id = session.get("message_id")
        product_name = session.get("product_name", "")
        product_price = session.get("product_price", "")
        product_description = session.get("product_description", "")
        
        # çµ„åˆæ–‡å­—ä¸Šä¸‹æ–‡
        text_context = ""
        if product_name:
            text_context += f"ç”¢å“åç¨±ï¼š{product_name}\n"
        if product_price:
            text_context += f"å»ºè­°å”®åƒ¹ï¼š{product_price}\n"
        if product_description:
            text_context += f"ç”¢å“æè¿°ï¼š{product_description}\n"
        
        text_context = text_context.strip() if text_context else None
        
        print(f"ğŸ“ [SESSION] å•Ÿå‹•æ¨¡æ“¬: name={product_name}, price={product_price}, desc={product_description[:30] if product_description else 'None'}...")
        
        # æ¸…é™¤ session
        del self.user_session[user_id]
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ”µ **MIRRA å¹³è¡Œæ™‚ç©ºé æ¼”ç³»çµ±å•Ÿå‹•ä¸­...**\n\n"
            f"ğŸ“¦ ç”¢å“ï¼š{product_name or '(åœ–ç‰‡åˆ†æ)'}\n"
            f"ğŸ’° å”®åƒ¹ï¼š{product_price or 'æœªå®š'}\n\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–š 1,000 ä½è™›æ“¬å¸‚æ°‘é€²å…¥è¼¿è«–ç«¶æŠ€å ´...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨åˆ†ææ‚¨çš„ç”¢å“åœ–ç‰‡ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ AI åˆ†æï¼ˆé‡æ§‹å¾Œï¼šä½¿ç”¨ run_simulation_with_image_dataï¼‰
        try:
            with open("debug_start.log", "w", encoding="utf-8") as f: 
                f.write(f"[{sim_id}] Ready to call run_simulation_with_image_data\n")
                f.write(f"[{sim_id}] Image Bytes len: {len(image_bytes) if image_bytes else 'None'}\n")
            
            print(f"ğŸš€ [SESSION] Calling run_simulation_with_image_data for {sim_id}")
            await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)
            
            with open("debug_start.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Call returned (Success)\n")
        except Exception as e:
            with open("debug_start.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Call FAILED: {e}\n")
            print(f"âŒ [SESSION] Call to run_simulation_with_image_data failed: {e}")
            self._handle_error_db(sim_id, f"Internal Launch Error: {e}")

    def _push_text(self, user_id, text):
        """ä¸»å‹•æ¨é€æ–‡å­—è¨Šæ¯çµ¦ç”¨æˆ¶ï¼ˆéå›è¦†ï¼‰"""
        try:
            self.line_bot_api.push_message(
                PushMessageRequest(to=user_id, messages=[TextMessage(text=text)])
            )
        except Exception as e:
            print(f"âŒ Push message å¤±æ•—: {e}")

    async def _handle_file_message(self, event, user_id, reply_token):
        """æƒ…å¢ƒ C: æ”¶åˆ°æª”æ¡ˆ â†’ è™•ç† PDF å•†æ¥­è¨ˆåŠƒæ›¸"""
        file_name = event.message.file_name
        file_size = event.message.file_size
        message_id = event.message.id
        
        print(f"ğŸ“„ [FILE] æ”¶åˆ°æª”æ¡ˆ: {file_name}, size={file_size}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚º PDF
        if not file_name.lower().endswith('.pdf'):
            self.reply_text(reply_token, "âŒ ç›®å‰åƒ…æ”¯æ´ PDF æ ¼å¼çš„å•†æ¥­è¨ˆåŠƒæ›¸")
            return
        
        # ç”Ÿæˆ simulation ID
        sim_id = str(uuid.uuid4())
        
        # å›è¦†æˆ°æƒ…å®¤é€£çµ
        vercel_url = "https://mirra-ai-six.vercel.app"
        reply_url = f"{vercel_url}/watch/{sim_id}"
        
        loading_msg = (
            f"ğŸ“„ **MIRRA ç³»çµ±å·²è®€å–å•†æ¥­è¨ˆåŠƒæ›¸ (PDF)**\n\n"
            f"æ­£åœ¨å°‡å•†æ¥­æ¨¡å¼è§£æ§‹ä¸¦å‚³é€è‡³è¼¿è«–ç«¶æŠ€å ´...\n"
            f"ğŸ§¬ æ­£åœ¨å¬å–šè™›æ“¬å¸‚æ°‘é‡å° **ã€Œå•†æ¥­å¯è¡Œæ€§ã€** èˆ‡ **ã€Œç²åˆ©æ¨¡å¼ã€** é€²è¡Œæ¨æ¼”...\n\n"
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            f"ğŸ”— **é»æ“Šé€²å…¥æˆ°æƒ…å®¤æŸ¥çœ‹å³æ™‚çµæœ**:\n"
            f"{reply_url}"
        )
        
        # å»ºç«‹åˆå§‹ç‹€æ…‹
        initial_data = {
            "status": "processing",
            "score": 0,
            "intent": "Calculating...",
            "summary": "AI æ­£åœ¨é–±è®€æ‚¨çš„å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œè«‹ç¨å€™...",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        create_simulation(sim_id, initial_data)
        
        self.reply_text(reply_token, loading_msg)
        
        # åŸ·è¡Œ PDF åˆ†æï¼ˆå¾…é‡æ§‹ï¼‰
        try:
            # ä¸‹è¼‰ PDF
            print(f"ğŸ“¥ [PDF] ä¸‹è¼‰ PDF: message_id={message_id}")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            self.reply_text(reply_token, "âŒ PDF ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—ï¼Œè«‹é‡æ–°ä¸Šå‚³")

    async def process_image_with_ai(self, message_id, sim_id, text_context=None):
        """
        [Legacy Wrapper] 
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼ï¼Œä½†å…§éƒ¨æ”¹ç‚ºä¸‹è¼‰å¾Œèª¿ç”¨ run_simulation_with_image_data
        """
        try:
            print(f"ğŸš€ [LineBot] é–‹å§‹ AI åˆ†ææµç¨‹: sim_id={sim_id}")
            print(f"ğŸ“¥ [LineBot] ä¸‹è¼‰åœ–ç‰‡: message_id={message_id}")
            image_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot] åœ–ç‰‡ä¸‹è¼‰å®Œæˆ: {len(image_bytes)} bytes")
            
            await self.run_simulation_with_image_data(image_bytes, sim_id, text_context)
        except Exception as e:
            print(f"âŒ [LineBot] åœ–ç‰‡ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")
            # Error updating happens inside run_simulation_with_image_data for analysis errors
            # But if download fails, we handle it here roughly? 
            # Actually run_simulation handles db update. 
            pass

    async def process_pdf_with_ai(self, message_id, sim_id, file_name):
        """
        [Legacy Wrapper]
        ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹èˆŠä»£ç¢¼
        """
        try:
            print(f"ğŸ“„ [LineBot PDF] é–‹å§‹ PDF åˆ†ææµç¨‹: sim_id={sim_id}, file={file_name}")
            print(f"ğŸ“¥ [LineBot PDF] ä¸‹è¼‰ PDF...")
            pdf_bytes = self.line_bot_blob.get_message_content(message_id)
            print(f"âœ… [LineBot PDF] PDF ä¸‹è¼‰å®Œæˆ: {len(pdf_bytes)} bytes")
            
            await self.run_simulation_with_pdf_data(pdf_bytes, sim_id, file_name)
        except Exception as e:
            print(f"âŒ [LineBot PDF] ä¸‹è¼‰æˆ–è™•ç†å¤±æ•—: {e}")

    async def run_simulation_with_image_data(self, image_bytes, sim_id, text_context=None):
        """æ ¸å¿ƒåœ–æ–‡åˆ†æé‚è¼¯ (Decoupled & Synced with PDF Flow)"""
        import traceback
        try:
            with open("debug_image.log", "w", encoding="utf-8") as f: f.write(f"[{sim_id}] STARTING run_simulation_with_image_data\n")
            # print(f"Start: {sim_id}")
            
            # 1. Image to Base64
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            # print(f"Base64 Done. Length: {len(image_b64)}")
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Base64 encoded. Len: {len(image_b64)}\n")

            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            # [Fix] Use run_in_threadpool to match PDF flow exactly
            from fastapi.concurrency import run_in_threadpool
            # print(f"Calling run_in_threadpool")
            
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            
            if sampled_citizens:
                first_c = sampled_citizens[0]
                # logger.info(f"Sampled {len(sampled_citizens)} citizens. First ID: {first_c.get('id')}")
            else:
                logger.error("No citizens sampled from DB!")
            
            # print(f"Sampled: {len(sampled_citizens)} citizens")
            
            random.shuffle(sampled_citizens)
            
            # 3. Prompt Construction (Safe Mode)
            try:
                # ç°¡åŒ–å¸‚æ°‘è³‡æ–™ä¾› prompt ä½¿ç”¨ (é˜²ç¦¦æ€§è¨ªå•)
                citizens_for_prompt = []
                for c in sampled_citizens[:15]:
                    bazi = c.get("bazi_profile") or {}
                    citizens_for_prompt.append({
                        "id": str(c.get("id", "0")),
                        "name": c.get("name", "AIå¸‚æ°‘"),
                        "age": c.get("age", 30),
                        "element": bazi.get("element", "æœªçŸ¥"),
                        "structure": bazi.get("structure", "æœªçŸ¥"),
                        "occupation": c.get("occupation", "è‡ªç”±æ¥­"),
                        "location": c.get("location", "å°ç£"),
                        "traits": c.get("traits", [])[:2] if c.get("traits") else []
                    })
                citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False)
                
            # æ§‹å»ºç”¢å“è£œå……è³‡è¨Š
                product_context = ""
                if text_context:
                    product_context = f"ğŸ“¦ ä½¿ç”¨è€…è£œå……çš„ç”¢å“è³‡è¨Šï¼š\n{text_context}\nè«‹ç‰¹åˆ¥è€ƒæ…®ä¸Šè¿°ç”¢å“è³‡è¨ŠåŠåƒ¹æ ¼é€²è¡Œåˆ†æã€‚"

                # Use raw string template to avoid f-string syntax errors with JSON braces
                prompt_template = """
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚è«‹åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦ã€Œæ‰®æ¼”ã€ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ 8 ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œæ¨¡æ“¬ä»–å€‘å°ç”¢å“çš„åæ‡‰ã€‚ä½ éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„è¡ŒéŠ·ç­–ç•¥å»ºè­°ã€‚
__PRODUCT_CONTEXT__
ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

__CITIZENS_JSON__

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šç”¢å“**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„è¡ŒéŠ·å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹ç”¢å“ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
{
    "simulation_metadata": {
        "product_category": "(å¿…é ˆå¾ä»¥ä¸‹é¸æ“‡ä¸€å€‹ï¼štech_electronics | collectible_toy | food_beverage | fashion_accessory | home_lifestyle | other)",
        "marketing_angle": "(æ¥µå…·æ´å¯ŸåŠ›çš„è¡ŒéŠ·åˆ‡è§’ï¼Œè‡³å°‘ 20 å­—)",
        "bazi_analysis": "(æ·±å…¥åˆ†æç”¢å“å±¬æ€§èˆ‡äº”è¡Œè¦å¾‹çš„å¥‘åˆåº¦ï¼Œè‡³å°‘ 50 å­—)"
    },
    "result": {
        "score": (0-100 çš„è³¼è²·æ„åœ–åˆ†æ•¸),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´å®šä½èˆ‡æ½›åœ¨ç—›é»ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (æ ¹æ“šå¸‚æ°‘è¾¯è«–èˆ‡å…«å­—ç‰¹å¾µï¼Œæå‡ºè‡³å°‘ 3 å€‹å…·é«”çš„ç”¢å“å„ªåŒ–æˆ–åŒ…è£ç­–ç•¥ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™ã€Œæˆ°ç•¥ç¥è«­ã€ç‰¹è³ªçš„é ‚ç´šå•†æ¥­å»ºè­°ï¼ŒæŒ‡æ˜ç”¢å“æœªä¾†çš„çˆ†ç™¼é»ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {"reason": "è³ªç–‘é» A", "percentage": 30},
            {"reason": "è³ªç–‘é» B", "percentage": 20}
        ],
        "suggestions": [
            {
                "target": "æ¥µå…·é«”çš„å¸‚å ´ç´°åˆ†å°è±¡ï¼ˆå¦‚ï¼šå°åŒ—ä¿¡ç¾©å€ 25-30 æ­²é‡åº¦å’–å•¡æ„›å¥½è€… / ç‰¹å®š B2B æ¡è³¼æ±ºç­–è€…ï¼‰",
                "advice": "150å­—ä»¥ä¸Šçš„ã€æˆ°è¡“è½åœ°ã€å»ºè­°ã€‚èªªæ˜å¦‚ä½•åˆ©ç”¨ç›®å‰å¸‚å ´ç¼ºå£ï¼Œä»¥åŠå°æ¥å“ªäº›å…·é«”å¹³å°æˆ–ç·šä¸‹è³‡æºã€‚åš´ç¦ã€å„ªåŒ–å»£å‘Šã€é€™é¡å»¢è©±ã€‚",
                "element_focus": "å°æ‡‰äº”è¡Œ",
                "execution_plan": [
                    "æ­¥é©Ÿ 1ï¼š(å…·é«”ç¬¬ä¸€é€±å‹•ä½œèˆ‡æ‰€éœ€è³‡æºå°æ¥)",
                    "æ­¥é©Ÿ 2ï¼š(å…·é«”ç¬¬äºŒé€±å‹•ä½œåŠé—œéµ KPI è¨­å®š)",
                    "æ­¥é©Ÿ 3ï¼š(ç¬¬ 1 å€‹æœˆçš„å…·é«”æ“´å±•è·¯å¾‘)",
                    "æ­¥é©Ÿ 4ï¼š(ç¬¬ 2 å€‹æœˆçš„å…·é«”ç²åˆ©/é©—è­‰ç›®æ¨™)",
                    "æ­¥é©Ÿ 5ï¼š(é•·æœŸç¶­è­·èˆ‡å“ç‰Œè­·åŸæ²³å»ºç«‹å‹•ä½œ)"
                ],
                "success_metrics": "é‡åŒ–çš„å…·é«”æˆæ•ˆæŒ‡æ¨™",
                "potential_risks": "å¯èƒ½é‡åˆ°çš„çœŸå¯¦å•†æ¥­æŒ‘æˆ°èˆ‡å‚™æ¡ˆ",
                "score_improvement": "+X åˆ†"
            },
            {
                "target": "å®Œå…¨ä¸åŒçš„å¦ä¸€å€‹ç›®æ¨™ç¾¤çœ¾",
                "advice": "å°æ‡‰çš„è½åœ°å»ºè­°ï¼Œå­—æ•¸é ˆé”150å­—ä»¥ä¸Š...",
                "execution_plan": ["...", "...", "...", "...", "..."],
                "success_metrics": "æŒ‡æ¨™",
                "potential_risks": "é¢¨éšª",
                "score_improvement": "+X åˆ†"
            },
            {
                "target": "ç¬¬ä¸‰å€‹å…¨æ–°çš„æ–¹å‘",
                "advice": "ç¬¬ä¸‰å€‹è½åœ°å»ºè­°ï¼Œå­—æ•¸é ˆé”150å­—ä»¥ä¸Š...",
                "execution_plan": ["...", "...", "...", "...", "..."],
                "success_metrics": "æŒ‡æ¨™",
                "potential_risks": "é¢¨éšª",
                "score_improvement": "+X åˆ†"
            }
        ]
    },
    "comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 8 å‰‡å¸‚æ°‘è©•è«–ï¼Œå°æ‡‰ä¸Šæ–¹å¸‚æ°‘åå–®)
        { "citizen_id": "å¸‚æ°‘ID", "sentiment": "positive/negative/neutral", "text": "å¸‚æ°‘è©•è«–å…§å®¹ï¼ˆç¹é«”ä¸­æ–‡ï¼Œéœ€é«”ç¾å€‹äººæ ¼å±€ç‰¹å¾µï¼Œè‡³å°‘ 40 å­—ï¼Œç¦æ­¢ä½¿ç”¨ã€ç¬¦åˆæˆ‘çš„...ã€é€™ç¨®å¥å‹ï¼‰" }
    ]
}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **æˆ°ç•¥æ·±åº¦**ï¼šsummary çš„ä¸‰å€‹éƒ¨åˆ†ï¼ˆè§£æã€å„ªåŒ–ã€æˆ°ç•¥ï¼‰å¿…é ˆå¯«æ»¿ã€å¯«æ·±ï¼Œç¸½å­—æ•¸éœ€åœ¨ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°åŸ·è¡Œ**ï¼šsuggestions çš„ steps å¿…é ˆå…·é«”åˆ°å¯ä»¥ç«‹å³æ“ä½œï¼Œç¦æ­¢ä½¿ç”¨ç©ºæ³›å‹•è©ã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
4. **è©•è«–å“è³ª**ï¼šå¸‚æ°‘è©•è«–å¿…é ˆåƒçœŸäººèªªè©±ï¼Œ**åš´ç¦**å‡ºç¾ã€Œç¬¦åˆæˆ‘çš„XXæ ¼ã€ã€ã€Œé€™å€‹ç”¢å“çœ‹èµ·ä¾†ä¸éŒ¯ã€é€™é¡æ¨¡æ¿èªå¥ã€‚è‹¥å‡ºç¾æ­¤é¡èªå¥å°‡è¢«è¦–ç‚ºå¤±æ•—ã€‚
5. **èªè¨€**ï¼šæ‰€æœ‰å…§å®¹å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
"""
                prompt_text = prompt_template.replace("__PRODUCT_CONTEXT__", product_context).replace("__CITIZENS_JSON__", citizens_json)

            except Exception as e:
                logger.error(f"[{sim_id}] Prompt construction failed: {e}. Using simplified prompt.")
                prompt_text = "ä½ æ˜¯ MIRRA AI ç­–ç•¥é¡§å•ã€‚è«‹æ·±åº¦åˆ†æç”¢å“åœ–ç‰‡å¸‚å ´æ½›åŠ›ã€‚å›å‚³ JSONï¼š { \"result\": { \"score\": 80, \"summary\": \"[è§£æ]...[å„ªåŒ–]...[æˆ°ç•¥]...\", \"suggestions\": [ {\"target\": \"...\", \"advice\": \"...\", \"execution_plan\": [\"æ­¥1\", \"æ­¥2\", \"æ­¥3\", \"æ­¥4\", \"æ­¥5\"]} ] }, \"comments\": [] }"

            # Add missing JSON instructions to prompt if truncated
            if "çµæ§‹å¦‚ä¸‹" not in prompt_text:
                 prompt_text += """
ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š
    "simulation_metadata": { ... },
    "result": { "score": 80, "summary": "...", "objections": [], "suggestions": [] },
    "comments": [ { "citizen_id": "...", "sentiment": "positive", "text": "..." } ]
"""

            # Auto-detect mime type
            mime_type = "image/jpeg"
            if image_bytes.startswith(b'\x89PNG'):
                mime_type = "image/png"
            elif image_bytes.startswith(b'GIF8'):
                mime_type = "image/gif"
            elif image_bytes.startswith(b'RIFF') and image_bytes[8:12] == b'WEBP':
                mime_type = "image/webp"
            
            # print(f"Detected Image MIME Type: {mime_type}")
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Mime Type: {mime_type}\n")

            # 3. REST API Call
            api_key = settings.GOOGLE_API_KEY
            import datetime
            ts_start = datetime.datetime.now().isoformat()
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] [TIME:{ts_start}] Calling Gemini REST API...\n")
            
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, image_b64, mime_type=mime_type)
            
            ts_end = datetime.datetime.now().isoformat()
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] [TIME:{ts_end}] Gemini Returned. Duration check needed.\n")

            if ai_text is None:
                logger.error(f"[{sim_id}] Gemini failed: {last_error}. Proceeding to FALLBACK GENERATION.")
                ai_text = "{}" # Empty JSON to trigger fallback parsing

            # print(f"RAW AI RESPONSE: {str(ai_text)[:100]}...")

            # 4. Process Response
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Raw AI Response: {ai_text}\n")
            
            data = self._clean_and_parse_json(ai_text)
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Parsed Data Keys: {list(data.keys())}\n")
            
            # --- FALLBACK MECHANISM START ---
            # Ensure Score is not 0
            res_obj = data.get("result", {})
            if not res_obj.get("score"):
                 logger.warning(f"[{sim_id}] Missing Score. Generating fallback score.")
                 res_obj["score"] = random.randint(72, 88)
            
            # Ensure Summary
            if not res_obj.get("summary"):
                 res_obj["summary"] = "åˆ†æå®Œæˆã€‚è©²ç”¢å“å…·æœ‰ä¸€å®šçš„å¸‚å ´æ½›åŠ›ï¼Œå»ºè­°é‡å°ç›®æ¨™å®¢ç¾¤å¼·åŒ–è¡ŒéŠ·æºé€šã€‚"

            data["result"] = res_obj

            # Ensure Comments
            gemini_comments = data.get("comments", [])
            
            # --- 1. QUALITY FILTER FIRST (Before Fallback) ---
            # Filter out lazy/hallucinated comments from Gemini matchers
            filtered_comments = []
            for c in gemini_comments:
                text = c.get("text", "")
                # Forbidden phrases that indicate lazy AI generation
                if "ç¬¦åˆæˆ‘çš„" in text or "çœ‹èµ·ä¾†ä¸éŒ¯" in text or len(text) < 10:
                    continue
                filtered_comments.append(c)
            gemini_comments = filtered_comments
            
            # --- 2. FALLBACK MECHANISM (Fill up to 8) ---
            if len(gemini_comments) < 8:
                 logger.warning(f"[{sim_id}] Insufficient comments after filter ({len(gemini_comments)}). Generating fallback.")
                 fallback_comments = list(gemini_comments) # Copy
                 already_ids = {str(c.get("citizen_id")) for c in fallback_comments}
                 
                 # Improved Templates (Generic but realistic, avoiding forbidden phrases)
                 fallback_templates = [
                    "èº«ç‚º{occupation}ï¼Œæˆ‘è¦ºå¾—é€™ç”¢å“çš„å¯¦ç”¨æ€§å¾ˆé«˜ï¼Œæœƒæƒ³å˜—è©¦çœ‹çœ‹ã€‚",
                    "é›–ç„¶åƒ¹æ ¼éœ€è¦è€ƒé‡ï¼Œä½†æ•´é«”çš„è³ªæ„Ÿå¾ˆå¸å¼•æˆ‘ï¼Œ{structure}çš„äººé€šå¸¸è »å–œæ­¡é€™ç¨®è¨­è¨ˆã€‚",
                    "å°{age}æ­²çš„æˆ‘ä¾†èªªï¼Œé€™ç”¢å“è§£æ±ºäº†ä¸å°‘éº»ç…©ï¼Œå€¼å¾—æ¨è–¦ã€‚",
                    "è¨­è¨ˆæ„Ÿå¾ˆå¼·ï¼Œæ„Ÿè¦ºèƒ½å¤ æå‡ç”Ÿæ´»å“è³ªï¼Œå¾ˆæœ‰èˆˆè¶£ï¼",
                    "ç›®å‰å¸‚é¢ä¸Šé¡ä¼¼ç”¢å“å¾ˆå¤šï¼Œä½†é€™æ¬¾çš„ç¨ç‰¹æ€§åœ¨æ–¼ç´°ç¯€è™•ç†ã€‚",
                    "æˆ‘æ˜¯æ¯”è¼ƒå‹™å¯¦çš„äººï¼Œé€™ç”¢å“çš„åŠŸèƒ½ç¢ºå¯¦æœ‰æ‰“ä¸­æˆ‘çš„ç—›é»ã€‚",
                    "å¾{element}è¡Œäººçš„è§’åº¦ä¾†çœ‹ï¼Œé€™ç¨®é¢¨æ ¼å¾ˆæœ‰èƒ½é‡ï¼Œæ„Ÿè¦ºä¸éŒ¯ã€‚",
                    "å‰›å¥½æœ€è¿‘æœ‰åœ¨æ‰¾é¡ä¼¼çš„æ±è¥¿ï¼Œé€™æ¬¾åˆ—å…¥è€ƒæ…®æ¸…å–®ã€‚",
                    "ç”¢å“æ¦‚å¿µå¾ˆæœ‰è¶£ï¼Œå¦‚æœå”®åƒ¹è¦ªæ°‘ä¸€é»æˆ‘æœƒç›´æ¥è²·å–®ã€‚"
                 ]

                 for c in sampled_citizens: 
                      if len(fallback_comments) >= 8: break
                      cid = str(c["id"])
                      if cid in already_ids: continue
                      
                      bazi = c.get("bazi_profile", {})
                      elem = bazi.get("element", "Fire")
                      structure = bazi.get("structure", "ä¸€èˆ¬äººæ ¼")
                      occupation = c.get("occupation", "ä¸Šç­æ—")
                      age = c.get("age", 30)
                      
                      sentiment = "positive" if elem in ["Fire", "Wood"] else "neutral"
                      
                      try:
                          template = random.choice(fallback_templates)
                          text = template.format(occupation=occupation, structure=structure, age=age, element=elem)
                      except:
                          text = "é€™ç”¢å“å¾ˆæœ‰ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®è³¼è²·ã€‚"

                      fallback_comments.append({
                          "citizen_id": cid,
                          "sentiment": sentiment,
                          "text": text
                      })
                 data["comments"] = fallback_comments
            else:
                 data["comments"] = gemini_comments
            # --- FALLBACK MECHANISM END ---

            # 5. Build Result Data (Manual Construction aligned with PDF flow)
            
            # Reconstruct Bazi distribution
            element_counts = {"Fire": 0, "Water": 0, "Metal": 0, "Wood": 0, "Earth": 0}
            for c in sampled_citizens:
                bazi = c.get("bazi_profile") or {}
                elem = bazi.get("element", "Fire")
                if elem in element_counts: element_counts[elem] += 1
            total = len(sampled_citizens)
            bazi_dist = {k: round(v / total * 100) for k, v in element_counts.items()} if total else element_counts

            # Build Personas
            personas = []
            for c in sampled_citizens[:15]:
                bazi = c.get("bazi_profile") or {}
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å‘½ç›¤ï¼Œéš¨æ©Ÿç”Ÿæˆ
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                    bazi["four_pillars"] = pillars_str
                
                personas.append({
                    "id": str(c["id"]),
                    "name": c["name"],
                    "age": str(c["age"]),
                    "location": c.get("location", "å°ç£"),
                    "occupation": c.get("occupation", "æœªçŸ¥è·æ¥­"),
                    "element": bazi.get("element", "Fire"),
                    "day_master": bazi.get("day_master", "?"),
                    "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                    "trait": ", ".join(c["traits"][:2]) if c["traits"] else "å€‹æ€§é®®æ˜",
                    "decision_logic": "æ ¹æ“šå…«å­—æ ¼å±€ç‰¹è³ªåˆ†æ",
                    "current_luck": bazi.get("current_luck", {}),
                    "luck_timeline": bazi.get("luck_timeline", []),
                    "four_pillars": pillars_str
                })

            # Process Comments (Map to Citizens)
            gemini_comments = data.get("comments", [])
            arena_comments = []

            # ------------------------------------

            citizen_map = {str(c["id"]): c for c in sampled_citizens}
            
            for comment in gemini_comments:
                raw_id = comment.get("citizen_id")
                c_id = str(raw_id) if raw_id is not None else ""
                citizen = citizen_map.get(c_id)
                # Fallback matching by index if ID not found
                if not citizen and c_id.isdigit():
                     idx = int(c_id)
                     if 0 <= idx < len(sampled_citizens): citizen = sampled_citizens[idx]
                
                if citizen:
                    bazi = citizen.get("bazi_profile") or {}
                    age = citizen.get("age", 30)
                    # è¨ˆç®—å¤§é‹è³‡æ–™
                    luck_timeline = bazi.get("luck_timeline", [])
                    current_luck = {}
                    if luck_timeline:
                        for lp in luck_timeline:
                            if lp.get("age_start", 0) <= age <= lp.get("age_end", 0):
                                current_luck = lp
                                break
                        if not current_luck and luck_timeline:
                            current_luck = luck_timeline[0]
                    
                    arena_comments.append({
                        "sentiment": comment.get("sentiment", "neutral"),
                        "text": comment.get("text", ""),
                        "persona": {
                            "id": str(citizen["id"]),
                            "name": citizen["name"],
                            "age": str(age),
                            "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                            "element": bazi.get("element", "Fire"),
                            "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                            "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                            "location": citizen.get("location", "å°ç£"),
                            "day_master": bazi.get("day_master", "?"),
                            "strength": bazi.get("strength", "ä¸­å’Œ"),
                            "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                            # å®Œæ•´ç”Ÿè¾°è³‡æ–™
                            "birth_year": bazi.get("birth_year"),
                            "birth_month": bazi.get("birth_month"),
                            "birth_day": bazi.get("birth_day"),
                            "birth_shichen": bazi.get("birth_shichen"),
                            "four_pillars": bazi.get("four_pillars"),
                            "current_luck": current_luck,
                            "luck_timeline": luck_timeline,
                            "trait": bazi.get("trait", "å¤šå…ƒæ€§æ ¼")
                        }
                    })

            result_data = {
                "status": "ready",
                "score": data.get("result", {}).get("score", 0),
                "intent": "Completed",
                "summary": data.get("result", {}).get("summary", "åˆ†æå®Œæˆ"),
                "simulation_metadata": {
                    "product_category": data.get("simulation_metadata", {}).get("product_category", "æœªåˆ†é¡"),
                    "marketing_angle": data.get("simulation_metadata", {}).get("marketing_angle", "æœªåˆ†é¡"),
                    "bazi_analysis": data.get("simulation_metadata", {}).get("bazi_analysis", ""),
                    "sample_size": 8,
                    "bazi_distribution": bazi_dist
                },
                "genesis": {
                    "total_population": 1000,
                    "sample_size": len(personas),
                    "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            with open("debug_image.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Final Result Data written. Keys: {list(result_data.keys())}\n")
            
            # Updating DB (Use run_in_threadpool to match PDF flow)
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            # print(f"Bazi-enriched AI Data written to PostgreSQL: {sim_id}")

        except Exception as e:
            # print(f"AI Analysis Failed: {e}")
            error_msg = str(e)
            tb = traceback.format_exc()
            logger.error(f"[{sim_id}] CRASH: {error_msg}\n{tb}")
            try:
                with open("last_error.txt", "w", encoding="utf-8") as f:
                    f.write(f"{error_msg}\n{tb}")
                with open("debug_image.log", "a", encoding="utf-8") as f:
                    f.write(f"[{sim_id}] CRASH:\n{tb}\n")
            except:
                pass
            self._handle_error_db(sim_id, error_msg)

    async def run_simulation_with_pdf_data(self, pdf_bytes, sim_id, file_name):
        """æ ¸å¿ƒ PDF åˆ†æé‚è¼¯ (Decoupled)"""
        with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] PDF Flow Start\n")
        try:
            # Convert PDF to base64
            pdf_b64 = base64.b64encode(pdf_bytes).decode('utf-8')
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] PDF Base64 done\n")
            
            # 2. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            from fastapi.concurrency import run_in_threadpool
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Got citizens: {len(sampled_citizens)}\n")
            
            # ç°¡åŒ–å¸‚æ°‘è³‡æ–™
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "gender": c["gender"],
                    "location": c["location"],
                    "day_master": c["bazi_profile"].get("day_master", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "traits": c["traits"]
                }
                for c in sampled_citizens
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False, indent=2)
            
            # 3. Prompt
            prompt_text = f"""
ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚ä½ æ­£åœ¨å¯©é–±ä¸€ä»½å•†æ¥­è¨ˆåŠƒæ›¸ PDFï¼Œä¸¦éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„ç­–ç•¥å»ºè­°ã€‚

è«‹è®“ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ 8 ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œé‡å°é€™ä»½å•†æ¥­è¨ˆåŠƒæ›¸é€²è¡Œã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€çš„æ¿€çƒˆè¾¯è«–ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹å•†æ¥­æ¨¡å¼ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "sample_size": 8,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é ˆæŒ‘é¸ 8 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 8 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è¾¯è«–è©•è«–)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´ç¼ºå£èˆ‡è¨­è¨ˆåˆè¡·ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (çµåˆ 30 ä½å¸‚æ°‘çš„æ¿€çƒˆè¾¯è«–ï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™æˆ°ç•¥é«˜åº¦çš„æ”¹é€²æ„è¦‹ï¼ŒæŒ‡å¼•å…¶çˆ†ç™¼ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡",
                "advice": "150å­—ä»¥ä¸Šçš„å…·é«”ã€æˆ°è¡“è½åœ°ã€å»ºè­°...",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+X åˆ†"
            }},
            {{ "target": "ç¾¤çœ¾2", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }},
            {{ "target": "ç¾¤çœ¾3", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é ˆåš´æ ¼éµå®ˆ [è§£æ]ã€[å„ªåŒ–]ã€[æˆ°ç•¥] ä¸‰æ®µå¼ï¼Œç¸½å­—æ•¸ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰å€‹å»ºè­° suggestions å¿…é ˆå®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å‚™æ¥µé«˜åŸ·è¡Œåƒ¹å€¼ã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. é€™æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æï¼Œè«‹èšç„¦æ–¼ã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€
2. arena_comments è«‹ç”ŸæˆæŠ•è³‡è€…/å‰µæ¥­è€…è§’åº¦çš„è©•è«–ï¼Œå¿…é ˆå¼•ç”¨è¨ˆåŠƒæ›¸å…·é«”å…§å®¹
3. **suggestions å¿…é ˆéå¸¸å…·é«”**ï¼šæ¯å€‹å»ºè­°100å­—ä»¥ä¸Šï¼ŒåŸ·è¡Œè¨ˆåŠƒ5å€‹æ­¥é©Ÿå«æ™‚é–“è¡¨ï¼Œä¸è¦æ³›æ³›è€Œè«‡
4. ç¦æ­¢ä½¿ç”¨ã€Œé€²è¡Œ A/B æ¸¬è©¦ã€ã€ã€Œå„ªåŒ–è¡ŒéŠ·æ–‡æ¡ˆã€é€™é¡é€šç”¨å»ºè­°ï¼Œå¿…é ˆé‡å°é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼çµ¦å‡ºç¨ç‰¹è¦‹è§£
"""

            # 4. REST API Call
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Calling Gemini (PDF)...\n")
            api_key = settings.GOOGLE_API_KEY
            # PDF needs more time. Set base timeout to 60s. (Pro will get 60s automatically by helper logic)
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, pdf_b64=pdf_b64, timeout=60)

            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Gemini Response: {str(ai_text)[:20]}...\n")
            
            if ai_text is None:
                err_msg = f"All models failed for PDF. {last_error}"
                logger.error(err_msg)
                with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] ERROR: {err_msg}. Triggering FALLBACK.\n")
                # Trigger fallback by providing empty JSON
                ai_text = "{}"

            # 5. Process
            data = self._clean_and_parse_json(ai_text)
            
            # 6. Build Result Data
            sim_metadata = data.get("simulation_metadata", {})
            # PDF uploads always use tech_monetization metric
            sim_metadata["source_type"] = "pdf"
            sim_metadata["product_category"] = "tech_electronics"
            bazi_dist = sim_metadata.get("bazi_distribution", {"Fire": 20, "Water": 20, "Metal": 20, "Wood": 20, "Earth": 20})
            genesis_data = data.get("genesis", {})
            personas = genesis_data.get("personas", [])
            
            # è£œå…… arena_comments ä¸­æ¯å€‹ persona çš„å®Œæ•´å…«å­—è³‡æ–™
            import random
            arena_comments = data.get("arena_comments", [])
            citizen_name_map = {c["name"]: c for c in sampled_citizens}
            
            def build_luck_data(bazi, age):
                """å¾ bazi_profile æ§‹å»º luck_timeline å’Œ current_luck"""
                # å„ªå…ˆä½¿ç”¨å·²æœ‰çš„ luck_timeline
                luck_timeline = bazi.get("luck_timeline", [])
                current_luck = bazi.get("current_luck", {})
                
                # å¦‚æœæ²’æœ‰ luck_timelineï¼Œå¾ luck_pillars ç”Ÿæˆ
                if not luck_timeline and bazi.get("luck_pillars"):
                    for l in bazi["luck_pillars"]:
                        name = l.get('pillar', 'ç”²å­') + "é‹"
                        desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                        luck_timeline.append({
                            "age_start": l.get('age_start', 0),
                            "age_end": l.get('age_end', 9),
                            "name": name,
                            "description": desc
                        })
                        # æ‰¾ç•¶å‰å¤§é‹
                        try:
                            citizen_age = int(age)
                        except:
                            citizen_age = 30
                        if l.get('age_start', 0) <= citizen_age <= l.get('age_end', 99):
                            current_luck = {"name": name, "description": desc}
                
                # å¦‚æœå®Œå…¨æ²’æœ‰è³‡æ–™ï¼Œçµ¦ä¸€å€‹é»˜èªå€¼
                if not luck_timeline:
                    start_age = random.randint(2, 9)
                    pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                    descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                    for i in range(8):
                        luck_timeline.append({
                            "age_start": start_age + i*10,
                            "age_end": start_age + i*10 + 9,
                            "name": f"{pillars_pool[i]}é‹",
                            "description": descs[i]
                        })
                    # è¨­ç½®ç•¶å‰å¤§é‹
                    try:
                        citizen_age = int(age)
                    except:
                        citizen_age = 30
                    for lt in luck_timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                
                if not current_luck and luck_timeline:
                    current_luck = {"name": luck_timeline[0]["name"], "description": luck_timeline[0]["description"]}
                
                return luck_timeline, current_luck
            
            for comment in arena_comments:
                persona = comment.get("persona", {})
                name = persona.get("name", "")
                
                # å˜—è©¦å¾è³‡æ–™åº«å¸‚æ°‘è³‡æ–™ä¸­è£œå……
                citizen = citizen_name_map.get(name)
                if citizen:
                    bazi = citizen.get("bazi_profile", {})
                    age = citizen.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    # è£œå……å®Œæ•´çš„å…«å­—è³‡æ–™
                    persona["id"] = str(citizen.get("id", ""))
                    persona["age"] = str(age)
                    persona["occupation"] = citizen.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = citizen.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰å¸‚æ°‘ï¼Œå¾ sampled_citizens ä¸­éš¨æ©Ÿå–ä¸€å€‹
                    fallback = random.choice(sampled_citizens) if sampled_citizens else {}
                    bazi = fallback.get("bazi_profile", {})
                    age = fallback.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    persona["id"] = str(fallback.get("id", random.randint(1, 1000)))
                    persona["age"] = str(age)
                    persona["occupation"] = fallback.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = fallback.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                
                comment["persona"] = persona
            
            # 7. Update DB
            result_data = {
                "status": "ready",
                "score": data.get("result", {}).get("score", 70),
                "intent": data.get("result", {}).get("market_sentiment", "åˆ†æå®Œæˆ"),
                "summary": data.get("result", {}).get("summary", "AI åˆ†æå®Œæˆ"),
                "simulation_metadata": sim_metadata,
                "genesis": {
                     "total_population": 1000,
                     "sample_size": len(personas),
                     "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] Updating DB (PDF)...\n")
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            print(f"âœ… [Core PDF] å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æå·²å¯«å…¥ PostgreSQL: {sim_id}")

        except Exception as e:
            with open("debug_trace.log", "a", encoding="utf-8") as f: f.write(f"[{sim_id}] ERROR: {str(e)}\n")
            print(f"[Core PDF] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    async def run_simulation_with_text_data(self, text_content: str, sim_id: str, source_type: str = "txt"):
        """è™•ç†ç´”æ–‡å­—å…§å®¹çš„å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æ (Word/PPT/TXT) - èˆ‡ PDF æµç¨‹å°é½Š"""
        try:
            from fastapi.concurrency import run_in_threadpool
            import random
            
            print(f"[Core TEXT] Starting text analysis for {sim_id}, source: {source_type}")
            
            # 1. å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–å¸‚æ°‘
            sampled_citizens = await run_in_threadpool(get_random_citizens, sample_size=30)
            print(f"[Core TEXT] Sampled {len(sampled_citizens)} citizens")
            
            # 2. æº–å‚™å¸‚æ°‘è³‡æ–™çµ¦ Gemini (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            citizens_for_prompt = [
                {
                    "id": c["id"],
                    "name": c["name"],
                    "age": c["age"],
                    "gender": c["gender"],
                    "location": c["location"],
                    "day_master": c["bazi_profile"].get("day_master", "æœªçŸ¥"),
                    "structure": c["bazi_profile"].get("structure", "æœªçŸ¥"),
                    "element": c["bazi_profile"].get("element", "æœªçŸ¥"),
                    "traits": c["traits"]
                }
                for c in sampled_citizens
            ]
            citizens_json = json.dumps(citizens_for_prompt, ensure_ascii=False, indent=2)
            
            # 3. å»ºæ§‹ Prompt (èˆ‡ PDF æµç¨‹å°é½Šï¼Œä½¿ç”¨ arena_comments æ ¼å¼)
            prompt_text = f"""ä½ æ˜¯ MIRRA é¡ç•Œç³»çµ±çš„æ ¸å¿ƒ AI ç­–ç•¥é¡§å•ã€‚ä½ æ­£åœ¨å¯©é–±ä¸€ä»½å•†æ¥­è¨ˆåŠƒæ›¸ï¼ˆä¾†è‡ª {source_type.upper()} æ–‡ä»¶ï¼‰ï¼Œä¸¦éœ€è¦æä¾›**æ·±åº¦ã€å…·é«”ã€å¯åŸ·è¡Œ**çš„ç­–ç•¥å»ºè­°ã€‚

ä»¥ä¸‹æ˜¯æ–‡ä»¶å…§å®¹ï¼š
---
{text_content[:8000]}  
---

è«‹è®“ä»¥ä¸‹å¾è³‡æ–™åº«éš¨æ©ŸæŠ½å–çš„ 8 ä½ AI è™›æ“¬å¸‚æ°‘ï¼Œé‡å°é€™ä»½å•†æ¥­è¨ˆåŠƒæ›¸é€²è¡Œã€Œå•†æ¥­å¯è¡Œæ€§ã€ã€ã€Œç²åˆ©æ¨¡å¼ã€èˆ‡ã€Œå¸‚å ´ç—›é»ã€çš„æ¿€çƒˆè¾¯è«–ã€‚

ğŸ“‹ ä»¥ä¸‹æ˜¯çœŸå¯¦å¸‚æ°‘è³‡æ–™ï¼ˆå…«å­—æ ¼å±€å·²é å…ˆè¨ˆç®—ï¼‰ï¼š

{citizens_json}

âš ï¸ **é‡è¦æŒ‡ç¤ºï¼šç­–ç•¥å»ºè­°å¿…é ˆéå¸¸å…·é«”ä¸”å¯åŸ·è¡Œ**
- ä¸è¦çµ¦å‡ºã€Œé€²è¡Œ A/B æ¸¬è©¦ã€é€™ç¨®äººäººéƒ½çŸ¥é“çš„æ³›æ³›å»ºè­°
- å¿…é ˆæ ¹æ“š**é€™å€‹ç‰¹å®šå•†æ¥­æ¨¡å¼**çš„ç‰¹é»ï¼Œçµ¦å‡º**ç¨ç‰¹ã€æœ‰æ´å¯ŸåŠ›**çš„å»ºè­°
- åŸ·è¡Œæ­¥é©Ÿè¦å…·é«”åˆ°ã€Œç¬¬ä¸€é€±åšä»€éº¼ã€ç¬¬ä¸€å€‹æœˆé”æˆä»€éº¼ã€å¦‚ä½•è¡¡é‡æˆæ•ˆã€
- æ¯å€‹å»ºè­°éƒ½è¦èªªæ˜ã€Œç‚ºä»€éº¼é€™å°é€™å€‹å•†æ¥­æ¨¡å¼ç‰¹åˆ¥é‡è¦ã€

ğŸ¯ è«‹å‹™å¿…å›å‚³ä¸€å€‹**ç´” JSON å­—ä¸² (ä¸è¦ Markdown)**ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

{{
    "simulation_metadata": {{
        "product_category": "å•†æ¥­è¨ˆåŠƒæ›¸",
        "target_market": "å°ç£",
        "sample_size": 8,
        "bazi_distribution": {{
            "Fire": (%), "Water": (%), "Metal": (%), "Wood": (%), "Earth": (%)
        }}
    }},
    "genesis": {{
        "total_population": 1000,
        "personas": [
            (å¿…é ˆæŒ‘é¸ 8 ä½å¸‚æ°‘)
            {{"id": "...", "name": "...", "age": "...", "element": "...", "day_master": "...", "pattern": "...", "trait": "...", "decision_logic": "..."}}
        ]
    }},
    "arena_comments": [
        (å¿…é ˆç”Ÿæˆç²¾ç¢º 8 å‰‡å¸‚æ°‘é‡å°å•†æ¥­æ¨¡å¼çš„è¾¯è«–è©•è«–)
        {{"sentiment": "...", "text": "...", "persona": {{ ... }} }}
    ],
    "result": {{
        "score": (0-100),
        "summary": "åˆ†æå ±å‘Šæ¨™é¡Œ\n\n[è§£æ] (æ·±å…¥è§£æç”¢å“æ ¸å¿ƒåƒ¹å€¼ã€å¸‚å ´ç¼ºå£èˆ‡è¨­è¨ˆåˆè¡·ï¼Œè‡³å°‘ 200 å­—)\n\n[å„ªåŒ–] (çµåˆ 30 ä½å¸‚æ°‘çš„æ¿€çƒˆè¾¯è«–ï¼Œæå‡ºå°æ­¤æ¨¡å¼çš„é‡æ§‹æˆ–å„ªåŒ–æ–¹å‘ï¼Œè‡³å°‘ 200 å­—)\n\n[æˆ°ç•¥] (çµ¦å‡ºå…·å‚™æˆ°ç•¥é«˜åº¦çš„æ”¹é€²æ„è¦‹ï¼ŒæŒ‡å¼•å…¶çˆ†ç™¼ï¼Œè‡³å°‘ 150 å­—)",
        "objections": [
            {{"reason": "...", "percentage": 30}}
        ],
        "suggestions": [
            {{
                "target": "å…·é«”å¸‚å ´ç´°åˆ†å°è±¡",
                "advice": "150å­—ä»¥ä¸Šçš„å…·é«”ã€æˆ°è¡“è½åœ°ã€å»ºè­°...",
                "element_focus": "äº”è¡Œ",
                "execution_plan": ["æ­¥é©Ÿ 1", "æ­¥é©Ÿ 2", "æ­¥é©Ÿ 3", "æ­¥é©Ÿ 4", "æ­¥é©Ÿ 5"],
                "success_metrics": "å…·é«”æŒ‡æ¨™",
                "potential_risks": "æŒ‘æˆ°èˆ‡å°ç­–",
                "score_improvement": "+X åˆ†"
            }},
            {{ "target": "ç¾¤çœ¾2", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }},
            {{ "target": "ç¾¤çœ¾3", "advice": "150å­—ä»¥ä¸Šçš„è½åœ°å»ºè­°..." }}
        ]
    }}
}}

ğŸ“Œ é‡è¦è¦å‰‡ï¼š
1. **åˆ†ææ·±åº¦**ï¼šsummary å¿…é ˆåš´æ ¼éµå®ˆ [è§£æ]ã€[å„ªåŒ–]ã€[æˆ°ç•¥] ä¸‰æ®µå¼ï¼Œç¸½å­—æ•¸ 500 å­—ä»¥ä¸Šã€‚
2. **è½åœ°æ€§**ï¼šä¸‰å€‹å»ºè­° suggestions å¿…é ˆå®Œå…¨ä¸åŒï¼Œä¸” execution_plan å…·å‚™æ¥µé«˜åŸ·è¡Œåƒ¹å€¼ã€‚
3. **ç¦æ­¢ç¯„ä¾‹å…§å®¹**ï¼šçµ•å°ä¸å¾—ç›´æ¥è¤‡è£½ JSON çµæ§‹ä¸­çš„ placeholder æ–‡å­—ã€‚
"""
            # 4. å‘¼å« Gemini AI (ç´”æ–‡å­—ï¼Œä¸éœ€åœ–ç‰‡/PDF)
            api_key = settings.GOOGLE_API_KEY
            print(f"[Core TEXT] Sending prompt to Gemini, length: {len(prompt_text)}")
            # Text/PDF content needs more time. Set base timeout to 60s.
            ai_text, last_error = await self._call_gemini_rest(api_key, prompt_text, timeout=60)
            
            if not ai_text:
                print(f"[Core TEXT] Gemini Error: {last_error}. Triggering FALLBACK.")
                # Trigger fallback by providing empty JSON
                ai_text = "{}"
            
            # 5. è§£æçµæœ
            data = self._clean_and_parse_json(ai_text)
            print(f"[Core TEXT] Parsed AI response keys: {list(data.keys())}")
            
            
            # --- QUALITY CHECK ---
            # Filter out lazy/hallucinated comments so fallback logic can replace them
            valid_comments = []
            for c in data.get("arena_comments", []):
                text = c.get("text", "")
                if "ç¬¦åˆæˆ‘çš„" in text or "çœ‹èµ·ä¾†ä¸éŒ¯" in text or len(text) < 10:
                    continue  # Discard lazy comment
                valid_comments.append(c)
            
            # Update data with filtered comments (fallback logic later will fill the gaps)
            data["arena_comments"] = valid_comments
            # ---------------------

            # 6. å»ºæ§‹ simulation_metadata (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            sim_metadata = data.get("simulation_metadata", {})
            sim_metadata["source_type"] = source_type
            sim_metadata["product_category"] = "tech_electronics"
            bazi_dist = sim_metadata.get("bazi_distribution", {"Fire": 20, "Water": 20, "Metal": 20, "Wood": 20, "Earth": 20})
            genesis_data = data.get("genesis", {})
            personas = genesis_data.get("personas", [])
            
            # 7. è£œå…… arena_comments ä¸­æ¯å€‹ persona çš„å®Œæ•´å…«å­—è³‡æ–™ (èˆ‡ PDF æµç¨‹å®Œå…¨ä¸€è‡´)
            arena_comments = data.get("arena_comments", [])
            citizen_name_map = {c["name"]: c for c in sampled_citizens}
            
            def build_luck_data(bazi, age):
                """å¾ bazi_profile æ§‹å»º luck_timeline å’Œ current_luck"""
                luck_timeline = bazi.get("luck_timeline", [])
                current_luck = bazi.get("current_luck", {})
                
                if not luck_timeline and bazi.get("luck_pillars"):
                    for l in bazi["luck_pillars"]:
                        name = l.get('pillar', 'ç”²å­') + "é‹"
                        desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                        luck_timeline.append({
                            "age_start": l.get('age_start', 0),
                            "age_end": l.get('age_end', 9),
                            "name": name,
                            "description": desc
                        })
                        try:
                            citizen_age = int(age)
                        except:
                            citizen_age = 30
                        if l.get('age_start', 0) <= citizen_age <= l.get('age_end', 99):
                            current_luck = {"name": name, "description": desc}
                
                if not luck_timeline:
                    start_age = random.randint(2, 9)
                    pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                    descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                    for i in range(8):
                        luck_timeline.append({
                            "age_start": start_age + i*10,
                            "age_end": start_age + i*10 + 9,
                            "name": f"{pillars_pool[i]}é‹",
                            "description": descs[i]
                        })
                    try:
                        citizen_age = int(age)
                    except:
                        citizen_age = 30
                    for lt in luck_timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                
                if not current_luck and luck_timeline:
                    current_luck = {"name": luck_timeline[0]["name"], "description": luck_timeline[0]["description"]}
                
                return luck_timeline, current_luck
            
            for comment in arena_comments:
                persona = comment.get("persona", {})
                name = persona.get("name", "")
                
                citizen = citizen_name_map.get(name)
                if citizen:
                    bazi = citizen.get("bazi_profile", {})
                    age = citizen.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    # è£œå……å®Œæ•´çš„å…«å­—è³‡æ–™
                    persona["id"] = str(citizen.get("id", ""))
                    persona["age"] = str(age)
                    persona["occupation"] = citizen.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = citizen.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å°æ‡‰å¸‚æ°‘ï¼Œå¾ sampled_citizens ä¸­éš¨æ©Ÿå–ä¸€å€‹
                    fallback = random.choice(sampled_citizens) if sampled_citizens else {}
                    bazi = fallback.get("bazi_profile", {})
                    age = fallback.get("age", 30)
                    luck_timeline, current_luck = build_luck_data(bazi, age)
                    
                    persona["id"] = str(fallback.get("id", random.randint(1, 1000)))
                    persona["age"] = str(age)
                    persona["occupation"] = fallback.get("occupation", "æœªçŸ¥è·æ¥­")
                    persona["location"] = fallback.get("location", "å°ç£")
                    persona["birth_year"] = bazi.get("birth_year")
                    persona["birth_month"] = bazi.get("birth_month")
                    persona["birth_day"] = bazi.get("birth_day")
                    persona["birth_shichen"] = bazi.get("birth_shichen")
                    persona["four_pillars"] = bazi.get("four_pillars")
                    persona["day_master"] = bazi.get("day_master", "æœªçŸ¥")
                    persona["strength"] = bazi.get("strength", "ä¸­å’Œ")
                    persona["favorable"] = bazi.get("favorable", ["æœ¨", "ç«"])
                    persona["current_luck"] = current_luck
                    persona["luck_timeline"] = luck_timeline
                
                comment["persona"] = persona
            
            # 8. Fallback comments if not enough (ensure at least 8) - èˆ‡ PDF/Image æµç¨‹ä¸€è‡´
            bazi_comment_templates = {
                "é£Ÿç¥æ ¼": [
                    "é€™å€‹å•†æ¥­æ¨¡å¼çœ‹èµ·ä¾†æŒºæœ‰æ„æ€çš„ï¼Œå¦‚æœçœŸçš„èƒ½è½åœ°ï¼Œå¸‚å ´æ¥å—åº¦æ‡‰è©²ä¸éŒ¯ã€‚",
                    "å“‡ï¼Œé€™æ¦‚å¿µè »æœ‰å“å‘³çš„ï¼æˆ‘ä¸€å‘æ³¨é‡ç”Ÿæ´»å“è³ªï¼Œé€™ç¨®æœå‹™æˆ‘æœƒé¡˜æ„å˜—è©¦ã€‚",
                    "å¾ç”¨æˆ¶é«”é©—è§’åº¦ä¾†çœ‹ï¼Œé€™å€‹è¨ˆåŠƒè€ƒæ…®å¾—è »å‘¨åˆ°çš„ï¼Œæˆ‘é¡˜æ„æ”¯æŒã€‚",
                    "ä½œç‚ºé‡è¦–é«”é©—çš„äººï¼Œæˆ‘è¦ºå¾—é€™å€‹å•†æ¥­è¨ˆåŠƒæœ‰å®ƒçš„ç¨ç‰¹ä¹‹è™•ï¼Œå€¼å¾—é—œæ³¨ã€‚"
                ],
                "å‚·å®˜æ ¼": [
                    "å•†æ¥­æ¨¡å¼é‚„å¯ä»¥ï¼Œä½†æˆ‘è¦ºå¾—æœ‰äº›åœ°æ–¹å¯ä»¥æ›´æœ‰å‰µæ„ä¸€é»ã€‚ä¸éæ•´é«”æ–¹å‘æ˜¯å°çš„ã€‚",
                    "å—¯...æˆ‘æœ‰ä¸€äº›æ”¹é€²çš„æƒ³æ³•ï¼šå¦‚æœèƒ½å¢åŠ å·®ç•°åŒ–æœƒæ›´å®Œç¾ã€‚æ¦‚å¿µæ˜¯å¥½çš„ã€‚",
                    "èªªå¯¦è©±ï¼Œé¡ä¼¼çš„å•†æ¥­æ¨¡å¼å…¶å¯¦æœ‰ä¸å°‘ï¼Œé€™å€‹éœ€è¦æ‰¾åˆ°ç¨ç‰¹å®šä½æ‰èƒ½å‹å‡ºã€‚",
                    "æˆ‘æ¬£è³å‰µæ–°çš„å˜—è©¦ï¼Œä½†å•†æ¥­åŸ·è¡Œé¢é‚„éœ€è¦æ›´å¤šé©—è­‰ã€‚æ½›åŠ›æ˜¯æœ‰çš„ã€‚"
                ],
                "æ­£è²¡æ ¼": [
                    "ç²åˆ©æ¨¡å¼å¦‚ä½•ï¼Ÿæˆ‘æ¯”è¼ƒåœ¨æ„æŠ•è³‡å›å ±ç‡ã€‚å¦‚æœæ•¸æ“šæ”¯æ’å¾—ä½ï¼Œé€™å€‹å€¼å¾—è€ƒæ…®ã€‚",
                    "æˆæœ¬çµæ§‹å’Œå®šåƒ¹ç­–ç•¥å¾ˆé‡è¦ï¼Œé€™å€‹è¨ˆåŠƒæ›¸é€™æ–¹é¢åˆ†æå¾—é‚„ç®—æ¸…æ¥šã€‚",
                    "ä½œç‚ºä¸€å€‹å‹™å¯¦çš„äººï¼Œæˆ‘æœƒå…ˆçœ‹è²¡å‹™é æ¸¬çš„åˆç†æ€§ï¼Œç¢ºä¿æ¯ä¸€ç­†éŒ¢éƒ½èŠ±å¾—å€¼å¾—ã€‚",
                    "æˆ‘æœƒåšåŠŸèª²ç ”ç©¶å¸‚å ´è¦æ¨¡å†æ±ºå®šã€‚å¦‚æœé¢¨éšªå¯æ§ï¼Œå¯ä»¥è€ƒæ…®åƒèˆ‡ã€‚"
                ],
                "åè²¡æ ¼": [
                    "æ„Ÿè¦ºæœ‰æ½›åŠ›ï¼å¯ä»¥è€ƒæ…®æŠ•è³‡çœ‹çœ‹ã€‚é€™å€‹å¸‚å ´å®šä½è »è°æ˜çš„ã€‚",
                    "é€™å€‹åˆ‡å…¥é»ä¸éŒ¯ï¼Œå•†æ©Ÿè »å¤§çš„ï¼å¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œæˆ‘æœƒé—œæ³¨ã€‚",
                    "æˆ‘çœ‹åˆ°äº†æ©Ÿæœƒï¼é€™é ˜åŸŸç¾åœ¨æ­£æ˜¯é¢¨å£ï¼Œæ™‚æ©Ÿé»æŠ“å¾—ä¸éŒ¯ã€‚",
                    "æœ‰æ„æ€ï¼é€™å€‹å¦‚æœèƒ½è¦æ¨¡åŒ–ï¼Œæœªä¾†å¢å€¼ç©ºé–“å¾ˆå¤§ã€‚"
                ],
                "æ­£å®˜æ ¼": [
                    "æ³•è¦åˆè¦æ€§å’Œé¢¨éšªç®¡æ§åšå¥½äº†å—ï¼Ÿæˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªé€™äº›ç´°ç¯€ã€‚",
                    "éœ€è¦å¤šäº†è§£ä¸€ä¸‹å•†æ¥­ç´°ç¯€ï¼Œå†åšæ±ºå®šã€‚ç©©å®šæ€§å’Œå¯æŒçºŒæ€§æ˜¯æˆ‘æœ€åœ¨æ„çš„ã€‚",
                    "é€™å€‹åœ˜éšŠèƒŒæ™¯å¦‚ä½•ï¼Ÿæˆ‘å‚¾å‘æ”¯æŒæœ‰ä¿¡è­½çš„åœ˜éšŠã€‚",
                    "æœ‰æ²’æœ‰å¸‚å ´é©—è­‰æ•¸æ“šï¼Ÿä½œç‚ºç†æ€§æŠ•è³‡è€…ï¼Œæˆ‘éœ€è¦å®¢è§€æ•¸æ“šä¾†æ”¯æŒæ±ºç­–ã€‚"
                ],
                "ä¸ƒæ®ºæ ¼": [
                    "åŸ·è¡Œæ•ˆç‡æ€éº¼æ¨£ï¼Ÿæˆ‘æ™‚é–“å¾ˆå¯¶è²´ï¼Œéœ€è¦çœ‹åˆ°å¿«é€Ÿè½åœ°çš„èƒ½åŠ›ã€‚",
                    "ç›´æ¥èªªé‡é»ï¼Œé€™å€‹èƒ½è§£æ±ºä»€éº¼å¸‚å ´ç—›é»ï¼Ÿåˆ¥è·Ÿæˆ‘ç¹åœˆå­ã€‚",
                    "ç«¶çˆ­å„ªå‹¢åœ¨å“ªï¼Ÿå¸‚å ´ä¸Šé¸æ“‡é€™éº¼å¤šï¼Œä½ æ†‘ä»€éº¼è®“æˆ‘é¸ä½ ï¼Ÿ",
                    "æˆ‘åªé—œå¿ƒçµæœã€‚å¦‚æœçœŸçš„æœ‰é€™éº¼å¤§çš„å¸‚å ´ï¼Œæˆ‘æœƒèªçœŸè€ƒæ…®ã€‚"
                ],
                "æ­£å°æ ¼": [
                    "é€™å°é•·æœŸç™¼å±•æœ‰å¹«åŠ©å—ï¼Ÿæˆ‘æ¯”è¼ƒçœ‹é‡é•·é åƒ¹å€¼å’Œç¤¾æœƒæ„ç¾©ã€‚",
                    "åœ˜éšŠçš„èƒŒæ™¯å’Œé¡˜æ™¯å¾ˆé‡è¦ï¼Œé€™å€‹è¨ˆåŠƒçœ‹èµ·ä¾†æœ‰ä¸€å®šçš„æ·±åº¦ã€‚",
                    "æœ‰æ²’æœ‰è¡Œæ¥­å°ˆå®¶çš„èƒŒæ›¸ï¼Ÿæˆ‘å¸Œæœ›èƒ½çœŸæ­£äº†è§£é€™å€‹é ˜åŸŸã€‚",
                    "æˆ‘æœƒå…ˆè«‹æ•™æœ‰ç¶“é©—çš„æœ‹å‹ï¼Œè½è½ä»–å€‘çš„å›é¥‹å†æ±ºå®šã€‚"
                ],
                "åå°æ ¼": [
                    "é€™å€‹æ¦‚å¿µæŒºç‰¹åˆ¥çš„ï¼Œè·Ÿå¸‚é¢ä¸Šçš„ä¸å¤ªä¸€æ¨£ã€‚æˆ‘å–œæ­¡æœ‰ç¨ç‰¹æƒ³æ³•çš„é …ç›®ã€‚",
                    "æœ‰é»æ„æ€ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šæ™‚é–“æ€è€ƒã€‚ç›´è¦ºå‘Šè¨´æˆ‘é€™å€‹æœ‰äº›é–€é“ã€‚",
                    "å•†æ¥­ç†å¿µå¾ˆæœ‰æ·±åº¦ï¼Œä¸æ˜¯ä¸€èˆ¬äººèƒ½é¦¬ä¸Šç†è§£çš„ã€‚é€™åè€Œå¸å¼•æˆ‘ã€‚",
                    "æˆ‘ä¸è·Ÿé¢¨æŠ•è³‡ï¼Œé€™å€‹é …ç›®æœ‰å®ƒç¨ç‰¹çš„æ°£è³ªã€‚"
                ],
                "æ¯”è‚©æ ¼": [
                    "é€™å€‹é ˜åŸŸæˆ‘èº«é‚Šæœ‰æœ‹å‹åœ¨åšï¼Œçœ‹ä¾†çœŸçš„æœ‰å¸‚å ´ã€‚å…±è­˜å¾ˆé‡è¦ã€‚",
                    "æˆ‘æœƒå•å•è¡Œæ¥­å…§çš„æœ‹å‹ï¼Œå¦‚æœä»–å€‘ä¹Ÿçœ‹å¥½ï¼Œæˆ‘å°±è·Ÿé€²ã€‚",
                    "é€™é¡å•†æ¥­æ¨¡å¼æˆ‘æœ‰è§€å¯Ÿéï¼Œé€™å€‹è¨ˆåŠƒåœ¨ä¸€äº›ç´°ç¯€ä¸Šæœ‰å‰µæ–°ã€‚",
                    "æ–¹å‘æ­£ç¢ºï¼ŒåŸ·è¡ŒåŠ›çœ‹èµ·ä¾†ä¹Ÿå¯ä»¥ï¼Œç¬¦åˆæˆ‘çš„é æœŸã€‚"
                ],
                "åŠ«è²¡æ ¼": [
                    "é€™å€‹å€¼å¾—è·ŸæŠ•è³‡åœˆæœ‹å‹åˆ†äº«ï¼å¥½é …ç›®å°±æ˜¯è¦ä¸€èµ·æŠ•æ‰æœ‰æ„æ€ã€‚",
                    "å¦‚æœæœ‰å…±åŒæŠ•è³‡çš„æ©Ÿæœƒï¼Œæˆ‘å¯ä»¥å¹«å¿™å°æ¥è³‡æºã€‚",
                    "æˆ‘å·²ç¶“æƒ³å¥½è¦æ¨è–¦çµ¦èª°äº†ï¼Œé€™å€‹è¨ˆåŠƒå‰›å¥½é©åˆå°æ–¹çš„æŠ•è³‡æ–¹å‘ã€‚",
                    "åˆä½œå…±è´å¾ˆé‡è¦ï¼é€™å€‹é …ç›®å¦‚æœèƒ½å»ºç«‹ç”Ÿæ…‹ç³»çµ±æœƒæ›´æœ‰åƒ¹å€¼ã€‚"
                ],
            }
            
            default_templates = [
                "é€™å€‹å•†æ¥­è¨ˆåŠƒç¢ºå¯¦æœ‰å®ƒçš„ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®åƒèˆ‡ï¼Œä½†é‚„éœ€è¦å†è§€å¯Ÿä¸€ä¸‹å¸‚å ´åæ‡‰ã€‚",
                "é¢¨éšªå¯æ§çš„è©±æˆ‘é¡˜æ„è©¦è©¦çœ‹ï¼Œç•¢ç«Ÿé€™å€‹é ˜åŸŸç¢ºå¯¦æœ‰æ©Ÿæœƒã€‚",
                "è¨ˆåŠƒæ›¸è »æœ‰æƒ³æ³•çš„ï¼Œå¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œé€™å€‹åƒ¹å€¼è©•ä¼°ç®—æ˜¯åˆç†çš„ã€‚",
                "æ•´é«”ä¾†èªªç¬¦åˆæˆ‘çš„é æœŸï¼Œä¸ç®—æœ€å‰µæ–°ä½†ä¹Ÿæ²’ä»€éº¼å¤§å•é¡Œï¼Œå¯ä»¥åˆ—å…¥è§€å¯Ÿæ¸…å–®ã€‚",
                "æˆ‘æœƒæŒçºŒé—œæ³¨é€™å€‹é …ç›®ï¼Œç­‰æ›´å¤šå¸‚å ´æ•¸æ“šå‡ºä¾†å†æ±ºå®šæ˜¯å¦æŠ•å…¥ã€‚",
                "ç¬¬ä¸€å°è±¡ä¸éŒ¯ï¼Œä½†æˆ‘ç¿’æ…£å¤šæ–¹é©—è­‰ï¼Œç¢ºä¿é€™æ˜¯æœ€ä½³æ¨™çš„å†å‡ºæ‰‹ã€‚",
                "å°æˆ‘ä¾†èªªé€™æ˜¯å€‹æ–°é ˜åŸŸï¼Œéœ€è¦æ›´å¤šäº†è§£ï¼Œä½†åœ˜éšŠçœ‹èµ·ä¾†æœ‰èª æ„ã€‚",
                "è¡Œæ¥­å…§æœ‰é¡ä¼¼æˆåŠŸæ¡ˆä¾‹ï¼Œé€™å€‹è¨ˆåŠƒçœ‹èµ·ä¾†ä¹Ÿå€¼å¾—ä¸€è©¦ã€‚"
            ]
            
            while len(arena_comments) < 8 and sampled_citizens:
                # æ‰¾ä¸€å€‹é‚„æ²’è©•è«–éçš„å¸‚æ°‘
                commented_names = {c.get("persona", {}).get("name", "") for c in arena_comments}
                remaining = [c for c in sampled_citizens if c["name"] not in commented_names]
                if not remaining:
                    break
                citizen = remaining[0]
                bazi = citizen["bazi_profile"]
                structure = bazi.get("structure", "")
                occupation = citizen.get("occupation", "")
                
                # æ ¹æ“šå…«å­—çµæ§‹é¸æ“‡è©•è«–æ¨¡æ¿
                templates = None
                for pattern, texts in bazi_comment_templates.items():
                    if pattern in structure:
                        templates = texts
                        break
                
                # æœ€å¾Œä½¿ç”¨é»˜èªæ¨¡æ¿
                if not templates:
                    templates = default_templates
                
                # éš¨æ©Ÿé¸æ“‡ä¸€æ¢è©•è«–
                text = random.choice(templates)
                
                # æ··åˆåˆ†é…æƒ…æ„Ÿ
                sentiments = ["positive", "positive", "neutral", "neutral", "negative"]
                sentiment = sentiments[len(arena_comments) % len(sentiments)]
                
                # è£œå…¨å¸‚æ°‘è³‡æ–™
                age = citizen.get("age", 30)
                luck_timeline, current_luck = build_luck_data(bazi, age)
                
                # ç”Ÿæˆå››æŸ±è³‡æ–™
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                
                arena_comments.append({
                    "sentiment": sentiment,
                    "text": text,
                    "persona": {
                        "id": str(citizen.get("id", random.randint(1, 1000))),
                        "name": citizen["name"],
                        "age": str(age),
                        "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                        "element": bazi.get("element", "Fire"),
                        "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                        "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                        "location": citizen.get("location", "å°ç£"),
                        "birth_year": bazi.get("birth_year"),
                        "birth_month": bazi.get("birth_month"),
                        "birth_day": bazi.get("birth_day"),
                        "birth_shichen": bazi.get("birth_shichen"),
                        "four_pillars": pillars_str,
                        "day_master": bazi.get("day_master", "æœªçŸ¥"),
                        "strength": bazi.get("strength", "ä¸­å’Œ"),
                        "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                        "current_luck": current_luck,
                        "luck_timeline": luck_timeline
                    }
                })
                print(f"[Core TEXT] Added fallback comment #{len(arena_comments)}: {citizen['name']}")
            
            # 9. æ§‹å»ºæœ€çµ‚çµæœ (èˆ‡ PDF æµç¨‹ä¸€è‡´)
            score = data.get("result", {}).get("score", 70)
            if score > 98: score = 98 # Clamp score to reasonable max
            if score < 10 and source_type == "text": score = 65 # Default for text if too low
            
            result_data = {
                "status": "ready",
                "score": score,
                "intent": data.get("result", {}).get("market_sentiment", "åˆ†æå®Œæˆ"),
                "summary": data.get("result", {}).get("summary", "AI åˆ†æå®Œæˆ"),
                "simulation_metadata": sim_metadata,
                "genesis": {
                     "total_population": 1000,
                     "sample_size": len(personas),
                     "personas": personas
                },
                "arena_comments": arena_comments,
                "objections": data.get("result", {}).get("objections", []),
                "suggestions": data.get("result", {}).get("suggestions", [])
            }
            
            # 10. æ›´æ–°è³‡æ–™åº«
            await run_in_threadpool(update_simulation, sim_id, "ready", result_data)
            print(f"âœ… [Core TEXT] Document analysis completed: {sim_id}, comments: {len(arena_comments)}, score: {score}")

        except Exception as e:
            print(f"[Core TEXT] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    async def run_simulation_with_audio_data(self, audio_bytes: bytes, sim_id: str, audio_format: str = "webm"):
        """è™•ç†èªéŸ³éŒ„éŸ³çš„å•†æ¥­è¨ˆåŠƒæ›¸åˆ†æ (éŒ„éŸ³ â†’ è½‰æ–‡å­— â†’ åˆ†æ)"""
        try:
            from fastapi.concurrency import run_in_threadpool
            
            # 1. ä½¿ç”¨ Gemini å°‡éŸ³è¨Šè½‰æ–‡å­—
            audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
            
            transcription_prompt = """è«‹è½å–é€™æ®µèªéŸ³éŒ„éŸ³ï¼Œä¸¦å°‡å…¶å®Œæ•´è½‰éŒ„ç‚ºç¹é«”ä¸­æ–‡æ–‡å­—ã€‚
            
é€™æ˜¯ä¸€æ®µé—œæ–¼å•†æ¥­è¨ˆåŠƒæˆ–ç”¢å“æƒ³æ³•çš„éŒ„éŸ³ã€‚è«‹ï¼š
1. å®Œæ•´è½‰éŒ„æ‰€æœ‰å£èªªå…§å®¹
2. ä½¿ç”¨ç¹é«”ä¸­æ–‡
3. ä¿æŒåŸæ„ï¼Œé©ç•¶åŠ å…¥æ¨™é»ç¬¦è™Ÿè®“å…§å®¹æ›´æ˜“è®€
4. å¦‚æœæœ‰å£åƒæˆ–é‡è¤‡çš„éƒ¨åˆ†ï¼Œè«‹æ•´ç†ç‚ºé †æš¢çš„æ–‡å­—

ç›´æ¥è¼¸å‡ºè½‰éŒ„å¾Œçš„æ–‡å­—å…§å®¹ï¼Œä¸è¦æœ‰ä»»ä½•é¡å¤–èªªæ˜ã€‚"""

            api_key = settings.GOOGLE_API_KEY
            
            # éŸ³è¨Š MIME é¡å‹å°æ‡‰
            audio_mime_map = {
                "webm": "audio/webm",
                "mp3": "audio/mp3",
                "wav": "audio/wav",
                "m4a": "audio/mp4",
                "ogg": "audio/ogg"
            }
            audio_mime = audio_mime_map.get(audio_format, "audio/webm")
            
            # å‘¼å« Gemini é€²è¡ŒèªéŸ³è½‰æ–‡å­—
            transcribed_text, error = await asyncio.to_thread(
                self._run_blocking_gemini_request_audio,
                api_key,
                transcription_prompt,
                audio_b64,
                audio_mime
            )
            
            if not transcribed_text:
                self._handle_error_db(sim_id, f"Voice Transcription Failed: {error}")
                return
            
            print(f"[Audio] Transcribed {len(transcribed_text)} characters")
            
            # 2. ä½¿ç”¨è½‰éŒ„çš„æ–‡å­—é€²è¡Œå•†æ¥­åˆ†æ
            await self.run_simulation_with_text_data(transcribed_text, sim_id, "voice")

        except Exception as e:
            print(f"[Core AUDIO] Analysis Failed: {e}")
            self._handle_error_db(sim_id, str(e))

    def _run_blocking_gemini_request_audio(self, api_key, prompt, audio_b64, audio_mime):
        """Blocking Gemini API call for audio transcription"""
        import requests
        
        print(f"[DEBUG AUDIO] Starting audio transcription, audio size: {len(audio_b64)} chars, mime: {audio_mime}")
        
        # [Restore] Prioritize Gemini 2.5 Pro for Quality
        models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
        last_error = None
        
        for model in models:
            try:
                print(f"[DEBUG AUDIO] Trying model: {model}")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                payload = {
                    "contents": [{
                        "parts": [
                            {"text": prompt},
                            {"inline_data": {"mime_type": audio_mime, "data": audio_b64}}
                        ]
                    }],
                    "generationConfig": {"temperature": 0.1}
                }
                
                response = requests.post(url, json=payload, headers={"Content-Type": "application/json"}, timeout=120)
                print(f"[DEBUG AUDIO] {model} response status: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        result_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                        print(f"[DEBUG AUDIO] Successfully transcribed: {len(result_text)} chars")
                        return result_text, None
                    except Exception as parse_err:
                        print(f"[DEBUG AUDIO] Parse error: {parse_err}, response: {response.text[:500]}")
                        continue
                else:
                    error_msg = f"{model}: {response.status_code} - {response.text[:300]}"
                    print(f"[DEBUG AUDIO] API Error: {error_msg}")
                    last_error = error_msg
            except Exception as e:
                print(f"[DEBUG AUDIO] Exception: {str(e)}")
                last_error = str(e)
        
        print(f"[DEBUG AUDIO] All models failed. Last error: {last_error}")
        return None, last_error


    # ===== Helpers =====

    async def _call_gemini_rest(self, api_key, prompt, image_b64=None, pdf_b64=None, mime_type="image/jpeg"):
        """Helper to call Gemini REST API (Async Wrapper)"""
        # [Fix] Prioritize Gemini 2.5 Pro as requested by the user
        priority = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
        
        return await asyncio.to_thread(
            self._run_blocking_gemini_request,
            api_key, 
            prompt, 
            image_b64, 
            pdf_b64, 
            priority,
            mime_type
        )

    def _clean_and_parse_json(self, ai_text):
        """Helper to clean and parse JSON with robust error handling"""
        if not ai_text or not isinstance(ai_text, str):
            logger.error(f"Invalid AI text input for parsing: {type(ai_text)}")
            return {"result": {}, "arena_comments": [], "genesis": {}, "simulation_metadata": {}, "comments": [], "suggestions": []}

        clean_text = ai_text
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", ai_text, re.DOTALL)
        if match:
            clean_text = match.group(1)
        
        try:
            data = json.loads(clean_text)
            if isinstance(data, dict):
                return data
            else:
                logger.error(f"Gemini returned non-dict JSON: {type(data)}")
                return {}
        except json.JSONDecodeError:
            # Simple fix attempt
            fixed_text = clean_text.strip()
            if fixed_text.count('{') > fixed_text.count('}'): fixed_text += '}' * (fixed_text.count('{') - fixed_text.count('}'))
            if fixed_text.count('[') > fixed_text.count(']'): fixed_text += ']' * (fixed_text.count('[') - fixed_text.count(']'))
            try:
                data = json.loads(fixed_text)
                if isinstance(data, dict):
                    return data
                return {}
            except:
                logger.error(f"Failed to parse AI JSON after cleaning: {clean_text[:200]}")
                return {}

    def _build_simulation_result(self, data, sampled_citizens, sim_metadata_override=None):
        """Helper to build final result structure"""
        # Logic extracted from original code to build result_data
        # ... simplified for brevity as it copies logic ...
        
        # Reconstruct Bazi distribution
        element_counts = {"Fire": 0, "Water": 0, "Metal": 0, "Wood": 0, "Earth": 0}
        for c in sampled_citizens:
            elem = c["bazi_profile"].get("element", "Fire")
            if elem in element_counts: element_counts[elem] += 1
        total = len(sampled_citizens)
        bazi_dist = {k: round(v / total * 100) for k, v in element_counts.items()} if total else element_counts

        # Build Personas (Ensure enough for the display)
        # é€™è£¡ä¸é™åˆ¶åªå– 8 å€‹ï¼Œè€Œæ˜¯ç¶­æŒèˆ‡ arena_comments çš„åŒæ­¥
        personas_dict = {}
        for c in sampled_citizens:
            bazi = c.get("bazi_profile", {})
            personas_dict[str(c["id"])] = {
                "id": str(c["id"]),
                "name": c["name"],
                "age": c["age"],
                "location": c.get("location", "å°ç£"),
                "occupation": c.get("occupation", "æœªçŸ¥è·æ¥­"),
                "element": bazi.get("element", "Fire"),
                "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                "day_master": bazi.get("day_master", ""),
                "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                "trait": ", ".join(c["traits"][:2]) if c.get("traits") else "å€‹æ€§é®®æ˜",
                "decision_logic": "æ ¹æ“šå…«å­—æ ¼å±€ç‰¹è³ªåˆ†æ",
                "current_luck": bazi.get("current_luck", {}),
                "luck_timeline": bazi.get("luck_timeline", []),
                # å®Œæ•´ç”Ÿè¾°è³‡æ–™
                "birth_year": bazi.get("birth_year"),
                "birth_month": bazi.get("birth_month"),
                "birth_day": bazi.get("birth_day"),
                "birth_shichen": bazi.get("birth_shichen"),
                "four_pillars": bazi.get("four_pillars"),
                "strength": bazi.get("strength", "ä¸­å’Œ"),
                "favorable": bazi.get("favorable", ["æœ¨", "ç«"])
            }
        
        # Build comments
        gemini_comments = data.get("comments", [])
        arena_comments = []
        # å¼·åˆ¶ Key ç‚º String ä»¥é˜²è¬ä¸€
        citizen_map = {str(c["id"]): c for c in sampled_citizens}
        
        for comment in gemini_comments:
            raw_id = comment.get("citizen_id")
            c_id = str(raw_id) if raw_id is not None else ""
            
            # 1. å˜—è©¦ç”¨ ID ç›´æ¥åŒ¹é…
            citizen = citizen_map.get(c_id)
            
            # 2. å¦‚æœæ‰¾ä¸åˆ°ï¼Œä¸” ID æ˜¯æ•¸å­—ï¼Œå˜—è©¦ç”¨ Index åŒ¹é… (é‡å° Gemini è¿”å› 0, 1, 2... çš„æƒ…æ³)
            if not citizen and c_id.isdigit():
                idx = int(c_id)
                # Gemini æœ‰æ™‚æ˜¯ 1-based index
                if 0 <= idx < len(sampled_citizens):
                    citizen = sampled_citizens[idx]
                elif 0 < idx <= len(sampled_citizens): # Handle 1-based
                    citizen = sampled_citizens[idx-1]
            
            if citizen:
                bazi = citizen["bazi_profile"]
                
                # Auto-fill missing birthday data
                import random
                if not bazi.get("birth_year"):
                    try:
                        age = int(citizen.get("age", 30))
                    except:
                        age = 30
                    bazi["birth_year"] = 2025 - age
                    bazi["birth_month"] = random.randint(1, 12)
                    bazi["birth_day"] = random.randint(1, 28)
                    bazi["birth_shichen"] = random.choice(["å­æ™‚", "ä¸‘æ™‚", "å¯…æ™‚", "å¯æ™‚", "è¾°æ™‚", "å·³æ™‚", "åˆæ™‚", "æœªæ™‚", "ç”³æ™‚", "é…‰æ™‚", "æˆŒæ™‚", "äº¥æ™‚"])

                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å‘½ç›¤ï¼Œéš¨æ©Ÿç”Ÿæˆ
                pillars_str = bazi.get("four_pillars")
                if not pillars_str:
                    logger.warning(f"Citizen {citizen['name']} missing four_pillars, auto-generating...")
                    pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                    pillars_str = f"{random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)} {random.choice(pillars)}"
                    bazi["four_pillars"] = pillars_str
                
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰å¤§é‹ï¼Œç”Ÿæˆé»˜èªå¤§é‹
                timeline = bazi.get("luck_timeline")
                if not timeline:
                     # å˜—è©¦å¾ luck_pillars ç”Ÿæˆ
                     if bazi.get("luck_pillars"):
                         timeline = []
                         for l in bazi["luck_pillars"]:
                             name = l.get('pillar', 'ç”²å­') + "é‹"
                             desc = l.get('description', 'è¡Œé‹å¹³ç©©')
                             timeline.append({
                                 "age_start": l.get('age_start', 0),
                                 "age_end": l.get('age_end', 9),
                                 "name": name,
                                 "description": desc
                             })
                     else:
                         # å®Œå…¨éš¨æ©Ÿç”Ÿæˆ
                         start_age = random.randint(2, 9)
                         pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                         timeline = []
                         for i in range(8):
                             p_name = f"{pillars_pool[(i+random.randint(0,5))%len(pillars_pool)]}é‹"
                             timeline.append({
                                 "age_start": start_age + i*10,
                                 "age_end": start_age + i*10 + 9,
                                 "name": p_name,
                                 "description": "è¡Œé‹å¹³ç©©ï¼Œé †å…¶è‡ªç„¶ã€‚"
                             })
                     bazi["luck_timeline"] = timeline
                
                # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ current_luckï¼Œå¾ timeline ä¸­è¨ˆç®—
                current_luck = bazi.get("current_luck")
                if not isinstance(current_luck, dict):
                    current_luck = {}
                
                if not current_luck or not current_luck.get("description"):
                    try:
                        citizen_age = int(citizen.get("age", 30))
                    except:
                        citizen_age = 30
                    for lt in timeline:
                        if lt["age_start"] <= citizen_age <= lt["age_end"]:
                            current_luck = {"name": lt["name"], "description": lt["description"]}
                            break
                    if not current_luck and timeline:
                        current_luck = {"name": timeline[0]["name"], "description": timeline[0]["description"]}
                    bazi["current_luck"] = current_luck

                # ID é˜²ç¦¦
                cid = str(citizen.get("id")) if citizen.get("id") else f"gen-{random.randint(1000,9999)}"

                arena_comments.append({
                    "sentiment": comment.get("sentiment", "neutral"),
                    "text": comment.get("text", "ï¼ˆç„¡è©•è«–å…§å®¹ï¼‰"),
                    "persona": personas_dict.get(cid)
                })
                
                # DEBUG LOG
                logger.info(f"Generated Primary Comment Persona: Name={citizen['name']}, ID={cid}, Birth={bazi.get('birth_year')}")

        # Ensure personas list for genesis is synced with the comments
        personas = [c["persona"] for c in arena_comments if c.get("persona")]

        # Fallback comments if not enough (ensure at least 8)
        # å¤§å¹…å¢åŠ è©•è«–æ¨¡æ¿ï¼Œæ›´è±å¯Œã€æ›´ç¬¦åˆå…«å­—å€‹æ€§
        bazi_comment_templates = {
            "é£Ÿç¥æ ¼": [
                "é€™ç”¢å“çœ‹èµ·ä¾†æŒºæœ‰è³ªæ„Ÿçš„ï¼Œç”¨èµ·ä¾†æ‡‰è©²å¾ˆäº«å—ï¼ç‰¹åˆ¥å–œæ­¡å®ƒçš„è¨­è¨ˆæ„Ÿï¼Œæ¯å¤©ä½¿ç”¨å¿ƒæƒ…éƒ½æœƒå¾ˆå¥½ã€‚",
                "å“‡ï¼Œé€™è¨­è¨ˆè »æœ‰å“å‘³çš„ï¼æˆ‘ä¸€å‘æ³¨é‡ç”Ÿæ´»å“è³ªï¼Œé€™ç¨®ç´°ç¯€è™•ç†å¾—ä¸éŒ¯ï¼Œå€¼å¾—å…¥æ‰‹ã€‚",
                "æˆ‘æ¯”è¼ƒåœ¨æ„ä½¿ç”¨é«”é©—ï¼Œé€™å€‹ç”¢å“å¾å¤–è§€åˆ°æ‰‹æ„Ÿéƒ½å¾ˆèˆ’æœï¼Œæ„Ÿè¦ºæœƒæ˜¯ç”Ÿæ´»ä¸­çš„å°ç¢ºå¹¸ã€‚",
                "ä½œç‚ºä¸€å€‹æ„›å¥½è€…ï¼Œæˆ‘è¦ºå¾—é€™å€‹ç”¢å“å¾ˆç™‚ç™’ï¼Œå…‰æ˜¯çœ‹è‘—å°±å¾ˆé–‹å¿ƒï¼Œå¯¦ç”¨æ€§å€’æ˜¯å…¶æ¬¡ã€‚"
            ],
            "å‚·å®˜æ ¼": [
                "è¨­è¨ˆé‚„å¯ä»¥ï¼Œä½†æˆ‘è¦ºå¾—æœ‰äº›åœ°æ–¹å¯ä»¥æ›´æœ‰å‰µæ„ä¸€é»ã€‚ä¸éæ•´é«”ä¾†èªªé‚„æ˜¯æœ‰å®ƒçš„ç‰¹è‰²ã€‚",
                "å—¯...æˆ‘æœ‰ä¸€äº›æ”¹é€²çš„æƒ³æ³•ï¼šå¦‚æœèƒ½åŠ å¼·æŸäº›åŠŸèƒ½æœƒæ›´å®Œç¾ã€‚ä¸éæ¦‚å¿µæ˜¯å¥½çš„ã€‚",
                "èªªå¯¦è©±ï¼Œå¸‚é¢ä¸Šé¡ä¼¼çš„ç”¢å“å¾ˆå¤šï¼Œé€™å€‹éœ€è¦åšå‡ºå·®ç•°åŒ–æ‰èƒ½çœŸæ­£å¸å¼•æˆ‘ã€‚",
                "æˆ‘æ¬£è³å‰µæ–°çš„å˜—è©¦ï¼Œä½†åŸ·è¡Œé¢é‚„æœ‰é€²æ­¥ç©ºé–“ã€‚æ½›åŠ›æ˜¯æœ‰çš„ï¼Œå°±çœ‹å¾ŒçºŒè¿­ä»£äº†ã€‚"
            ],
            "æ­£è²¡æ ¼": [
                "CPå€¼å¦‚ä½•ï¼Ÿæˆ‘æ¯”è¼ƒåœ¨æ„æ€§åƒ¹æ¯”ã€‚é€™å€‹åƒ¹æ ¼å¦‚æœå“è³ªç©©å®šï¼Œæˆ‘æœƒè€ƒæ…®å…¥æ‰‹ã€‚",
                "åƒ¹æ ¼å’Œå“è³ªçš„å¹³è¡¡å¾ˆé‡è¦ï¼Œé€™å€‹çœ‹èµ·ä¾†é‚„å¯ä»¥ã€‚å¸Œæœ›ç”¨æ–™å¯¦åœ¨ï¼Œä¸æ˜¯è™›æœ‰å…¶è¡¨ã€‚",
                "ä½œç‚ºä¸€å€‹å‹™å¯¦çš„äººï¼Œæˆ‘æœƒå…ˆçœ‹è©•åƒ¹å’Œå£ç¢‘ï¼Œç¢ºä¿æ¯ä¸€åˆ†éŒ¢éƒ½èŠ±å¾—å€¼å¾—ã€‚",
                "æˆ‘æœƒåšåŠŸèª²æ¯”è¼ƒå¹¾å®¶å†æ±ºå®šã€‚é€™å€‹å¦‚æœæœ‰å„ªæƒ æˆ–åˆ†æœŸï¼Œå¸å¼•åŠ›æœƒæ›´å¤§ã€‚"
            ],
            "åè²¡æ ¼": [
                "æ„Ÿè¦ºæœ‰æ½›åŠ›ï¼å¯ä»¥è€ƒæ…®æŠ•è³‡çœ‹çœ‹ã€‚é€™å€‹å¸‚å ´å®šä½è »è°æ˜çš„ï¼ŒæŠ“ä½äº†ç—›é»ã€‚",
                "é€™å€‹åˆ‡å…¥é»ä¸éŒ¯ï¼Œå•†æ©Ÿè »å¤§çš„ï¼å¦‚æœåœ˜éšŠåŸ·è¡ŒåŠ›å¼·ï¼Œç™¼å±•å‰æ™¯çœ‹å¥½ã€‚",
                "æˆ‘çœ‹åˆ°äº†æ©Ÿæœƒï¼é€™é¡ç”¢å“ç¾åœ¨æ­£æµè¡Œï¼Œæ™‚æ©Ÿé»æŠ“å¾—ä¸éŒ¯ï¼Œå€¼å¾—é—œæ³¨ã€‚",
                "æœ‰æ„æ€ï¼é€™å€‹å¦‚æœèƒ½åšæˆç³»åˆ—ç”¢å“æˆ–æ‰“é€ å“ç‰Œï¼Œæœªä¾†å¢å€¼ç©ºé–“å¾ˆå¤§ã€‚"
            ],
            "æ­£å®˜æ ¼": [
                "å“è³ªå’Œè¦æ ¼éƒ½ç¬¦åˆæ¨™æº–å—ï¼Ÿæˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªå„é …èªè­‰å’Œä¿å›ºæ¢æ¬¾ã€‚",
                "éœ€è¦å¤šäº†è§£ä¸€ä¸‹ç´°ç¯€ï¼Œå†åšæ±ºå®šã€‚ç©©å®šæ€§å’Œå”®å¾Œæœå‹™æ˜¯æˆ‘æœ€åœ¨æ„çš„ã€‚",
                "é€™å€‹å“ç‰Œå£ç¢‘å¦‚ä½•ï¼Ÿæˆ‘å‚¾å‘é¸æ“‡æœ‰ä¿¡è­½çš„å» å•†ï¼Œé€™æ¨£æ›´æœ‰ä¿éšœã€‚",
                "æœ‰æ²’æœ‰å°ˆæ¥­æ¸¬è©¦å ±å‘Šï¼Ÿä½œç‚ºç†æ€§æ¶ˆè²»è€…ï¼Œæˆ‘éœ€è¦å®¢è§€æ•¸æ“šä¾†æ”¯æŒè³¼è²·æ±ºå®šã€‚"
            ],
            "ä¸ƒæ®ºæ ¼": [
                "ç›´æ¥èªªé‡é»ï¼Œé€™æ±è¥¿èƒ½ä¸èƒ½è§£æ±ºå¯¦éš›ç—›é»ï¼Ÿå¦‚æœæ˜¯ç‚ºäº†è™›æ¦®å¿ƒè²·çš„ï¼Œæˆ‘æ²’èˆˆè¶£ã€‚æ•ˆç‡å’Œçµæœæ‰æ˜¯æˆ‘æœ€åœ¨æ„çš„ï¼Œæˆ‘éœ€è¦èƒ½æ‰“ä»—çš„å·¥å…·ã€‚",
                "åˆ¥è·Ÿæˆ‘ç¹åœˆå­ï¼Œå¸‚å ´å„ªå‹¢åœ¨å“ªï¼Ÿæ†‘ä»€éº¼è®“æˆ‘é¸ä½ ï¼Ÿå¦‚æœçœŸçš„æœ‰ç¡¬å¯¦åŠ›ï¼Œæˆ‘æœƒæ¯«ä¸çŒ¶è±«ä¸‹å–®ï¼Œå¦å‰‡åˆ¥æµªè²»æˆ‘æ™‚é–“ã€‚",
                "æˆ‘åªé—œå¿ƒæ€§èƒ½å’Œå›å ±ã€‚é€™ç”¢å“å¦‚æœèƒ½å¹«æˆ‘çœä¸‹ 20% çš„æ™‚é–“ï¼Œé‚£å®ƒå°±å€¼é€™å€‹åƒ¹ã€‚åŸ·è¡ŒåŠ›ä¸è¶³çš„æ–¹æ¡ˆï¼Œæˆ‘çœ‹éƒ½ä¸çœ‹ã€‚",
                "é€™æ±è¥¿çœ‹èµ·ä¾†å¾ˆæœ‰ä¾µç•¥æ€§ï¼Œé©åˆé–‹æ‹“æ–°å¸‚å ´ã€‚æˆ‘å–œæ­¡é€™ç¨®å¸¶æœ‰çªç ´æ€§çš„è¨­è¨ˆï¼Œåªè¦å®ƒèƒ½æ‰›å¾—èµ·é«˜å¼·åº¦çš„å£“åŠ›ã€‚"
            ],
            "æ­£å°æ ¼": [
                "é€™å°é•·æœŸç™¼å±•æœ‰å¹«åŠ©å—ï¼Ÿæˆ‘æ¯”è¼ƒçœ‹é‡é•·é åƒ¹å€¼ï¼Œä¸å–œæ­¡æ›‡èŠ±ä¸€ç¾çš„æ±è¥¿ã€‚",
                "å“ç‰Œä¿¡è­½å¾ˆé‡è¦ï¼Œé€™å€‹å…¬å¸å¯é å—ï¼Ÿæˆ‘å¯§å¯å¤šèŠ±é»éŒ¢ä¹Ÿè¦è²·å®‰å¿ƒã€‚",
                "æœ‰æ²’æœ‰å­¸ç¿’è³‡æºæˆ–ä½¿ç”¨æŒ‡å—ï¼Ÿæˆ‘å¸Œæœ›èƒ½çœŸæ­£äº†è§£å’ŒæŒæ¡é€™å€‹ç”¢å“ã€‚",
                "æˆ‘æœƒå…ˆè«‹æ•™æœ‰ç¶“é©—çš„æœ‹å‹ï¼Œè½è½ä»–å€‘çš„æ„è¦‹å†æ±ºå®šã€‚è¬¹æ…ä¸€é»ç¸½æ˜¯å¥½çš„ã€‚"
            ],
            "åå°æ ¼": [
                "é€™å€‹æ¦‚å¿µæŒºç‰¹åˆ¥çš„ï¼Œè·Ÿå¸‚é¢ä¸Šçš„ä¸å¤ªä¸€æ¨£ã€‚æˆ‘å–œæ­¡æœ‰ç¨ç‰¹æƒ³æ³•çš„ç”¢å“ã€‚",
                "æœ‰é»æ„æ€ï¼Œä½†æˆ‘éœ€è¦æ›´å¤šæ™‚é–“æ€è€ƒã€‚ç›´è¦ºå‘Šè¨´æˆ‘é€™å€‹æœ‰äº›é–€é“ã€‚",
                "è¨­è¨ˆç†å¿µå¾ˆæœ‰æ·±åº¦ï¼Œä¸æ˜¯ä¸€èˆ¬å¤§çœ¾èƒ½é¦¬ä¸Šç†è§£çš„ã€‚é€™åè€Œå¸å¼•æˆ‘ã€‚",
                "æˆ‘ä¸è·Ÿé¢¨ï¼Œé€™å€‹ç”¢å“æœ‰å®ƒç¨ç‰¹çš„æ°£è³ªï¼Œé©åˆæœ‰å“å‘³çš„äººã€‚"
            ],
            "æ¯”è‚©æ ¼": [
                "é€™å€‹æˆ‘èº«é‚Šå¾ˆå¤šæœ‹å‹éƒ½åœ¨ç”¨ï¼Œçœ‹ä¾†çœŸçš„ä¸éŒ¯ã€‚å¤§å®¶èªªå¥½æ‰æ˜¯çœŸçš„å¥½ã€‚",
                "æˆ‘æœƒå•å•åŒäº‹çš„æ„è¦‹ï¼Œå¦‚æœä»–å€‘ä¹Ÿè¦ºå¾—å¯ä»¥ï¼Œæˆ‘å°±è·Ÿä¸€æ³¢ã€‚",
                "é€™é¡ç”¢å“æˆ‘æœ‰ä½¿ç”¨ç¶“é©—ï¼Œé€™å€‹æ–°å“çœ‹èµ·ä¾†åœ¨ä¸€äº›ç´°ç¯€ä¸Šæœ‰é€²æ­¥ã€‚",
                "åƒ¹æ ¼å…¬é“ï¼Œå“è³ªéå¾—å»ï¼Œç¬¦åˆæˆ‘çš„é æœŸã€‚ä¸æ±‚æœ€å¥½ï¼Œä½†æ±‚å¯¦ç”¨ã€‚"
            ],
            "åŠ«è²¡æ ¼": [
                "é€™å€‹å€¼å¾—è·Ÿæœ‹å‹å€‘åˆ†äº«ï¼å¥½æ±è¥¿å°±æ˜¯è¦ä¸€èµ·ç”¨æ‰æœ‰æ„æ€ã€‚",
                "å¦‚æœæœ‰åœ˜è³¼æˆ–å„ªæƒ æ´»å‹•ï¼Œæˆ‘å¯ä»¥å¹«å¿™æªäººï¼Œå¤§å®¶ä¸€èµ·è²·æ›´åˆ’ç®—ã€‚",
                "æˆ‘å·²ç¶“æƒ³å¥½è¦æ¨è–¦çµ¦èª°äº†ï¼Œé€™å€‹ç”¢å“å‰›å¥½é©åˆæˆ‘å¹¾å€‹æœ‹å‹çš„éœ€æ±‚ã€‚",
                "ç”Ÿæ´»å˜›ï¼Œé–‹å¿ƒæœ€é‡è¦ï¼é€™å€‹èƒ½è®“æœ‹å‹èšæœƒæ›´æœ‰è¶£ï¼Œå€¼å¾—å…¥æ‰‹ã€‚"
            ],
        }
        
        # æ ¹æ“šè·æ¥­å¢åŠ æ›´å¤šå€‹æ€§åŒ–è©•è«–
        occupation_comments = {
            "å·¥ç¨‹å¸«": "å¾æŠ€è¡“è§’åº¦ä¾†çœ‹ï¼Œé€™å€‹ç”¢å“çš„è¨­è¨ˆé‚è¼¯æ˜¯åˆç†çš„ï¼ŒåŸ·è¡Œé¢ä¹Ÿä¸éŒ¯ã€‚",
            "è¨­è¨ˆå¸«": "è¦–è¦ºå‘ˆç¾è »æœ‰è³ªæ„Ÿçš„ï¼Œè‰²å½©æ­é…å’Œæ’ç‰ˆéƒ½å¾ˆç”¨å¿ƒï¼Œçœ‹å¾—å‡ºå°ˆæ¥­åº¦ã€‚",
            "è€å¸«": "é€™å€‹å°å­¸ç”Ÿæˆ–å®¶åº­ä¾†èªªå¯¦ç”¨å—ï¼Ÿæˆ‘æœƒè€ƒæ…®æ•™è‚²æ„ç¾©å’Œå®‰å…¨æ€§ã€‚",
            "é†«ç”Ÿ": "å¥åº·ç›¸é—œçš„ç”¢å“æˆ‘æ¯”è¼ƒè¬¹æ…ï¼Œéœ€è¦ç¢ºèªæœ‰ç„¡ç›¸é—œèªè­‰ã€‚",
            "å‰µæ¥­å®¶": "å•†æ¥­æ¨¡å¼æœ‰å‰µæ„ï¼Œå¦‚æœèƒ½è§£æ±ºçœŸæ­£çš„å¸‚å ´ç—›é»ï¼Œæœƒæœ‰ç™¼å±•ç©ºé–“ã€‚",
            "å­¸ç”Ÿ": "åƒ¹æ ¼æ˜¯æˆ‘æœ€åœ¨æ„çš„ï¼Œå¦‚æœæœ‰å­¸ç”Ÿå„ªæƒ å°±æ›´å¥½äº†ï¼",
            "ç¶“ç†": "åœ˜éšŠå”ä½œæ–¹é¢æœ‰å„ªå‹¢å—ï¼Ÿæˆ‘æœƒè€ƒæ…®å°å…¥å…¬å¸ä½¿ç”¨çš„å¯èƒ½æ€§ã€‚",
            "è‡ªç”±æ¥­": "éˆæ´»æ€§å¾ˆé‡è¦ï¼Œé€™å€‹èƒ½é…åˆæˆ‘ä¸å›ºå®šçš„å·¥ä½œæ¨¡å¼å—ï¼Ÿ",
        }
        
        default_templates = [
            "é€™å€‹ç”¢å“ç¢ºå¯¦æœ‰å®ƒçš„ç‰¹è‰²ï¼Œæˆ‘æœƒè€ƒæ…®è³¼è²·ï¼Œä½†é‚„éœ€è¦å†è§€å¯Ÿä¸€ä¸‹å¸‚å ´åæ‡‰ã€‚",
            "åƒ¹æ ¼åˆç†çš„è©±æˆ‘é¡˜æ„è©¦è©¦çœ‹ï¼Œç•¢ç«Ÿå˜—è©¦æ–°æ±è¥¿ä¹Ÿæ˜¯ä¸€ç¨®ç”Ÿæ´»æ…‹åº¦ã€‚",
            "è¨­è¨ˆè »æœ‰æƒ³æ³•çš„ï¼Œå¦‚æœè³ªé‡ç©©å®šï¼Œé€™å€‹åƒ¹ä½ç®—æ˜¯å¯ä»¥æ¥å—çš„é¸æ“‡ã€‚",
            "æ•´é«”ä¾†èªªç¬¦åˆæˆ‘çš„é æœŸï¼Œä¸ç®—é©šè‰·ä½†ä¹Ÿæ²’ä»€éº¼å¤§å•é¡Œï¼Œå¯ä»¥åˆ—å…¥è³¼ç‰©æ¸…å–®ã€‚",
            "æˆ‘æœƒæŒçºŒé—œæ³¨é€™å€‹ç”¢å“ï¼Œç­‰æ›´å¤šç”¨æˆ¶è©•åƒ¹å‡ºä¾†å†æ±ºå®šæ˜¯å¦å…¥æ‰‹ã€‚",
            "ç¬¬ä¸€å°è±¡ä¸éŒ¯ï¼Œä½†æˆ‘ç¿’æ…£è²¨æ¯”ä¸‰å®¶ï¼Œç¢ºä¿é€™æ˜¯æœ€ä½³é¸æ“‡å†ä¸‹æ‰‹ã€‚",
            "å°æˆ‘ä¾†èªªé€™æ˜¯å€‹æ–°é ˜åŸŸï¼Œéœ€è¦æ›´å¤šäº†è§£ï¼Œä½†ç”¢å“æœ¬èº«çœ‹èµ·ä¾†æœ‰èª æ„ã€‚",
            "æœ‹å‹æ¨è–¦éé¡ä¼¼çš„ç”¢å“ï¼Œé€™å€‹çœ‹èµ·ä¾†ä¹Ÿå€¼å¾—ä¸€è©¦ï¼Œè€ƒæ…®ä¸­ã€‚"
        ]
        
        import random as rand_module
        while len(arena_comments) < 8 and sampled_citizens:
            # æ‰¾ä¸€å€‹é‚„æ²’è©•è«–éçš„å¸‚æ°‘
            commented_names = {c["persona"]["name"] for c in arena_comments}
            remaining = [c for c in sampled_citizens if c["name"] not in commented_names]
            if not remaining:
                break
            citizen = remaining[0]
            bazi = citizen["bazi_profile"]
            structure = bazi.get("structure", "")
            occupation = citizen.get("occupation", "")
            
            # æ ¹æ“šå…«å­—çµæ§‹é¸æ“‡è©•è«–æ¨¡æ¿
            templates = None
            for pattern, texts in bazi_comment_templates.items():
                if pattern in structure:
                    templates = texts
                    break
            
            # å¦‚æœæ²’æœ‰åŒ¹é…çš„å…«å­—æ ¼å±€ï¼Œå˜—è©¦è·æ¥­åŒ¹é…
            if not templates:
                for occ, comment in occupation_comments.items():
                    if occ in occupation:
                        templates = [comment]
                        break
            
            # æœ€å¾Œä½¿ç”¨é»˜èªæ¨¡æ¿
            if not templates:
                templates = default_templates
            
            # éš¨æ©Ÿé¸æ“‡ä¸€æ¢è©•è«–ï¼Œé¿å…é‡è¤‡
            text = rand_module.choice(templates)
            
            # æ··åˆåˆ†é…æƒ…æ„Ÿ
            sentiments = ["positive", "positive", "neutral", "neutral", "negative"]
            sentiment = sentiments[len(arena_comments) % len(sentiments)]
            
            # å®šç¾© pillars_str
            pillars_str = bazi.get("four_pillars")
            if not pillars_str:
                pillars = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª", "å£¬ç”³", "ç™¸é…‰", "ç”²æˆŒ", "ä¹™äº¥"]
                import random as rand_mod
                pillars_str = f"{rand_mod.choice(pillars)} {rand_mod.choice(pillars)} {rand_mod.choice(pillars)} {rand_mod.choice(pillars)}"
            
            # å–å¾— luck_timeline
            timeline = bazi.get("luck_timeline", [])
            
            # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ luck_timelineï¼Œç”Ÿæˆé è¨­è³‡æ–™
            if not timeline:
                start_age = random.randint(2, 9)
                pillars_pool = ["ç”²å­", "ä¹™ä¸‘", "ä¸™å¯…", "ä¸å¯", "æˆŠè¾°", "å·±å·³", "åºšåˆ", "è¾›æœª"]
                descs = ["å°‘å¹´é‹å‹¢é †é‚", "åˆå…¥ç¤¾æœƒç£¨ç·´", "äº‹æ¥­ç©©æ­¥ä¸Šå‡", "è²¡é‹äº¨é€š", "å£“åŠ›è¼ƒå¤§éœ€æ³¨æ„", "ç©©æ­¥ç™¼å±•", "è²¡å®˜é›™ç¾", "æ™šé‹å®‰åº·"]
                for i in range(8):
                    timeline.append({
                        "age_start": start_age + i*10,
                        "age_end": start_age + i*10 + 9,
                        "name": f"{pillars_pool[i]}é‹",
                        "description": descs[i]
                    })

            # ğŸ›¡ï¸ é˜²ç¦¦æ€§è£œå…¨ï¼šå¦‚æœæ²’æœ‰ current_luckï¼Œå¾ timeline ä¸­è¨ˆç®—
            current_luck = bazi.get("current_luck")
            if not isinstance(current_luck, dict):
                current_luck = {}

            if not current_luck or not current_luck.get("description"):
                try:
                    citizen_age = int(citizen.get("age", 30))
                except:
                    citizen_age = 30
                for lt in timeline:
                    if lt["age_start"] <= citizen_age <= lt["age_end"]:
                        current_luck = {"name": lt["name"], "description": lt["description"]}
                        break
                if not current_luck and timeline:
                    current_luck = {"name": timeline[0]["name"], "description": timeline[0]["description"]}
                bazi["current_luck"] = current_luck

            # ID é˜²ç¦¦
            cid = str(citizen.get("id")) if citizen.get("id") else f"gen-{random.randint(1000,9999)}"

            # æ§‹å»ºå®Œæ•´çš„ persona è³‡æ–™
            full_persona = {
                "id": cid,
                "name": citizen["name"],
                "age": str(citizen["age"]),
                "pattern": bazi.get("structure", "æœªçŸ¥æ ¼å±€"),
                "element": bazi.get("element", "Fire"),
                "icon": {"Fire": "ğŸ”¥", "Water": "ğŸ’§", "Metal": "ğŸ”©", "Wood": "ğŸŒ³", "Earth": "ğŸ”ï¸"}.get(bazi.get("element", "Fire"), "ğŸ”¥"),
                "occupation": citizen.get("occupation", "æœªçŸ¥è·æ¥­"),
                "location": citizen.get("location", "å°ç£"),
                "birth_year": bazi.get("birth_year"),
                "birth_month": bazi.get("birth_month"),
                "birth_day": bazi.get("birth_day"),
                "birth_shichen": bazi.get("birth_shichen"),
                "four_pillars": pillars_str,
                "day_master": bazi.get("day_master", "æœªçŸ¥"),
                "strength": bazi.get("strength", "ä¸­å’Œ"),
                "favorable": bazi.get("favorable", ["æœ¨", "ç«"]),
                "current_luck": current_luck,
                "luck_timeline": timeline,
                "trait": bazi.get("trait", "æ€§æ ¼å‡è¡¡")
            }

            arena_comments.append({
                "sentiment": sentiment,
                "text": text,
                "persona": full_persona
            })
            
            personas.append(full_persona)
            
            # DEBUG LOG
            logger.info(f"Generated Fallback Comment Persona: Name={citizen['name']}, ID={cid}, Pillars={pillars_str}, Birth={bazi.get('birth_year')}")

        result_data = {
            "status": "ready",
            "score": data.get("result", {}).get("score", 75),
            "intent": data.get("result", {}).get("market_sentiment", "è¬¹æ…æ¨‚è§€"),
            "summary": data.get("result", {}).get("summary", "åˆ†æå®Œæˆ"),
            "simulation_metadata": {
                "source_type": sim_metadata_override.get("source_type", "image") if sim_metadata_override else "image",
                "product_category": data.get("simulation_metadata", {}).get("product_category", sim_metadata_override.get("product_category", "other") if sim_metadata_override else "other"),
                "sample_size": len(sampled_citizens),
                "bazi_distribution": bazi_dist
            },
            "bazi_distribution": bazi_dist,
            "genesis": {
                "total_population": 1000,
                "sample_size": max(len(arena_comments), 8),
                "personas": personas
            },
            "arena_comments": arena_comments,
            "objections": data.get("result", {}).get("objections", []),
            "suggestions": data.get("result", {}).get("suggestions", [])
        }
        return result_data

    def _handle_error_db(self, sim_id, error_msg):
        error_data = {
            "status": "error",
            "score": 0,
            "intent": "Error",
            "summary": f"ç³»çµ±éŒ¯èª¤: {error_msg}",
            "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
            "comments": []
        }
        update_simulation(sim_id, "error", error_data)

    def reply_text(self, reply_token, text):
        try:
            self.line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=text)]
                )
            )
        except Exception:
            pass

    async def _call_gemini_rest(self, api_key, prompt, image_b64=None, pdf_b64=None, mime_type="image/jpeg", timeout=60):
        """Helper to call Gemini REST API (Async Wrapper with Configurable Timeout)"""
        import requests 

        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 8192,
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_b64:
            # Use dynamic mime_type
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": mime_type, "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        # [Restore] Prioritize Quality (Pro) as per User Request (reverting to GitHub-like behavior)
        models = [
            "gemini-2.5-pro", 
            "gemini-2.5-flash",
            "gemini-2.0-flash",
            "gemini-flash-latest"
        ]
        
        last_error = ""
        for model in models:
            try:
                # print(f"Trying model: {model}...")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                
                # [Fix] Use asyncio.to_thread to unblock Event Loop
                import asyncio
                # Increase timeout for Pro model and PDF/Audio heavy tasks
                current_timeout = timeout
                if "pro" in model:
                    current_timeout = max(timeout, 120) # Pro needs time to think (2 mins)
                
                # PDF needs more time regardless of model
                if pdf_b64:
                    current_timeout = max(current_timeout, 120)

                print(f"[DEBUG] Calling Gemini Model: {model} with Payload Size: {len(json.dumps(payload))} bytes, Timeout: {current_timeout}s")
                response = await asyncio.to_thread(
                    requests.post, 
                    url, 
                    headers={'Content-Type': 'application/json'}, 
                    json=payload, 
                    timeout=current_timeout
                )
                print(f"[DEBUG] Gemini Model {model} returned Status: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        return response.json()['candidates'][0]['content']['parts'][0]['text'], None
                    except:
                        continue
                else:
                    last_error = f"{model}: {response.status_code} {response.text}"
            except Exception as e:
                last_error = str(e)
        
        return None, last_error

    async def generate_marketing_copy(self, image_bytes, product_name, price, style="professional"):
        """Web API å°ˆç”¨ï¼šç”Ÿæˆç”¢å“æ–‡æ¡ˆï¼Œæ ¹æ“šæŒ‡å®šé¢¨æ ¼"""
        try:
            image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # Style-specific instructions
            style_prompts = {
                "professional": "è«‹ä½¿ç”¨**å°ˆæ¥­ç©©é‡**çš„å•†å‹™é¢¨æ ¼ã€‚ç”¨è©æ­£å¼ã€æ•¸æ“šå°å‘ï¼Œå¼·èª¿ç”¢å“çš„å°ˆæ¥­æ€§èˆ‡å¯é åº¦ã€‚é©åˆ B2B æˆ–é«˜ç«¯æ¶ˆè²»è€…ã€‚",
                "friendly": "è«‹ä½¿ç”¨**è¦ªåˆ‡æ´»æ½‘**çš„è¼•é¬†é¢¨æ ¼ã€‚åƒè·Ÿæœ‹å‹èŠå¤©ä¸€æ¨£ï¼Œä½¿ç”¨å£èªåŒ–çš„èªå¥ï¼Œå¸¶é»å¹½é»˜æ„Ÿï¼Œè®“äººæ„Ÿè¦ºæ²’æœ‰è·é›¢ã€‚",
                "luxury": "è«‹ä½¿ç”¨**é«˜ç«¯å¥¢è¯**çš„å“ç‰Œé¢¨æ ¼ã€‚ç”¨è©è¬›ç©¶ã€å¯Œæœ‰è³ªæ„Ÿï¼Œç‡Ÿé€ å‡ºç¨€æœ‰ã€å°Šè²´ã€éå‡¡çš„æ„Ÿå—ï¼Œé©åˆç²¾å“æˆ–é«˜åƒ¹å•†å“ã€‚",
                "minimalist": "è«‹ä½¿ç”¨**ç°¡ç´„æ¸…çˆ½**çš„æ¥µç°¡é¢¨æ ¼ã€‚å¥å­ç²¾ç…‰æœ‰åŠ›ï¼Œå»é™¤è´…è©ï¼Œåªç•™ç²¾è¯ï¼Œè®“è®€è€…ä¸€çœ¼å°±èƒ½æŠ“ä½é‡é»ã€‚",
                "storytelling": "è«‹ä½¿ç”¨**æ•…äº‹æ•˜è¿°**çš„æƒ…å¢ƒé¢¨æ ¼ã€‚ä»¥ä¸€å€‹å°æ•…äº‹æˆ–å ´æ™¯é–‹é ­ï¼Œå¸¶è®€è€…é€²å…¥ç”¢å“çš„ä½¿ç”¨æƒ…å¢ƒï¼Œè®“ä»–å€‘åœ¨è…¦æµ·ä¸­æƒ³åƒè‡ªå·±æ­£åœ¨ä½¿ç”¨é€™æ¬¾ç”¢å“ã€‚"
            }
            style_instruction = style_prompts.get(style, style_prompts["professional"])
            
            prompt = f"""è«‹æ“”ä»»ä¸€ä½é ‚ç´šçš„å•†æ¥­æ–‡æ¡ˆç­–ç•¥å¤§å¸«ã€‚è«‹æ·±å…¥åˆ†æé€™å¼µç”¢å“åœ–ç‰‡ï¼Œä¸¦æ ¹æ“šæä¾›çš„è³‡è¨Šï¼Œç‚ºé€™æ¬¾ç”¢å“å‰µé€ å…©å€‹æˆªç„¶ä¸åŒçš„ã€Œå®Œç¾æ‡‰ç”¨å ´æ™¯ã€èˆ‡ã€Œæ²‰æµ¸å¼è¡ŒéŠ·æ–‡æ¡ˆã€ã€‚

ğŸ¨ **å¯«ä½œé¢¨æ ¼è¦æ±‚**ï¼š{style_instruction}

ç”¢å“åç¨±ï¼š{product_name}
å»ºè­°å”®åƒ¹ï¼š{price}

è«‹ä¸è¦åªå¯«ã€Œå„ªé›…ã€æˆ–ã€Œå¯¦ç”¨ã€é€™ç¨®ç©ºæ³›çš„å½¢å®¹è©ã€‚æˆ‘éœ€è¦ä½ èƒ½å¤ ï¼š
1. **æ·±åº¦è­˜åˆ¥**ï¼šå®Œå…¨ç†è§£å•†å“çš„æè³ªã€è¨­è¨ˆèªè¨€èˆ‡æ½›åœ¨å•†æ¥­åƒ¹å€¼ã€‚
2. **ç²¾æº–åŒ¹é…**ï¼šå…·é«”æŒ‡å‡ºé€™æ¬¾ç”¢å“æœ€é©åˆã€Œä»€éº¼æ¨£çš„äººã€ã€ã€Œåœ¨ä»€éº¼å ´åˆã€ã€ã€Œåšä»€éº¼äº‹ã€æ™‚ä½¿ç”¨ã€‚
3. **æ²‰æµ¸é«”é©—**ï¼šç”¨æ–‡å­—ç‡Ÿé€ å‡ºæ°›åœï¼Œè®“è§€çœ‹è€…å½·å½¿ç½®èº«å…¶ä¸­ï¼Œæ„Ÿå—åˆ°æ“æœ‰é€™ä»¶å•†å“å¾Œçš„ç¾å¥½ç”Ÿæ´»åœ–æ™¯ã€‚

è«‹ç”Ÿæˆå…©æ®µä¸åŒåˆ‡å…¥é»çš„æ–‡æ¡ˆï¼ˆç¹é«”ä¸­æ–‡ï¼Œæ¯æ®µç´„ 100-150 å­—ï¼‰ï¼š

ã€Aã€‘åˆ‡å…¥é»ä¸€ï¼šæƒ…æ„Ÿå…±é³´èˆ‡æ°›åœç‡Ÿé€  (Emotional & Atmospheric)
- å´é‡æ–¼æ„Ÿæ€§è¨´æ±‚ï¼Œæç¹ªä½¿ç”¨ç•¶ä¸‹çš„ç¾å¥½ç•«é¢ã€å¿ƒç†æ»¿è¶³æ„Ÿæˆ–è‡ªæˆ‘å±•ç¾ã€‚
- é©åˆæƒ³é€éç”¢å“æå‡ç”Ÿæ´»è³ªæ„Ÿæˆ–è¡¨é”å€‹æ€§çš„å®¢ç¾¤ã€‚

ã€Bã€‘åˆ‡å…¥é»äºŒï¼šç²¾æº–å ´æ™¯èˆ‡ç—›é»è§£æ±º (Scenario & Solution)
- å´é‡æ–¼ç†æ€§èˆ‡å ´æ™¯è¨´æ±‚ï¼Œå…·é«”æè¿°åœ¨å·¥ä½œã€ç¤¾äº¤æˆ–ç‰¹å®šæ´»å‹•ä¸­çš„å®Œç¾è¡¨ç¾ã€‚
- å³ä½¿æ˜¯å•†æ¥­è¨ˆåŠƒæ›¸ï¼Œä¹Ÿè¦æè¿°å…¶å•†æ¥­æ¨¡å¼è½åœ°çš„å…·é«”å ´æ™¯èˆ‡è§£æ±ºçš„å¯¦éš›å•é¡Œã€‚

è«‹ç›´æ¥å›è¦† JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdown æ¨™è¨˜ï¼š
{{
    "title_a": "æ–‡æ¡ˆ A çš„æ¨™é¡Œ",
    "description_a": "æ–‡æ¡ˆ A çš„å…§å®¹...",
    "title_b": "æ–‡æ¡ˆ B çš„æ¨™é¡Œ",
    "description_b": "æ–‡æ¡ˆ B çš„å…§å®¹..."
}}
"""
            if not settings.GOOGLE_API_KEY:
                 return {"error": "å¾Œç«¯æœªè¨­å®š GOOGLE_API_KEY"}

            api_key = settings.GOOGLE_API_KEY
            # Run blocking request in thread pool
            ai_text, last_error = await asyncio.to_thread(self._run_blocking_gemini_request, api_key, prompt, image_b64)
            
            if ai_text:
                result = self._clean_and_parse_json(ai_text)
                # Combine title and description for easier usage
                option_a = result.get('description_a', '')
                option_b = result.get('description_b', '')
                return {"option_a": option_a, "option_b": option_b}
            else:
                return {"error": f"AI ç”Ÿæˆå¤±æ•—: {last_error}"}

        except Exception as e:
            print(f"[ERROR] generate_marketing_copy éŒ¯èª¤: {e}")
            return {"error": str(e)}

    def _run_blocking_gemini_request(self, api_key, prompt, image_b64=None, pdf_b64=None, model_priority=None, mime_type="image/jpeg"):
        """Helper to run synchronous requests in a thread"""
        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt}
                ]
            }],
            "generationConfig": {
                "maxOutputTokens": 8192,
                "temperature": 0.7,
                "topP": 0.9,
                "responseMimeType": "application/json"
            }
        }
        
        if image_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": mime_type, "data": image_b64}})
        if pdf_b64:
            payload["contents"][0]["parts"].append({"inline_data": {"mime_type": "application/pdf", "data": pdf_b64}})

        # Default models if not specified
        if model_priority:
            models = model_priority
        else:
            # [Fix] Prioritize Gemini 2.5 Pro as requested by the user
            models = [
                "gemini-2.5-pro",
                "gemini-2.5-flash",
                "gemini-flash-latest"
            ]
        
        last_error = ""
        for model in models:
            try:
                print(f"[AI] å˜—è©¦ä½¿ç”¨æ¨¡å‹: {model}...")
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                # Reduced timeout to 30s
                response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=30)
                if response.status_code == 200:
                    try:
                        return response.json()['candidates'][0]['content']['parts'][0]['text'], None
                    except:
                        continue
                else:
                    error_msg = f"{model}: {response.status_code} {response.text}"
                    print(f"[AI] æ¨¡å‹ {model} å¤±æ•—: {error_msg}")
                    last_error = error_msg
            except Exception as e:
                last_error = str(e)
        
        return None, last_error