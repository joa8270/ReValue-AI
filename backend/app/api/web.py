from fastapi import APIRouter, File, UploadFile, Form, BackgroundTasks
from typing import List
from app.core.database import create_simulation, insert_citizens_batch, get_citizens_count, clear_citizens, get_citizen_by_id, update_simulation
import uuid
from app.services.video_analysis_service import video_analysis_service

import sys
import os
import json

print("[WEB] Module web.py loaded!", flush=True)

# ç¢ºä¿å¯ä»¥å°å…¥ create_citizens
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from create_citizens import generate_citizen

router = APIRouter()

# ğŸ”§ Debug wrapper to catch background task exceptions
async def safe_run_pdf_task(line_service, *args, **kwargs):
    """Wrapper to catch and log any exceptions from PDF background task"""
    try:
        with open("debug_trace.log", "a", encoding="utf-8") as f:
            f.write(f"[WRAPPER] Starting PDF task with {len(args)} args, {len(kwargs)} kwargs\n")
        await line_service.run_simulation_with_pdf_data(*args, **kwargs)
    except Exception as e:
        import traceback
        error_msg = f"[WRAPPER] PDF Task Failed: {e}\n{traceback.format_exc()}"
        print(error_msg, flush=True)
        with open("debug_trace.log", "a", encoding="utf-8") as f:
            f.write(error_msg + "\n")
        with open("last_error.txt", "w", encoding="utf-8") as f:
            f.write(error_msg)
        
        # ğŸ›¡ï¸ Update DB to error state so frontend knows it failed
        try:
            # Assuming sim_id is the first argument in args
            if args:
                sim_id = args[0]
                update_simulation(sim_id, "error", {
                    "status": "error",
                    "summary": f"ç³»çµ±éŒ¯èª¤: {str(e)}",
                    "score": 0,
                    "intent": "Error",
                    "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
                    "comments": []
                })
        except:
            pass

async def run_video_audit_task(
    sim_id: str, 
    video_url: str, 
    product_name: str = None, 
    price: str = None,
    description: str = None,
    style: str = "å°ˆæ¥­ç©©é‡",
    language: str = "zh-TW",
    targeting_data: dict = None,
    is_expert_mode: bool = False,
    is_force_random: bool = False,
    analysis_scenario: str = "b2c",
    seed_salt: int = 0
):
    """Background task for video analysis and simulation with full params"""
    try:
        print(f">> [Task] Starting video audit for {video_url} (ID: {sim_id})")
        
        # â¬ éšæ®µ 1ï¼šé–‹å§‹ä¸‹è¼‰è¦–é »
        update_simulation(sim_id, "processing", {
            "status": "processing",
            "summary": "ğŸ“¥ æ­£åœ¨ä¸‹è¼‰è¦–é »ï¼ˆé™åˆ¶å‰60ç§’ï¼‰...",
            "score": 0,
            "intent": "Processing..."
        })
        
        # 1. AI è¦–è¦ºå¯©ç‰‡
        report_data = video_analysis_service.analyze_video_content(video_url)
        
        # [CRITICAL FIX] å®Œæ•´éŒ¯èª¤æ””æˆªï¼ˆåŒ…å« None å’Œ error å­—æ®µï¼‰
        # é¿å…ä½¿ç”¨éŒ¯èª¤çš„ citizen_briefing é€²è¡Œå¸‚æ°‘æ¨¡æ“¬
        if not report_data or report_data.get("error"):
            error_type = report_data.get("error", "UNKNOWN_ERROR") if report_data else "NO_RESPONSE"
            error_msg = report_data.get("message", "AI å¯©ç‰‡å¤±æ•—") if report_data else "ç„¡å›æ‡‰"
            
            # æ ¹æ“šéŒ¯èª¤é¡å‹æä¾›é‡å°æ€§å»ºè­°
            suggestion_map = {
                "VIDEO_DOWNLOAD_FAILED": "å½±ç‰‡ä¸‹è¼‰å¤±æ•—ã€‚è«‹ç¢ºèªï¼š1.é€£çµæ˜¯å¦æœ‰æ•ˆ 2.æ˜¯å¦æœ‰é˜²ç›œéˆé™åˆ¶ 3.å˜—è©¦ä¸Šå‚³æœ¬åœ° MP4 æª”æ¡ˆ",
                "VIDEO_UNREADABLE": "AI ç„¡æ³•è­˜åˆ¥å½±ç‰‡å…§å®¹ã€‚å¯èƒ½æ˜¯ä¸‹è¼‰äº†éå½±ç‰‡æ–‡ä»¶ï¼ˆå¦‚ HTML éŒ¯èª¤é é¢ï¼‰ã€‚è«‹æ›´æ›é€£çµã€‚",
                "UPLOAD_FAILED": "å½±ç‰‡ä¸Šå‚³è‡³ AI æœå‹™å¤±æ•—ã€‚è«‹ç¨å¾Œé‡è©¦ã€‚",
                "PROCESSING_FAILED": "AI è™•ç†å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚è«‹å˜—è©¦è¼ƒçŸ­æˆ–è¼ƒå°çš„å½±ç‰‡ã€‚",
            }
            suggestion = suggestion_map.get(error_type, "è«‹å˜—è©¦ï¼š1.æ›´æ›æœ‰æ•ˆçš„å½±ç‰‡é€£çµ 2.ç¢ºä¿é€£çµå¯ç›´æ¥ä¸‹è¼‰ 3.ä¸Šå‚³æœ¬åœ° MP4 æª”æ¡ˆ")
            
            update_simulation(sim_id, "error", {
                "status": "error",
                "summary": f"[{error_type}] {error_msg}",
                "score": 0,
                "intent": "Error",
                "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
                "comments": [],
                "error_details": {
                    "type": error_type,
                    "message": error_msg,
                    "suggestion": suggestion
                }
            })
            print(f">> [Task] Video audit BLOCKED due to error: {error_type} - {error_msg}")
            return
        
        # â¬ éšæ®µ 2ï¼šAI åˆ†æå®Œæˆï¼Œé–‹å§‹å¸‚æ°‘æ¨¡æ“¬
        update_simulation(sim_id, "processing", {
            "status": "processing",
            "summary": "ğŸ¤– AI è¦–è¦ºåˆ†æå®Œæˆï¼Œæ­£åœ¨å¬å–š 1,000 ä½å¸‚æ°‘é€²è¡Œè©•ä¼°...",
            "score": 0,
            "intent": "Processing..."
        })
             
        # 2. å¸‚æ°‘å¸‚å ´æ¨¡æ“¬ (å‚³å…¥å®Œæ•´ç”¢å“è³‡è¨Šèˆ‡ç›®æ¨™å¸‚å ´åƒæ•¸)
        sim_result = video_analysis_service.run_market_simulation(
            report_data, 
            video_url, 
            product_name=product_name, 
            price=price,
            description=description,
            style=style,
            language=language,
            targeting_data=targeting_data,
            is_expert_mode=is_expert_mode,
            is_force_random=is_force_random,
            analysis_scenario=analysis_scenario,
            seed_salt=seed_salt
        )
        
        # 3. çµ„åˆæœ€çµ‚çµæœ
        final_data = {
            "status": "completed",
            "report": report_data,
            "simulation": sim_result,
            "simulation_logs": sim_result.get("simulation_logs", []),
            # å‰ç«¯ç›¸å®¹æ€§è½‰æ›
            "score": sim_result["score"],
            "summary": report_data.get("citizen_briefing", ""),
            "intent": sim_result["decision"],
            "comments": sim_result["top_reviews"],
            "genesis": {
                "total_population": 1000,
                "sample_size": len(sim_result["top_reviews"]),
                "personas": sim_result["top_reviews"]
            }
        }
        update_simulation(sim_id, "completed", final_data)
        print(f">> [Task] Video audit completed for {sim_id}")
    except Exception as e:
        import traceback
        print(f"!! [Task] Video audit failed: {e}\n{traceback.format_exc()}")
        update_simulation(sim_id, "error", {
            "status": "error", 
            "summary": f"è™•ç†å¤±æ•—: {str(e)}"
        })

@router.post("/video-audit")
async def video_audit_endpoint(
    background_tasks: BackgroundTasks,
    url: str = Form(...),
    product_name: str = Form(None),
    price: str = Form(None)
):
    """[New] Video Audit API Endpoint"""
    sim_id = f"video_{str(uuid.uuid4())}"
    
    initial_data = {
        "status": "processing",
        "summary": "æ­£åœ¨ä¸‹è¼‰ä¸¦è§£æå½±ç‰‡å…§å®¹...",
        "report": {},
        "simulation": {},
        "intent": "Processing...",
        "score": 0,
        "video_url": url # Store URL for history
    }
    create_simulation(sim_id, initial_data)
    
    background_tasks.add_task(run_video_audit_task, sim_id, url, product_name, price)
    
    return {"status": "ok", "sim_id": sim_id}

@router.get("/video-audits/recent")
async def list_recent_video_audits():
    """Fetch recent video audit simulations from DB"""
    from app.core.database import SessionLocal, Simulation
    db = SessionLocal()
    try:
        # Filter by ID prefix "video_"
        audits = db.query(Simulation).filter(Simulation.sim_id.like("video_%")).order_by(Simulation.created_at.desc()).limit(10).all()
        result = []
        for a in audits:
            data = a.data or {}
            result.append({
                "sim_id": a.sim_id,
                "status": a.status,
                "created_at": a.created_at.isoformat() if a.created_at else None,
                "score": data.get("score", 0),
                "intent": data.get("intent", "Unknown"),
                "video_url": data.get("video_url", "Unknown")
            })
        return {"audits": result}
    except Exception as e:
        print(f"!! Error fetching recent audits: {e}")
        return {"audits": [], "error": str(e)}
    finally:
        db.close()




@router.get("/citizen/{citizen_id}")
async def get_citizen_data(citizen_id: str):
    """
    æ ¹æ“š ID æŸ¥è©¢å¸‚æ°‘çš„å®Œæ•´è³‡æ–™ï¼ˆåŒ…æ‹¬å…«å­—å‘½ç›¤ã€å¤§é‹ç­‰ï¼‰
    å‰ç«¯ Modal ç”¨æ­¤ API å–å¾—å®Œæ•´è³‡æ–™
    """
    citizen = get_citizen_by_id(citizen_id)
    if citizen:
        return citizen
    else:
        return {"error": "Citizen not found", "id": citizen_id}

@router.get("/citizens/genesis")
async def get_all_citizens_endpoint(limit: int = 1000, offset: int = 0):
    """
    [Frontend] å–å¾—æ‰€æœ‰å¸‚æ°‘è³‡æ–™ (ç”¨æ–¼ç€è¦½é é¢)
    """
    try:
        from app.core.database import get_all_citizens, SessionLocal, Citizen
        
        # ğŸ” Debug: Check DB Connection directly in the API process
        db = SessionLocal()
        raw_count = db.query(Citizen).count()
        db_url = str(db.get_bind().url)
        # Mask password for security
        safe_db_url = db_url.split("@")[-1] if "@" in db_url else "Unknown"
        db.close()

        citizens = get_all_citizens(limit=limit, offset=offset)
        
        return {
            "citizens": citizens, 
            "total": len(citizens),
            "debug_info": {
                "raw_db_count": raw_count,
                "db_host": safe_db_url,
                "limit_param": limit,
                "fetched_count": len(citizens)
            }
        }
    except Exception as e:
        print(f"âŒ Get all citizens failed: {e}")
        return {"citizens": [], "error": str(e)}

@router.get("/admin/reset-citizens")
async def reset_citizens_endpoint(count: int = 1000):
    """
    [Admin] é‡ç½®ä¸¦é‡æ–°ç”Ÿæˆ AI å¸‚æ°‘æ•¸æ“šåº«
    """
    try:
        print(f"ğŸ”„ é–‹å§‹é‡ç½®å¸‚æ°‘æ•¸æ“šï¼Œç›®æ¨™: {count} ä½...")
        clear_citizens()
        
        citizens = [generate_citizen(i) for i in range(count)]
        
        batch_size = 100
        for i in range(0, len(citizens), batch_size):
            insert_citizens_batch(citizens[i:i+batch_size])
            
        final_count = get_citizens_count()
        return {"status": "success", "message": f"æˆåŠŸé‡ç½®ä¸¦ç”Ÿæˆ {final_count} ä½ AI å¸‚æ°‘", "count": final_count}
    except Exception as e:
        print(f"âŒ é‡ç½®å¤±æ•—: {e}")
        return {"status": "error", "message": str(e)}

# ç§»é™¤å…¨åŸŸ import å’Œå¯¦ä¾‹åŒ–ï¼Œé¿å…å¾ªç’°å¼•ç”¨
# from app.services.line_bot_service import LineBotService
# line_service = LineBotService()

@router.post("/trigger")
async def trigger_simulation(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(None),
    product_name: str = Form(None),

    price: str = Form(None),
    description: str = Form(None),
    market_prices: str = Form(None),  # JSON å­—ä¸²æ ¼å¼çš„å¸‚å ´æ¯”åƒ¹è³‡æ–™
    style: str = Form(None),  # æ–°å¢ style æ¬„ä½
    language: str = Form("zh-TW"),  # æ–°å¢ language æ¬„ä½
    targeting: str = Form(None), # JSON string of targeting options
    expert_mode: str = Form("false"), # "true"/"false" string
    force_random: str = Form("false"), # "true"/"false" string
    seed_salt: int = Form(0), # [New] Batch Control Salt
    analysis_scenario: str = Form("b2c"), # "b2c" / "b2b"
    video_url: str = Form(None) # [New] Video URL for integration
):
    print(f"[WEB] trigger_simulation called! salt={seed_salt}, video={video_url}", flush=True)  

    try:
        with open("debug_trace.log", "a", encoding="utf-8") as f:
            f.write(f"ğŸ‘‰ [WEB] trigger_simulation called with salt={seed_salt}, expert_mode={expert_mode}\n")
    except Exception as e:
        print(f"Failed to write log: {e}")

    from app.services.line_bot_service import LineBotService
    line_service = LineBotService()

    sim_id = str(uuid.uuid4())
    
    # ğŸ” [Ghost Buster] Debug DB Source & Sampling
    try:
        from app.core.database import engine, get_random_citizens
        db_url = str(engine.url)
        print(f"[Ghost] Runtime DB: {db_url}")
        
        # Test Sample
        sample = get_random_citizens(sample_size=5)
        sample_names = [c["name"] for c in sample]
        
        with open("debug_ghost.log", "a", encoding="utf-8") as f:
            f.write(f"\n[{sim_id}] TRIGGERED\n")
            f.write(f"[{sim_id}] DB URL: {db_url}\n")
            f.write(f"[{sim_id}] Sample Check (5): {sample_names}\n")
            if "å½­å† å®‡" in sample_names:
                f.write(f"[{sim_id}] âš ï¸ GHOST DETECTED IN SAMPLE!\n")
            else:
                f.write(f"[{sim_id}] âœ… Sample Clean.\n")
                
    except Exception as e:
        print(f"[Ghost] Check Failed: {e}")


    
    # é å…ˆå®šç¾© extï¼Œé¿å… initial_data å¼•ç”¨éŒ¯èª¤
    ext = ""
    if files and len(files) > 0 and files[0].filename:
        ext = files[0].filename.split(".")[-1].lower() if "." in files[0].filename else ""

    
    # è§£æå¸‚å ´æ¯”åƒ¹è³‡æ–™
    market_prices_data = None
    if market_prices:
        try:
            import json
            market_prices_data = json.loads(market_prices)
        except:
            pass
            
    # è§£æå—çœ¾å®šéŒ¨è³‡æ–™
    targeting_data = None
    if targeting:
        try:
            import json
            targeting_data = json.loads(targeting)
        except:
            pass
            
    # è§£æ Expert Mode & Force Random
    is_expert_mode = expert_mode.lower() == 'true'
    is_force_random = force_random.lower() == 'true'
    
    # å»ºç«‹åˆå§‹ç‹€æ…‹
    initial_data = {
        "status": "processing",
        "score": 0,
        "intent": "Calculating...",
        "summary": "AI æ­£åœ¨å•Ÿå‹•ä¸¦è®€å–æ‚¨çš„è³‡æ–™...",
        "genesis": {"total_population": 0, "sample_size": 0, "personas": []},
        "comments": [],
        "product_name": product_name, # ä¿å­˜ç”¨æˆ¶è¼¸å…¥
        "price": price,              # ä¿å­˜ç”¨æˆ¶è¼¸å…¥
        "description": description,  # ä¿å­˜ç”¨æˆ¶è¼¸å…¥
        "video_url": video_url,      # [New] Save video URL
        "market_prices": market_prices_data,


        "simulation_metadata": {
            "style": style,
            "language": language, # å„²å­˜èªè¨€è¨­å®š
            "product_name": product_name, # å†—é¤˜å‚™ä»½ï¼Œç¢ºä¿å‰ç«¯å¼•ç”¨ç›¸å®¹
            "source_type": "pdf" if ext == "pdf" or ext in ["docx", "txt"] else "image",
            "targeting": targeting_data,
            "expert_mode": is_expert_mode,
            "force_random": is_force_random,
            "analysis_scenario": analysis_scenario
        }
    }
    # å»ºç«‹ DB ç´€éŒ„
    create_simulation(sim_id, initial_data)
    
    # è®€å–æª”æ¡ˆ
    file_bytes_list = []
    filenames = []
    
    # <--- é—œéµï¼šåªæœ‰ç•¶ files ä¸ç‚º None æ™‚æ‰åŸ·è¡Œè®€å–
    if files:
        for file in files:
            content = await file.read()
            file_bytes_list.append(content)
            filenames.append(file.filename.lower() if file.filename else "")
    
    # ä¸»è¦æª”æ¡ˆ (ç”¨æ–¼åˆ¤æ–·é¡å‹)
    main_filename = filenames[0] if filenames else ""
    main_file_bytes = file_bytes_list[0] if file_bytes_list else b""
    
    # çµ„åˆ Text Context
    text_context = ""
    if product_name: text_context += f"ç”¢å“åç¨±ï¼š{product_name}\n"
    if price: text_context += f"å»ºè­°å”®åƒ¹ï¼š{price}\n"
    if description: text_context += f"ç”¢å“æè¿°ï¼š{description}\n"
    text_context = text_context.strip() if text_context else None

    # åˆ¤æ–·æª”æ¡ˆé¡å‹
    from app.utils.document_parser import parse_document, get_file_extension
    ext = get_file_extension(main_filename)
    
    # æ–‡ä»¶é¡å‹è™•ç† (Word, PPT, TXT)
    document_extensions = ["docx", "pptx", "txt"]
    audio_extensions = ["webm", "mp3", "wav", "m4a", "ogg"]
    
    # [MODE SWITCH] æ ¹æ“šè¼¸å…¥é¡å‹é¸æ“‡è™•ç†æµç¨‹
    
    # â­ ç´”è¦–é »æ¨¡å¼ï¼šæ²’æœ‰ä¸Šå‚³æ–‡ä»¶ï¼Œåªæœ‰ video_url
    if video_url and not file_bytes_list:
        print(f"[WEB] ğŸ¬ Pure Video Mode detected! URL: {video_url}", flush=True)
        
        # ä¸è¦åŒæ­¥æ¢æ¸¬ï¼ˆæœƒè¶…æ™‚ï¼‰ï¼Œç›´æ¥å•Ÿå‹•å¾Œå°ä»»å‹™
        background_tasks.add_task(
            run_video_audit_task,
            sim_id,
            video_url,
            product_name,
            price,
            description=description,
            style=style,
            language=language,
            targeting_data=targeting_data,
            is_expert_mode=is_expert_mode,
            is_force_random=is_force_random,
            analysis_scenario=analysis_scenario,
            seed_salt=seed_salt
        )
    
    elif ext == "pdf":
        # PDF Processing - use wrapper to catch exceptions
        background_tasks.add_task(
            safe_run_pdf_task, 
            line_service,  # Pass service instance to wrapper
            sim_id, 
            main_file_bytes,
            main_filename,
            product_name or "Unknown Product", 
            price or "Unknown Price",
            description or "",
            market_prices_data,
            style,
            language,
            targeting_data,
            is_expert_mode,
            is_force_random,
            analysis_scenario,
            seed_salt,
            video_url=video_url # [Fix] Use keyword for safety
        )


    elif ext in document_extensions:
        # Word/PPT/TXT: è§£ææ–‡å­—å¾Œå‚³çµ¦æ–‡å­—åˆ†ææµç¨‹
        parsed_text = parse_document(main_file_bytes, main_filename)
        if parsed_text:
            # åˆä½µè§£æå…§å®¹èˆ‡ç”¨æˆ¶é¡å¤–è¼¸å…¥
            full_context = parsed_text
            if text_context:
                full_context = f"{text_context}\n\n---\n\n{parsed_text}"
            background_tasks.add_task(line_service.run_simulation_with_text_data, full_context, sim_id, ext, language)
        else:
            # è¨­ç½®éŒ¯èª¤ç‹€æ…‹
            from app.core.database import update_simulation
            update_simulation(sim_id, "error", {"status": "error", "summary": f"ç„¡æ³•è§£æ {ext.upper()} æ–‡ä»¶"})
    elif ext in audio_extensions:
        # éŸ³è¨Šæª”: å‚³çµ¦èªéŸ³è½‰æ–‡å­—è™•ç†
        background_tasks.add_task(line_service.run_simulation_with_audio_data, main_file_bytes, sim_id, ext, language)
    else:
        # Image Processing (default)
        # NOTE: file_bytes_list is already populated at line 167-172, no need to read again
        # UploadFile can only be read once!
            
        background_tasks.add_task(
            line_service.run_simulation_with_image_data, 
            file_bytes_list, 
            sim_id, 
            text_context=text_context, 
            language=language,
            force_random=is_force_random,
            seed_salt=seed_salt,
            video_url=video_url
        )


        
    return {"status": "ok", "sim_id": sim_id}


@router.post("/generate-description")
async def generate_description(
    files: List[UploadFile] = File(...),
    product_name: str = Form(...),
    price: str = Form(...),
    style: str = Form("professional"),
    language: str = Form("zh-TW")
):
    try:
        from app.services.line_bot_service import LineBotService
        line_service = LineBotService()

        # Read multiple files
        file_bytes_list = []
        for file in files:
            file_bytes_list.append(await file.read())
        
        # Call LineBotService to generate copy with selected style and language
        result = await line_service.generate_marketing_copy(file_bytes_list, product_name, price, style, language)
        
        if "error" in result:
            return {"error": result["error"]}
            
        return result
        
    except Exception as e:
        return {"error": str(e)}

@router.post("/identify-product")
async def identify_product(
    files: List[UploadFile] = File(...),
    language: str = Form("zh-TW")
):
    """
    ä½¿ç”¨ Gemini 2.5 Pro è­˜åˆ¥åœ–ç‰‡ä¸­çš„ç”¢å“åç¨±ä¸¦ä¼°ç®—å¸‚å ´åƒ¹æ ¼
    """
    try:
        from app.services.line_bot_service import LineBotService
        import base64
        import os
        import requests
        import json
        import re
        import time
        
        line_service = LineBotService()
        
        # è®€å–æ‰€æœ‰åœ–ç‰‡
        image_parts = []
        for file in files:
            file_bytes = await file.read()
            # å°‡åœ–ç‰‡è½‰ç‚º base64
            image_b64 = base64.b64encode(file_bytes).decode('utf-8')
            
            # åˆ¤æ–· MIME type
            filename = file.filename.lower() if file.filename else ""
            if filename.endswith('.png'):
                mime_type = "image/png"
            elif filename.endswith('.webp'):
                mime_type = "image/webp"
            elif filename.endswith('.gif'):
                mime_type = "image/gif"
            else:
                mime_type = "image/jpeg"
            
            image_parts.append({"inline_data": {"mime_type": mime_type, "data": image_b64}})
            
        # æ ¹æ“šèªè¨€è¨­å®š Prompt
        lang_config = {
            "en": {
                "desc_instruction": "Describe the product in English (3-8 words)",
                "price_instruction": "Estimate average market price in USD based on global platforms (Amazon, eBay, Walmart)",
                "currency": "USD",
                "price_source_instruction": "Basis for price estimation (short, under 20 words)",
                "fallback_source": "Estimated based on Amazon/eBay market data",
                "market_calibration": "Calibrated with real data from {count} global platforms",
                "prompt_template": """Analyze this product image(s) and answer the following:
1. **Same Product Check**: If multiple images uploaded, are they different angles of the same product, or different products? (If different, focus on the most prominent one)
2. **Product Identification**: What is this product? {desc_instruction}
3. **Price Estimation**: {price_instruction}

Respond ONLY in this JSON format:
{{
  "is_same_product": true/false,
  "product_name": "Product Name in English",
  "estimated_price": number (without currency symbol),
  "currency": "{currency}",
  "price_range": "min-max",
  "price_source": "{price_source_instruction}"
}}

Only return JSON, no other text."""
            },
            "zh-CN": {
                "desc_instruction": "ç”¨ç®€çŸ­çš„ä¸­æ–‡æè¿°ï¼ˆ3-8ä¸ªå­—ï¼‰",
                "price_instruction": "æ ¹æ®ä¸­å›½ä¸»æµç”µå•†å¹³å°ï¼ˆæ·˜å®ã€äº¬ä¸œã€å¤©çŒ«ï¼‰ä¼°ç®—å¸‚åœºå¹³å‡å”®ä»·ï¼ˆäººæ°‘å¸ CNYï¼‰",
                "currency": "CNY",
                "price_source_instruction": "ä»·æ ¼ä¼°ç®—ä¾æ®è¯´æ˜ï¼ˆç®€çŸ­30å­—å†…ï¼‰",
                "fallback_source": "æ ¹æ®æ·˜å®/äº¬ä¸œåŒç±»äº§å“ä¼°ç®—",
                "market_calibration": "å·²è¿åŠ¨ {count} ä¸ªç”µå•†å¹³å°çœŸå®æ•°æ®è¿›è¡Œæ ¡å‡†",
                "prompt_template": """è¯·è§‚å¯Ÿè¿™å¼ ï¼ˆæˆ–å¤šå¼ ï¼‰äº§å“å›¾ç‰‡ï¼Œå›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
1. **æ˜¯å¦ä¸ºåŒä¸€äº§å“**ï¼šå¦‚æœä¸Šä¼ äº†å¤šå¼ å›¾ç‰‡ï¼Œè¯·åˆ¤æ–­å®ƒä»¬æ˜¯å¦ä¸ºåŒä¸€ä¸ªäº§å“çš„ä¸åŒè§’åº¦ï¼Ÿè¿˜æ˜¯å®Œå…¨ä¸åŒçš„äº§å“ï¼Ÿï¼ˆå¦‚æœæ˜¯ä¸åŒäº§å“ï¼Œè¯·ä»¥æœ€æ˜¾è‘—çš„é‚£ä¸ªä¸ºä¸»è¿›è¡Œå›ç­”ï¼‰
2. **äº§å“è¯†åˆ«**ï¼šè¿™å¼ å›¾ç‰‡ä¸­çš„äº§å“æ˜¯ä»€ä¹ˆï¼Ÿ{desc_instruction}
3. **ä»·æ ¼ä¼°ç®—**ï¼š{price_instruction}

è¯·ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›ç­”ï¼š
{{
  "is_same_product": true/false,
  "product_name": "äº§å“åç§°",
  "estimated_price": æ•°å­—ï¼ˆä¸å«è´§å¸ç¬¦å·ï¼‰ï¼Œ
  "currency": "{currency}",
  "price_range": "æœ€ä½ä»·-æœ€é«˜ä»·",
  "price_source": "{price_source_instruction}"
}}

åªå›ç­” JSONï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–è¯´æ˜ã€‚"""
            },
            "zh-TW": {
                "desc_instruction": "ç”¨ç°¡çŸ­çš„ä¸­æ–‡æè¿°ï¼ˆ3-8å€‹å­—ï¼‰",
                "price_instruction": "æ ¹æ“šå°ç£ä¸»æµé›»å•†å¹³å°ï¼ˆè¦çš®ã€PChomeã€MOMOï¼‰ä¼°ç®—å¸‚å ´å¹³å‡å”®åƒ¹ï¼ˆæ–°å°å¹£ TWDï¼‰",
                "currency": "TWD",
                "price_source_instruction": "åƒ¹æ ¼ä¼°ç®—ä¾æ“šèªªæ˜ï¼ˆç°¡çŸ­30å­—å…§ï¼‰",
                "fallback_source": "æ ¹æ“šè¦çš®/PChomeåŒé¡ç”¢å“ä¼°ç®—",
                "market_calibration": "å·²é€£å‹• {count} å€‹é›»å•†å¹³å°çœŸå¯¦æ•¸æ“šé€²è¡Œæ ¡æº–",
                "prompt_template": """è«‹è§€å¯Ÿé€™å¼µï¼ˆæˆ–å¤šå¼µï¼‰ç”¢å“åœ–ç‰‡ï¼Œå›ç­”ä»¥ä¸‹å•é¡Œï¼š
1. **æ˜¯å¦ç‚ºåŒä¸€ç”¢å“**ï¼šå¦‚æœä¸Šå‚³äº†å¤šå¼µåœ–ç‰‡ï¼Œè«‹åˆ¤æ–·å®ƒå€‘æ˜¯å¦ç‚ºåŒä¸€å€‹ç”¢å“çš„ä¸åŒè§’åº¦ï¼Ÿé‚„æ˜¯å®Œå…¨ä¸åŒçš„ç”¢å“ï¼Ÿï¼ˆå¦‚æœæ˜¯ä¸åŒç”¢å“ï¼Œè«‹ä»¥æœ€é¡¯è‘—çš„é‚£å€‹ç‚ºä¸»é€²è¡Œå›ç­”ï¼‰
2. **ç”¢å“è­˜åˆ¥**ï¼šé€™å¼µåœ–ç‰‡ä¸­çš„ç”¢å“æ˜¯ä»€éº¼ï¼Ÿ{desc_instruction}
3. **åƒ¹æ ¼ä¼°ç®—**ï¼š{price_instruction}

è«‹ç”¨ä»¥ä¸‹ JSON æ ¼å¼å›ç­”ï¼š
{{
  "is_same_product": true/false,
  "product_name": "ç”¢å“åç¨±",
  "estimated_price": æ•¸å­—ï¼ˆä¸å«è²¨å¹£ç¬¦è™Ÿï¼‰ï¼Œ
  "currency": "{currency}",
  "price_range": "æœ€ä½åƒ¹-æœ€é«˜åƒ¹",
  "price_source": "{price_source_instruction}"
}}

åªå›ç­” JSONï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–èªªæ˜ã€‚"""
            }
        }
        lc = lang_config.get(language, lang_config["zh-TW"])

        # æ§‹å»ºè­˜åˆ¥ promptï¼ˆæ ¹æ“šèªè¨€ä½¿ç”¨å°æ‡‰æ¨¡æ¿ï¼‰
        prompt = lc["prompt_template"].format(
            desc_instruction=lc["desc_instruction"],
            price_instruction=lc["price_instruction"],
            currency=lc["currency"],
            price_source_instruction=lc["price_source_instruction"]
        )

        # èª¿ç”¨ Gemini API
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            return {"error": "API Key not configured"}
        
        # çµ„åˆ prompt + åœ–ç‰‡
        content_parts = [{"text": prompt}] + image_parts
        
        payload = {
            "contents": [{
                "parts": content_parts
            }],
            "generationConfig": {
                "temperature": 0.3,
                "responseMimeType": "application/json"
            }
        }

        # [Fix] Prioritize Gemini 2.5 Pro as requested by the user
        models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-flash-latest"]
        api_key = os.getenv("GOOGLE_API_KEY")
        response = None
        last_error = ""
        clean_text = "" 

        raw_text = ""
        for model in models:
            try:
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
                print(f"[Identify] Trying model: {model}...", flush=True)
                start_time = time.time()
                response = requests.post(url, headers={'Content-Type': 'application/json'}, json=payload, timeout=90)
                duration = time.time() - start_time
                print(f"[Identify] Model {model} responded in {duration:.2f}s with status {response.status_code}", flush=True)
                
                if response.status_code == 200:
                    result = response.json()
                    raw_text = result['candidates'][0]['content']['parts'][0]['text'].strip()
                    print(f"[Identify] Raw AI output: {raw_text[:200]}...", flush=True)
                    # æ¸…ç†å¯èƒ½çš„ markdown æ¨™è¨˜
                    clean_text = raw_text.replace('```json', '').replace('```', '').strip()
                    break
                else:
                    last_error = f"{model}: {response.status_code} {response.text[:100]}"
                    print(f"[Identify] Model {model} error: {last_error}", flush=True)
            except Exception as e:
                last_error = str(e)
                print(f"[Identify] Model {model} exception: {last_error}", flush=True)

        if response is not None and getattr(response, "status_code", 0) == 200 and clean_text:
            print(f"[Identify] Attempting to parse JSON: {clean_text[:100]}...", flush=True)
            # å˜—è©¦ç›´æ¥è§£æ
            try:
                data = json.loads(clean_text)
            except json.JSONDecodeError:
                print("[Identify] Direct JSON parse failed, trying regex...", flush=True)
                # å¦‚æœç›´æ¥è§£æå¤±æ•—ï¼Œå˜—è©¦ç”¨æ­£å‰‡è¡¨é”å¼æå– JSON
                json_match = re.search(r'\{.*"product_name".*\}', clean_text, re.DOTALL)
                if json_match:
                    try:
                        data = json.loads(json_match.group())
                    except json.JSONDecodeError:
                        data = {}
                else:
                    data = {}
            
            if data.get("product_name"):
                product_name = str(data.get("product_name", "")).strip('"').strip("'").strip()
                estimated_price = data.get("estimated_price", 0) or 0  # Ensure not None
                print(f"[Identify] Product Identified: {product_name}, Est Price: {estimated_price}", flush=True)
                
                # ğŸ” æ–°å¢ï¼šæœå°‹å¸‚å ´çœŸå¯¦åƒ¹æ ¼
                from app.services.price_search import search_market_prices_sync
                print(f"[MarketSearch] Starting search for: {product_name}...", flush=True)
                search_start = time.time()
                market_prices = search_market_prices_sync(product_name, estimated_price)
                print(f"[MarketSearch] Completed in {time.time() - search_start:.2f}s. Results: {len(market_prices.get('prices', []))} items found.", flush=True)
                
                # ğŸ›¡ï¸ æ¨¡å‹æ ¡æº–ï¼šå¦‚æœæœå°‹åˆ°çš„å¹³å‡åƒ¹æ ¼å­˜åœ¨ä¸”æœ‰æ•ˆï¼Œå„ªå…ˆæ¡ç”¨çœŸå¯¦å¸‚å ´æ•¸æ“š
                final_estimated_price = estimated_price
                final_price_range = data.get("price_range", "")
                final_price_source = data.get("price_source", lc['fallback_source'])

                if market_prices.get("avg_price") and market_prices["avg_price"] > 0:
                    # å¦‚æœæœå°‹åˆ°çš„å¹³å‡é ç®—èˆ‡ AI ä¼°ç®—å·®ç•°è¶…é 20%ï¼Œå‰‡é€²è¡Œèª¿æ•´
                    avg_p = market_prices["avg_price"]
                    # Ensure estimated_price is not 0 to avoid division issues
                    diff_pct = abs(avg_p - estimated_price) / max(estimated_price, 1)
                    print(f"[Calibration] Market Avg: {avg_p}, Diff: {diff_pct:.2%}", flush=True)
                    if diff_pct > 0.2:
                        print(f"[Calibration] Overriding AI estimate with market average.", flush=True)
                        final_estimated_price = avg_p
                        final_price_range = f"{market_prices['min_price']}-{market_prices['max_price']}"
                        final_price_source = lc['market_calibration'].replace('{count}', str(len(market_prices.get('prices', []))))

                print(f"[Identify] Returning: {product_name}, Price: {final_estimated_price}", flush=True)
                return {
                    "product_name": product_name,
                    "estimated_price": final_estimated_price,
                    "price_range": final_price_range,
                    "price_source": final_price_source,
                    "market_prices": market_prices
                }
            else:
                print(f"[Identify] FAILED: Could not identify product name in data: {data}", flush=True)
                # æœ€å¾Œå˜—è©¦ï¼šå–ç¬¬ä¸€è¡Œä½œç‚ºç”¢å“åç¨±
                first_line = clean_text.split('\n')[0].strip()
                return {"error": "AI could not identify the product", "raw_text": raw_text, "product_name": first_line[:30] if first_line else "æœªçŸ¥ç”¢å“"}
        else:
            status_code = getattr(response, "status_code", "Unknown")
            return {"error": f"API Error: {status_code}"}

            
    except Exception as e:
        print(f"[ERROR] Product identification failed: {e}", flush=True)
        return {"error": str(e)}

# Model specifically for this endpoint
from pydantic import BaseModel

class RefineCopyRequest(BaseModel):
    sim_id: str
    current_copy: str
    product_name: str | None = None
    price: str | None = None
    style: str | None = None
    source_type: str | None = "image"
    language: str = "zh-TW" # Default to zh-TW

@router.post("/refine-copy")
async def refine_copy(request: RefineCopyRequest):
    """
    æ ¹æ“šæ¨¡æ“¬çµæœä¸­çš„è² è©•ï¼Œå„ªåŒ–æ–‡æ¡ˆ
    """
    try:
        from app.services.line_bot_service import LineBotService
        from app.core.database import get_simulation
        
        sim_data = get_simulation(request.sim_id)
        if not sim_data:
            return {"error": "Simulation found"}
            
        comments = sim_data.get("arena_comments", [])
        if not comments:
            return {"error": "No comments found in simulation"}
            
        # æº–å‚™è³‡æ–™
        line_service = LineBotService()
        product_name = request.product_name or sim_data.get("product_name", "ç”¢å“")
        price = request.price or str(sim_data.get("price", "æœªå®š"))
        style = request.style or sim_data.get("simulation_metadata", {}).get("style", "professional")
        source_type = request.source_type or sim_data.get("simulation_metadata", {}).get("source_type", "image")

        # åŸ·è¡Œå„ªåŒ–
        result = await line_service.refine_marketing_copy(
            comments=comments, 
            product_name=product_name, 
            price=price,
            original_copy=request.current_copy,
            style=style,
            source_type=source_type,
            language=request.language
        )
        
        return result
        
    except Exception as e:
        print(f"âŒ Refine copy failed: {e}")
        return {"error": str(e)}
